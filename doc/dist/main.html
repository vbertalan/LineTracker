<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>dist.main API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>dist.main</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from pathlib import Path
from typing import *  # type: ignore
import json
import re
import datetime
import gc
import os
from itertools import product
from textwrap import wrap
import warnings
import argparse
import abc
import shutil
import logging
import subprocess
from typing import Any, Dict, List, Optional, Tuple, Union
import psutil
import multiprocessing as mp
import functools
import random
import fire
import torch
from torch import nn
import itertools as it
import sklearn.preprocessing as skPrepro
import sklearn.metrics as skMetrics
from sklearn.feature_extraction.text import TfidfVectorizer
import uuid
import pandas as pd
import contextlib
import hashlib
from sklearn.cluster import DBSCAN
import ctypes
import functools as ft
from sklearn.metrics import adjusted_rand_score, silhouette_score, jaccard_score
from sklearn.metrics.cluster import rand_score
from sklearn.metrics.pairwise import pairwise_distances
from contextlib import redirect_stdout
from io import StringIO
from dist.parser import get_parsing_drainparser, ParsedLine

&#34;&#34;&#34;File of code: disclaimer functions comes from the repository https://github.com/AndressaStefany/severityPrediction&#34;&#34;&#34;
# tye hints
LlamaTokenizer = Union[&#34;trf.LlamaTokenizer&#34;, &#34;trf.LlamaTokenizerFast&#34;]
LlamaModel = &#34;trf.LlamaForCausalLM&#34;
PoolingOperationCode = Literal[&#34;mean&#34;, &#34;sum&#34;]
PoolingFn = Callable[[&#34;torch.Tensor&#34;], &#34;torch.Tensor&#34;]
ModelName = Literal[&#34;meta-llama/Llama-2-13b-chat-hf&#34;, &#34;meta-llama/Llama-2-7b-chat-hf&#34;]
DatasetName = Literal[&#34;eclipse_72k&#34;, &#34;mozilla_200k&#34;]
BugId: int
ParserTypes = Literal[&#34;drain&#34;]
EmbedderType = Literal[&#34;llama-13b&#34;, &#34;tfidf&#34;]
EmbeddingDistanceType = Literal[&#34;cosine&#34;, &#34;euclidean&#34;]
ClusteringType = Literal[&#34;kmedoid&#34;, &#34;dbscan&#34;]
# typehint imports
import transformers as trf
import torch
import torch.nn as nn
import torch.utils.data as dt
import huggingface_hub
import pandas as pd
import numpy as np
import peft
import trl
import matplotlib.pyplot as plt
import matplotlib
import sklearn.metrics as skMetr
import sklearn.model_selection as skMsel
import tqdm
import datasets
import h5py
import bitsandbytes as bnb
import evaluate  # type: ignore
import optuna
import accelerate



class LogData(TypedDict):
    &#34;&#34;&#34;
    - event_id: str, Unique string per bug_id
    - text: str, Text of the error
    - line_num: str, Plan id of the log: with log_name constitute the build_log
    &#34;&#34;&#34;

    event_id: str
    text: str
    line_num: str


class TripletMatrix(TypedDict):
    &#34;&#34;&#34;
    - variables_matrix: np.ndarray, matrix distances
    - embeddings_matrix: np.ndarray, embeddings distances
    - count_matrix: np.ndarray, count of line distances
    &#34;&#34;&#34;

    variables_matrix: np.ndarray
    embeddings_matrix: np.ndarray
    count_matrix: np.ndarray


class TripletCoef(TypedDict):
    &#34;&#34;&#34;
    - coef_variables_matrix: coefficient for the matrix distances
    - coef_embeddings_matrix: coefficient for the embeddings distances
    - coef_count_matrix: coefficient for the count of line distances
    &#34;&#34;&#34;

    coef_variables_matrix: float
    coef_embeddings_matrix: float
    coef_count_matrix: float


class LineTrackerException(Exception):
    &#34;&#34;&#34;Base class for the LineTracker exceptions&#34;&#34;&#34;


class EmptyLog(LineTrackerException):
    &#34;&#34;&#34;Exception when no logs is found&#34;&#34;&#34;

    def __init__(self, msg, logs: List[Dict[str, Any]]):
        super().__init__(msg)
        self.logs = logs


class NoVariable(LineTrackerException):
    &#34;&#34;&#34;Exception when no variables are inside log lines&#34;&#34;&#34;

    def __init__(self, msg, logs: List[Dict[str, Any]]):
        super().__init__(msg)
        self.logs = logs


class ParsingOutput(TypedDict):
    &#34;&#34;&#34;
    - event_id: str, Unique string per bug_id
    - template: str, the template used in this event
    - variables: List[str], the variables in this event
    &#34;&#34;&#34;

    event_id: str
    template: str
    variables: List[str]


class LogEmbeddingData(TypedDict):
    &#34;&#34;&#34;
    - event_id: str, Unique string per bug_id
    - text: str, the source text provided to the model to make the embedding
    - embedding: np.ndarray, the embedding generated by the model
    &#34;&#34;&#34;

    event_id: str
    text: str
    embedding: np.ndarray

class ClusteringAlgorithmOutput(TypedDict):
    type: str
    clustering: Dict[int, int]
    hyperparameters: Dict[str, Any]
    
class ClusteringAlgorithmOutputKMedoid(ClusteringAlgorithmOutput):
    type: str
    clustering: Dict[int, int]
    hyperparameters: Dict[str, Any]
    score: float

def get_parser_fn(
    parser_type: ParserTypes,
) -&gt; Callable[[List[LogData]], List[ParsingOutput]]:
    &#34;&#34;&#34;Get the function for the parser&#34;&#34;&#34;
    if parser_type == &#34;drain&#34;:
        return lambda events: get_parsing_drainparser(
            events,
            depth=5,
            similarity_threshold=0.4,
            max_children=3,
        )
    else:
        raise ValueError(f&#34;Expecting parser type to be among {&#39;,&#39;.join(get_args(ParserTypes))}&#34;)

def get_embedder(embedder_type: EmbedderType) -&gt; Callable[[List[LogData]], Generator[LogEmbeddingData, None, None]]:
    &#34;&#34;&#34;Get the function to generate the embeddings&#34;&#34;&#34;
    if embedder_type == &#34;llama-13b&#34;:
        return get_embedder_fn(embedder_type, pooling_code=&#39;mean&#39;, model_name=&#39;meta-llama/Llama-2-13b-chat-hf&#39;,limit_tokens=1000)
    elif embedder_type == &#34;tfidf&#34;:
        return generate_tfidf_embeddings
    else:
        raise ValueError(f&#34;Expecting embedder_type to be among {&#39;,&#39;.join(get_args(EmbedderType))}&#34;)

def get_emb_dist_fn(embedding_distance: EmbeddingDistanceType) -&gt; Callable[[np.ndarray], np.ndarray]:
    &#34;&#34;&#34;Get the function to generate the normalized (0-1) embeddings distances from the embeddings&#34;&#34;&#34;
    if embedding_distance == &#39;cosine&#39;:
        # in case of cosine distance that can take values between 0 and 2 we divide the result by 2 to come back between 0 and 1
        return lambda data: get_distance_matrix(data, metric=embedding_distance)/2
    elif embedding_distance == &#39;euclidean&#39;:
        # in case of euclidean distance that can take values unbouded we do a standard 0-1 normalization
        def fn_euclidean(data):
            d = get_distance_matrix(data, metric=embedding_distance)
            return (d-np.min(d))/(np.max(d)-np.min(d))
        return fn_euclidean
    else:
        raise ValueError(f&#34;Expecting embedding_distance to be among {&#39;,&#39;.join(get_args(EmbeddingDistanceType))}&#34;)
        
def get_clustering_fn(clustering_type: ClusteringType, must_link: Optional[List[Tuple[int,int]]] = None, cannot_link: Optional[List[Tuple[int,int]]] = None, epsilon: Optional[float] = None) -&gt; Callable[[np.ndarray], ClusteringAlgorithmOutput]:
    &#34;&#34;&#34;Get the function to generate the clustering from the combined distance matrix&#34;&#34;&#34;
    if clustering_type == &#39;kmedoid&#39;:
        assert epsilon is None, &#34;epsilon is not used for kmedoid&#34;
        return lambda combined_matrix: best_clustering_kmedoid(combined_matrix, must_link=must_link, cannot_link=cannot_link)
    elif clustering_type == &#39;dbscan&#39;:
        assert (must_link is None and cannot_link is None), f&#34;For dbscan must_link and cannot_link must be None as this option is not supported ({must_link=}, {cannot_link=})&#34;
        assert epsilon is not None
        return lambda combined_matrix: clustering_dbscan(combined_matrix, epsilon=epsilon)
    else:
        raise ValueError(f&#34;Expecting embedding_distance to be among {&#39;,&#39;.join(get_args(ClusteringType))}&#34;)


def get_variable_matrix(
    parsed_events: List[List[str]],
) -&gt; np.ndarray:
    &#34;&#34;&#34;Build the variable matrix from parsed logs
    
    # Arguments
    - parsed_events: List[List[str]], for each log line the variables inside this line. !! warning !! can be empty if there are no variable for a line
    
    # Returns
    - np.ndarray a one hot encoding indicating for each line if any of the variables inside the full log file is seen in this line
    &#34;&#34;&#34;
    binarizer = skPrepro.MultiLabelBinarizer(sparse_output=False)
    matrix_variables = binarizer.fit_transform(
        parsed_events
    )
    if matrix_variables.shape[0] == 0:
        raise EmptyLog(&#34;No logs in the logs provided&#34;, logs=parsed_events)  # type: ignore
    if matrix_variables.shape[1] == 0:
        raise NoVariable(&#34;No variables in the logs provided&#34;, logs=parsed_events)  # type: ignore
    return matrix_variables.astype(bool)  # type: ignore

def get_distance_matrix(
    embeddings: np.ndarray,
    metric: Literal[&#34;jaccard&#34;, &#34;cosine&#34;, &#34;euclidean&#34;],
) -&gt; np.ndarray:
    &#34;&#34;&#34;Generate a matrix with the distance between each pairs of lines using the metric provided
    
    # Arguments
    - embeddings: np.ndarray, (n_lines, size_embedding), for each log line the embedding associated
    - metric: Literal[&#34;jaccard&#34;, &#34;cosine&#34;, &#34;euclidean&#34;], the metric to use
    
    # Returns
    - np.ndarray (n_lines, n_lines) the pairwise distance between the embeddings
    &#34;&#34;&#34;
    return skMetrics.pairwise_distances(embeddings, metric=metric)

def execute_full_pipeline(
    logs: List[LogData],
    triplet_coefficient: TripletCoef,
    parser: Callable[[List[LogData]], List[ParsedLine]],
    embedder: Callable[[List[LogData]], Generator[np.ndarray, None, None]],
    emb_dist_fn: Callable[[np.ndarray], np.ndarray],
    clustering_fn: Callable[[np.ndarray], ClusteringAlgorithmOutput],
    float_precision: type = np.float32,
) -&gt; ClusteringAlgorithmOutput:
    &#34;&#34;&#34;Cluster logs provided in argument into groups of related log lines
    # Arguments
    - logs: List[LogData], the log lines
    - triplet_coefficient: TripletCoef, the three coefficients to use to ponderate the matrices
    - parser: Callable[[List[LogData]], List[ParsedLine]], a function that from the list of logs lines can generate for each line
    - embedder: Callable[[List[LogData]], Generator[np.ndarray, None, None]], the function that can generate embeddings from logs
    - emb_dist_fn: Callable[[np.ndarray], np.ndarray], given all embeddings of each log lines of the same log file, generate the normalized (between 0 and 1) distances between all embeddings
    - clustering_fn:  Callable[[np.ndarray], ClusteringAlgorithmOutput], taking the combined matrix with the coefficients provided, clusters the logs
    - float_precision: type = np.float32, the precision to use for all floating point matrices
    &#34;&#34;&#34;
    # 1. parse the logs
    parsed_logs: List[ParsedLine] = parser(logs)
    parsed_variables = [e[&#39;variables&#39;] for e in parsed_logs]
    # 2. build the variable matrix (alreay normalized matrix as it has values between 0 and 1)
    variables_matrix = get_variable_matrix(parsed_variables)
    variables_distance_matrix: np.ndarray = get_distance_matrix(
        variables_matrix,
        metric=&#34;jaccard&#34;,
    ).astype(float_precision)
    del variables_matrix
    # 3. build the embeddings
    embeddings: np.ndarray = np.array(
        [embedding for embedding in embedder(logs)]
    ).astype(float_precision)
    # 4. build the distance matrix
    embeddings_distance_matrix = emb_dist_fn(embeddings).astype(float_precision)
    max_v, min_v = np.max(embeddings_distance_matrix), np.min(
        embeddings_distance_matrix
    )
    assert (
        max_v &lt;= 1 and min_v &gt;= 0
    ), f&#34;Expecting the matrix to be normalized with values in the interval [0,1] but found values of embeddings distance between [{min_v},{max_v}]. check your emb_dist_fn&#34;
    del embeddings
    # 5. build the count matrix
    count_matrix = get_count_distance_matrix(logs, count_matrix_mode=&#34;absolute&#34;).astype(
        float_precision
    )
    # 6. merge the matrices with triplet coefficient
    combined_matrix = combine_matrices(
        TripletMatrix(
            variables_matrix=variables_distance_matrix,
            embeddings_matrix=embeddings_distance_matrix,
            count_matrix=count_matrix,
        ),
        triplet_coef=triplet_coefficient,
    ).astype(float_precision)
    # note: values will be between 0 and 3 (addition of 3 matrices normalized between 0 and 3)
    del variables_distance_matrix
    del embeddings_distance_matrix
    # 7. run the clustering algorithm with the constraints
    clustering_output = clustering_fn(combined_matrix)
    # 8. return the result
    return clustering_output</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="dist.main.execute_full_pipeline"><code class="name flex">
<span>def <span class="ident">execute_full_pipeline</span></span>(<span>logs: List[<a title="dist.main.LogData" href="#dist.main.LogData">LogData</a>], triplet_coefficient: <a title="dist.main.TripletCoef" href="#dist.main.TripletCoef">TripletCoef</a>, parser: Callable[[List[<a title="dist.main.LogData" href="#dist.main.LogData">LogData</a>]], List[<a title="dist.parser.ParsedLine" href="parser.html#dist.parser.ParsedLine">ParsedLine</a>]], embedder: Callable[[List[<a title="dist.main.LogData" href="#dist.main.LogData">LogData</a>]], Generator[numpy.ndarray, None, None]], emb_dist_fn: Callable[[numpy.ndarray], numpy.ndarray], clustering_fn: Callable[[numpy.ndarray], <a title="dist.main.ClusteringAlgorithmOutput" href="#dist.main.ClusteringAlgorithmOutput">ClusteringAlgorithmOutput</a>], float_precision: type = numpy.float32) ‑> <a title="dist.main.ClusteringAlgorithmOutput" href="#dist.main.ClusteringAlgorithmOutput">ClusteringAlgorithmOutput</a></span>
</code></dt>
<dd>
<div class="desc"><p>Cluster logs provided in argument into groups of related log lines</p>
<h1 id="arguments">Arguments</h1>
<ul>
<li>logs: List[LogData], the log lines</li>
<li>triplet_coefficient: TripletCoef, the three coefficients to use to ponderate the matrices</li>
<li>parser: Callable[[List[LogData]], List[ParsedLine]], a function that from the list of logs lines can generate for each line</li>
<li>embedder: Callable[[List[LogData]], Generator[np.ndarray, None, None]], the function that can generate embeddings from logs</li>
<li>emb_dist_fn: Callable[[np.ndarray], np.ndarray], given all embeddings of each log lines of the same log file, generate the normalized (between 0 and 1) distances between all embeddings</li>
<li>clustering_fn:
Callable[[np.ndarray], ClusteringAlgorithmOutput], taking the combined matrix with the coefficients provided, clusters the logs</li>
<li>float_precision: type = np.float32, the precision to use for all floating point matrices</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def execute_full_pipeline(
    logs: List[LogData],
    triplet_coefficient: TripletCoef,
    parser: Callable[[List[LogData]], List[ParsedLine]],
    embedder: Callable[[List[LogData]], Generator[np.ndarray, None, None]],
    emb_dist_fn: Callable[[np.ndarray], np.ndarray],
    clustering_fn: Callable[[np.ndarray], ClusteringAlgorithmOutput],
    float_precision: type = np.float32,
) -&gt; ClusteringAlgorithmOutput:
    &#34;&#34;&#34;Cluster logs provided in argument into groups of related log lines
    # Arguments
    - logs: List[LogData], the log lines
    - triplet_coefficient: TripletCoef, the three coefficients to use to ponderate the matrices
    - parser: Callable[[List[LogData]], List[ParsedLine]], a function that from the list of logs lines can generate for each line
    - embedder: Callable[[List[LogData]], Generator[np.ndarray, None, None]], the function that can generate embeddings from logs
    - emb_dist_fn: Callable[[np.ndarray], np.ndarray], given all embeddings of each log lines of the same log file, generate the normalized (between 0 and 1) distances between all embeddings
    - clustering_fn:  Callable[[np.ndarray], ClusteringAlgorithmOutput], taking the combined matrix with the coefficients provided, clusters the logs
    - float_precision: type = np.float32, the precision to use for all floating point matrices
    &#34;&#34;&#34;
    # 1. parse the logs
    parsed_logs: List[ParsedLine] = parser(logs)
    parsed_variables = [e[&#39;variables&#39;] for e in parsed_logs]
    # 2. build the variable matrix (alreay normalized matrix as it has values between 0 and 1)
    variables_matrix = get_variable_matrix(parsed_variables)
    variables_distance_matrix: np.ndarray = get_distance_matrix(
        variables_matrix,
        metric=&#34;jaccard&#34;,
    ).astype(float_precision)
    del variables_matrix
    # 3. build the embeddings
    embeddings: np.ndarray = np.array(
        [embedding for embedding in embedder(logs)]
    ).astype(float_precision)
    # 4. build the distance matrix
    embeddings_distance_matrix = emb_dist_fn(embeddings).astype(float_precision)
    max_v, min_v = np.max(embeddings_distance_matrix), np.min(
        embeddings_distance_matrix
    )
    assert (
        max_v &lt;= 1 and min_v &gt;= 0
    ), f&#34;Expecting the matrix to be normalized with values in the interval [0,1] but found values of embeddings distance between [{min_v},{max_v}]. check your emb_dist_fn&#34;
    del embeddings
    # 5. build the count matrix
    count_matrix = get_count_distance_matrix(logs, count_matrix_mode=&#34;absolute&#34;).astype(
        float_precision
    )
    # 6. merge the matrices with triplet coefficient
    combined_matrix = combine_matrices(
        TripletMatrix(
            variables_matrix=variables_distance_matrix,
            embeddings_matrix=embeddings_distance_matrix,
            count_matrix=count_matrix,
        ),
        triplet_coef=triplet_coefficient,
    ).astype(float_precision)
    # note: values will be between 0 and 3 (addition of 3 matrices normalized between 0 and 3)
    del variables_distance_matrix
    del embeddings_distance_matrix
    # 7. run the clustering algorithm with the constraints
    clustering_output = clustering_fn(combined_matrix)
    # 8. return the result
    return clustering_output</code></pre>
</details>
</dd>
<dt id="dist.main.get_clustering_fn"><code class="name flex">
<span>def <span class="ident">get_clustering_fn</span></span>(<span>clustering_type: Literal['kmedoid', 'dbscan'], must_link: Optional[List[Tuple[int, int]]] = None, cannot_link: Optional[List[Tuple[int, int]]] = None, epsilon: Optional[float] = None) ‑> Callable[[numpy.ndarray], <a title="dist.main.ClusteringAlgorithmOutput" href="#dist.main.ClusteringAlgorithmOutput">ClusteringAlgorithmOutput</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>Get the function to generate the clustering from the combined distance matrix</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_clustering_fn(clustering_type: ClusteringType, must_link: Optional[List[Tuple[int,int]]] = None, cannot_link: Optional[List[Tuple[int,int]]] = None, epsilon: Optional[float] = None) -&gt; Callable[[np.ndarray], ClusteringAlgorithmOutput]:
    &#34;&#34;&#34;Get the function to generate the clustering from the combined distance matrix&#34;&#34;&#34;
    if clustering_type == &#39;kmedoid&#39;:
        assert epsilon is None, &#34;epsilon is not used for kmedoid&#34;
        return lambda combined_matrix: best_clustering_kmedoid(combined_matrix, must_link=must_link, cannot_link=cannot_link)
    elif clustering_type == &#39;dbscan&#39;:
        assert (must_link is None and cannot_link is None), f&#34;For dbscan must_link and cannot_link must be None as this option is not supported ({must_link=}, {cannot_link=})&#34;
        assert epsilon is not None
        return lambda combined_matrix: clustering_dbscan(combined_matrix, epsilon=epsilon)
    else:
        raise ValueError(f&#34;Expecting embedding_distance to be among {&#39;,&#39;.join(get_args(ClusteringType))}&#34;)</code></pre>
</details>
</dd>
<dt id="dist.main.get_distance_matrix"><code class="name flex">
<span>def <span class="ident">get_distance_matrix</span></span>(<span>embeddings: numpy.ndarray, metric: Literal['jaccard', 'cosine', 'euclidean']) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Generate a matrix with the distance between each pairs of lines using the metric provided</p>
<h1 id="arguments">Arguments</h1>
<ul>
<li>embeddings: np.ndarray, (n_lines, size_embedding), for each log line the embedding associated</li>
<li>metric: Literal["jaccard", "cosine", "euclidean"], the metric to use</li>
</ul>
<h1 id="returns">Returns</h1>
<ul>
<li>np.ndarray (n_lines, n_lines) the pairwise distance between the embeddings</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_distance_matrix(
    embeddings: np.ndarray,
    metric: Literal[&#34;jaccard&#34;, &#34;cosine&#34;, &#34;euclidean&#34;],
) -&gt; np.ndarray:
    &#34;&#34;&#34;Generate a matrix with the distance between each pairs of lines using the metric provided
    
    # Arguments
    - embeddings: np.ndarray, (n_lines, size_embedding), for each log line the embedding associated
    - metric: Literal[&#34;jaccard&#34;, &#34;cosine&#34;, &#34;euclidean&#34;], the metric to use
    
    # Returns
    - np.ndarray (n_lines, n_lines) the pairwise distance between the embeddings
    &#34;&#34;&#34;
    return skMetrics.pairwise_distances(embeddings, metric=metric)</code></pre>
</details>
</dd>
<dt id="dist.main.get_emb_dist_fn"><code class="name flex">
<span>def <span class="ident">get_emb_dist_fn</span></span>(<span>embedding_distance: Literal['cosine', 'euclidean']) ‑> Callable[[numpy.ndarray], numpy.ndarray]</span>
</code></dt>
<dd>
<div class="desc"><p>Get the function to generate the normalized (0-1) embeddings distances from the embeddings</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_emb_dist_fn(embedding_distance: EmbeddingDistanceType) -&gt; Callable[[np.ndarray], np.ndarray]:
    &#34;&#34;&#34;Get the function to generate the normalized (0-1) embeddings distances from the embeddings&#34;&#34;&#34;
    if embedding_distance == &#39;cosine&#39;:
        # in case of cosine distance that can take values between 0 and 2 we divide the result by 2 to come back between 0 and 1
        return lambda data: get_distance_matrix(data, metric=embedding_distance)/2
    elif embedding_distance == &#39;euclidean&#39;:
        # in case of euclidean distance that can take values unbouded we do a standard 0-1 normalization
        def fn_euclidean(data):
            d = get_distance_matrix(data, metric=embedding_distance)
            return (d-np.min(d))/(np.max(d)-np.min(d))
        return fn_euclidean
    else:
        raise ValueError(f&#34;Expecting embedding_distance to be among {&#39;,&#39;.join(get_args(EmbeddingDistanceType))}&#34;)</code></pre>
</details>
</dd>
<dt id="dist.main.get_embedder"><code class="name flex">
<span>def <span class="ident">get_embedder</span></span>(<span>embedder_type: Literal['llama-13b', 'tfidf']) ‑> Callable[[List[<a title="dist.main.LogData" href="#dist.main.LogData">LogData</a>]], Generator[<a title="dist.main.LogEmbeddingData" href="#dist.main.LogEmbeddingData">LogEmbeddingData</a>, None, None]]</span>
</code></dt>
<dd>
<div class="desc"><p>Get the function to generate the embeddings</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_embedder(embedder_type: EmbedderType) -&gt; Callable[[List[LogData]], Generator[LogEmbeddingData, None, None]]:
    &#34;&#34;&#34;Get the function to generate the embeddings&#34;&#34;&#34;
    if embedder_type == &#34;llama-13b&#34;:
        return get_embedder_fn(embedder_type, pooling_code=&#39;mean&#39;, model_name=&#39;meta-llama/Llama-2-13b-chat-hf&#39;,limit_tokens=1000)
    elif embedder_type == &#34;tfidf&#34;:
        return generate_tfidf_embeddings
    else:
        raise ValueError(f&#34;Expecting embedder_type to be among {&#39;,&#39;.join(get_args(EmbedderType))}&#34;)</code></pre>
</details>
</dd>
<dt id="dist.main.get_parser_fn"><code class="name flex">
<span>def <span class="ident">get_parser_fn</span></span>(<span>parser_type: Literal['drain']) ‑> Callable[[List[<a title="dist.main.LogData" href="#dist.main.LogData">LogData</a>]], List[<a title="dist.main.ParsingOutput" href="#dist.main.ParsingOutput">ParsingOutput</a>]]</span>
</code></dt>
<dd>
<div class="desc"><p>Get the function for the parser</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_parser_fn(
    parser_type: ParserTypes,
) -&gt; Callable[[List[LogData]], List[ParsingOutput]]:
    &#34;&#34;&#34;Get the function for the parser&#34;&#34;&#34;
    if parser_type == &#34;drain&#34;:
        return lambda events: get_parsing_drainparser(
            events,
            depth=5,
            similarity_threshold=0.4,
            max_children=3,
        )
    else:
        raise ValueError(f&#34;Expecting parser type to be among {&#39;,&#39;.join(get_args(ParserTypes))}&#34;)</code></pre>
</details>
</dd>
<dt id="dist.main.get_variable_matrix"><code class="name flex">
<span>def <span class="ident">get_variable_matrix</span></span>(<span>parsed_events: List[List[str]]) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Build the variable matrix from parsed logs</p>
<h1 id="arguments">Arguments</h1>
<ul>
<li>parsed_events: List[List[str]], for each log line the variables inside this line. !! warning !! can be empty if there are no variable for a line</li>
</ul>
<h1 id="returns">Returns</h1>
<ul>
<li>np.ndarray a one hot encoding indicating for each line if any of the variables inside the full log file is seen in this line</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_variable_matrix(
    parsed_events: List[List[str]],
) -&gt; np.ndarray:
    &#34;&#34;&#34;Build the variable matrix from parsed logs
    
    # Arguments
    - parsed_events: List[List[str]], for each log line the variables inside this line. !! warning !! can be empty if there are no variable for a line
    
    # Returns
    - np.ndarray a one hot encoding indicating for each line if any of the variables inside the full log file is seen in this line
    &#34;&#34;&#34;
    binarizer = skPrepro.MultiLabelBinarizer(sparse_output=False)
    matrix_variables = binarizer.fit_transform(
        parsed_events
    )
    if matrix_variables.shape[0] == 0:
        raise EmptyLog(&#34;No logs in the logs provided&#34;, logs=parsed_events)  # type: ignore
    if matrix_variables.shape[1] == 0:
        raise NoVariable(&#34;No variables in the logs provided&#34;, logs=parsed_events)  # type: ignore
    return matrix_variables.astype(bool)  # type: ignore</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="dist.main.ClusteringAlgorithmOutput"><code class="flex name class">
<span>class <span class="ident">ClusteringAlgorithmOutput</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>dict() -&gt; new empty dictionary
dict(mapping) -&gt; new dictionary initialized from a mapping object's
(key, value) pairs
dict(iterable) -&gt; new dictionary initialized as if via:
d = {}
for k, v in iterable:
d[k] = v
dict(**kwargs) -&gt; new dictionary initialized with the name=value pairs
in the keyword argument list.
For example:
dict(one=1, two=2)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ClusteringAlgorithmOutput(TypedDict):
    type: str
    clustering: Dict[int, int]
    hyperparameters: Dict[str, Any]</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.dict</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="dist.main.ClusteringAlgorithmOutput.clustering"><code class="name">var <span class="ident">clustering</span> : Dict[int, int]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dist.main.ClusteringAlgorithmOutput.hyperparameters"><code class="name">var <span class="ident">hyperparameters</span> : Dict[str, Any]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dist.main.ClusteringAlgorithmOutput.type"><code class="name">var <span class="ident">type</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="dist.main.ClusteringAlgorithmOutputKMedoid"><code class="flex name class">
<span>class <span class="ident">ClusteringAlgorithmOutputKMedoid</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>dict() -&gt; new empty dictionary
dict(mapping) -&gt; new dictionary initialized from a mapping object's
(key, value) pairs
dict(iterable) -&gt; new dictionary initialized as if via:
d = {}
for k, v in iterable:
d[k] = v
dict(**kwargs) -&gt; new dictionary initialized with the name=value pairs
in the keyword argument list.
For example:
dict(one=1, two=2)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ClusteringAlgorithmOutputKMedoid(ClusteringAlgorithmOutput):
    type: str
    clustering: Dict[int, int]
    hyperparameters: Dict[str, Any]
    score: float</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.dict</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="dist.main.ClusteringAlgorithmOutputKMedoid.clustering"><code class="name">var <span class="ident">clustering</span> : Dict[int, int]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dist.main.ClusteringAlgorithmOutputKMedoid.hyperparameters"><code class="name">var <span class="ident">hyperparameters</span> : Dict[str, Any]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dist.main.ClusteringAlgorithmOutputKMedoid.score"><code class="name">var <span class="ident">score</span> : float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dist.main.ClusteringAlgorithmOutputKMedoid.type"><code class="name">var <span class="ident">type</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="dist.main.EmptyLog"><code class="flex name class">
<span>class <span class="ident">EmptyLog</span></span>
<span>(</span><span>msg, logs: List[Dict[str, Any]])</span>
</code></dt>
<dd>
<div class="desc"><p>Exception when no logs is found</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class EmptyLog(LineTrackerException):
    &#34;&#34;&#34;Exception when no logs is found&#34;&#34;&#34;

    def __init__(self, msg, logs: List[Dict[str, Any]]):
        super().__init__(msg)
        self.logs = logs</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="dist.main.LineTrackerException" href="#dist.main.LineTrackerException">LineTrackerException</a></li>
<li>builtins.Exception</li>
<li>builtins.BaseException</li>
</ul>
</dd>
<dt id="dist.main.LineTrackerException"><code class="flex name class">
<span>class <span class="ident">LineTrackerException</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Base class for the LineTracker exceptions</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class LineTrackerException(Exception):
    &#34;&#34;&#34;Base class for the LineTracker exceptions&#34;&#34;&#34;</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.Exception</li>
<li>builtins.BaseException</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="dist.main.EmptyLog" href="#dist.main.EmptyLog">EmptyLog</a></li>
<li><a title="dist.main.NoVariable" href="#dist.main.NoVariable">NoVariable</a></li>
</ul>
</dd>
<dt id="dist.main.LogData"><code class="flex name class">
<span>class <span class="ident">LogData</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><ul>
<li>event_id: str, Unique string per bug_id</li>
<li>text: str, Text of the error</li>
<li>line_num: str, Plan id of the log: with log_name constitute the build_log</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class LogData(TypedDict):
    &#34;&#34;&#34;
    - event_id: str, Unique string per bug_id
    - text: str, Text of the error
    - line_num: str, Plan id of the log: with log_name constitute the build_log
    &#34;&#34;&#34;

    event_id: str
    text: str
    line_num: str</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.dict</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="dist.main.LogData.event_id"><code class="name">var <span class="ident">event_id</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dist.main.LogData.line_num"><code class="name">var <span class="ident">line_num</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dist.main.LogData.text"><code class="name">var <span class="ident">text</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="dist.main.LogEmbeddingData"><code class="flex name class">
<span>class <span class="ident">LogEmbeddingData</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><ul>
<li>event_id: str, Unique string per bug_id</li>
<li>text: str, the source text provided to the model to make the embedding</li>
<li>embedding: np.ndarray, the embedding generated by the model</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class LogEmbeddingData(TypedDict):
    &#34;&#34;&#34;
    - event_id: str, Unique string per bug_id
    - text: str, the source text provided to the model to make the embedding
    - embedding: np.ndarray, the embedding generated by the model
    &#34;&#34;&#34;

    event_id: str
    text: str
    embedding: np.ndarray</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.dict</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="dist.main.LogEmbeddingData.embedding"><code class="name">var <span class="ident">embedding</span> : numpy.ndarray</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dist.main.LogEmbeddingData.event_id"><code class="name">var <span class="ident">event_id</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dist.main.LogEmbeddingData.text"><code class="name">var <span class="ident">text</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="dist.main.NoVariable"><code class="flex name class">
<span>class <span class="ident">NoVariable</span></span>
<span>(</span><span>msg, logs: List[Dict[str, Any]])</span>
</code></dt>
<dd>
<div class="desc"><p>Exception when no variables are inside log lines</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class NoVariable(LineTrackerException):
    &#34;&#34;&#34;Exception when no variables are inside log lines&#34;&#34;&#34;

    def __init__(self, msg, logs: List[Dict[str, Any]]):
        super().__init__(msg)
        self.logs = logs</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="dist.main.LineTrackerException" href="#dist.main.LineTrackerException">LineTrackerException</a></li>
<li>builtins.Exception</li>
<li>builtins.BaseException</li>
</ul>
</dd>
<dt id="dist.main.ParsingOutput"><code class="flex name class">
<span>class <span class="ident">ParsingOutput</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><ul>
<li>event_id: str, Unique string per bug_id</li>
<li>template: str, the template used in this event</li>
<li>variables: List[str], the variables in this event</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ParsingOutput(TypedDict):
    &#34;&#34;&#34;
    - event_id: str, Unique string per bug_id
    - template: str, the template used in this event
    - variables: List[str], the variables in this event
    &#34;&#34;&#34;

    event_id: str
    template: str
    variables: List[str]</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.dict</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="dist.main.ParsingOutput.event_id"><code class="name">var <span class="ident">event_id</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dist.main.ParsingOutput.template"><code class="name">var <span class="ident">template</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dist.main.ParsingOutput.variables"><code class="name">var <span class="ident">variables</span> : List[str]</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="dist.main.TripletCoef"><code class="flex name class">
<span>class <span class="ident">TripletCoef</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><ul>
<li>coef_variables_matrix: coefficient for the matrix distances</li>
<li>coef_embeddings_matrix: coefficient for the embeddings distances</li>
<li>coef_count_matrix: coefficient for the count of line distances</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class TripletCoef(TypedDict):
    &#34;&#34;&#34;
    - coef_variables_matrix: coefficient for the matrix distances
    - coef_embeddings_matrix: coefficient for the embeddings distances
    - coef_count_matrix: coefficient for the count of line distances
    &#34;&#34;&#34;

    coef_variables_matrix: float
    coef_embeddings_matrix: float
    coef_count_matrix: float</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.dict</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="dist.main.TripletCoef.coef_count_matrix"><code class="name">var <span class="ident">coef_count_matrix</span> : float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dist.main.TripletCoef.coef_embeddings_matrix"><code class="name">var <span class="ident">coef_embeddings_matrix</span> : float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dist.main.TripletCoef.coef_variables_matrix"><code class="name">var <span class="ident">coef_variables_matrix</span> : float</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="dist.main.TripletMatrix"><code class="flex name class">
<span>class <span class="ident">TripletMatrix</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><ul>
<li>variables_matrix: np.ndarray, matrix distances</li>
<li>embeddings_matrix: np.ndarray, embeddings distances</li>
<li>count_matrix: np.ndarray, count of line distances</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class TripletMatrix(TypedDict):
    &#34;&#34;&#34;
    - variables_matrix: np.ndarray, matrix distances
    - embeddings_matrix: np.ndarray, embeddings distances
    - count_matrix: np.ndarray, count of line distances
    &#34;&#34;&#34;

    variables_matrix: np.ndarray
    embeddings_matrix: np.ndarray
    count_matrix: np.ndarray</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.dict</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="dist.main.TripletMatrix.count_matrix"><code class="name">var <span class="ident">count_matrix</span> : numpy.ndarray</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dist.main.TripletMatrix.embeddings_matrix"><code class="name">var <span class="ident">embeddings_matrix</span> : numpy.ndarray</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dist.main.TripletMatrix.variables_matrix"><code class="name">var <span class="ident">variables_matrix</span> : numpy.ndarray</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="dist" href="index.html">dist</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="dist.main.execute_full_pipeline" href="#dist.main.execute_full_pipeline">execute_full_pipeline</a></code></li>
<li><code><a title="dist.main.get_clustering_fn" href="#dist.main.get_clustering_fn">get_clustering_fn</a></code></li>
<li><code><a title="dist.main.get_distance_matrix" href="#dist.main.get_distance_matrix">get_distance_matrix</a></code></li>
<li><code><a title="dist.main.get_emb_dist_fn" href="#dist.main.get_emb_dist_fn">get_emb_dist_fn</a></code></li>
<li><code><a title="dist.main.get_embedder" href="#dist.main.get_embedder">get_embedder</a></code></li>
<li><code><a title="dist.main.get_parser_fn" href="#dist.main.get_parser_fn">get_parser_fn</a></code></li>
<li><code><a title="dist.main.get_variable_matrix" href="#dist.main.get_variable_matrix">get_variable_matrix</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="dist.main.ClusteringAlgorithmOutput" href="#dist.main.ClusteringAlgorithmOutput">ClusteringAlgorithmOutput</a></code></h4>
<ul class="">
<li><code><a title="dist.main.ClusteringAlgorithmOutput.clustering" href="#dist.main.ClusteringAlgorithmOutput.clustering">clustering</a></code></li>
<li><code><a title="dist.main.ClusteringAlgorithmOutput.hyperparameters" href="#dist.main.ClusteringAlgorithmOutput.hyperparameters">hyperparameters</a></code></li>
<li><code><a title="dist.main.ClusteringAlgorithmOutput.type" href="#dist.main.ClusteringAlgorithmOutput.type">type</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="dist.main.ClusteringAlgorithmOutputKMedoid" href="#dist.main.ClusteringAlgorithmOutputKMedoid">ClusteringAlgorithmOutputKMedoid</a></code></h4>
<ul class="">
<li><code><a title="dist.main.ClusteringAlgorithmOutputKMedoid.clustering" href="#dist.main.ClusteringAlgorithmOutputKMedoid.clustering">clustering</a></code></li>
<li><code><a title="dist.main.ClusteringAlgorithmOutputKMedoid.hyperparameters" href="#dist.main.ClusteringAlgorithmOutputKMedoid.hyperparameters">hyperparameters</a></code></li>
<li><code><a title="dist.main.ClusteringAlgorithmOutputKMedoid.score" href="#dist.main.ClusteringAlgorithmOutputKMedoid.score">score</a></code></li>
<li><code><a title="dist.main.ClusteringAlgorithmOutputKMedoid.type" href="#dist.main.ClusteringAlgorithmOutputKMedoid.type">type</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="dist.main.EmptyLog" href="#dist.main.EmptyLog">EmptyLog</a></code></h4>
</li>
<li>
<h4><code><a title="dist.main.LineTrackerException" href="#dist.main.LineTrackerException">LineTrackerException</a></code></h4>
</li>
<li>
<h4><code><a title="dist.main.LogData" href="#dist.main.LogData">LogData</a></code></h4>
<ul class="">
<li><code><a title="dist.main.LogData.event_id" href="#dist.main.LogData.event_id">event_id</a></code></li>
<li><code><a title="dist.main.LogData.line_num" href="#dist.main.LogData.line_num">line_num</a></code></li>
<li><code><a title="dist.main.LogData.text" href="#dist.main.LogData.text">text</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="dist.main.LogEmbeddingData" href="#dist.main.LogEmbeddingData">LogEmbeddingData</a></code></h4>
<ul class="">
<li><code><a title="dist.main.LogEmbeddingData.embedding" href="#dist.main.LogEmbeddingData.embedding">embedding</a></code></li>
<li><code><a title="dist.main.LogEmbeddingData.event_id" href="#dist.main.LogEmbeddingData.event_id">event_id</a></code></li>
<li><code><a title="dist.main.LogEmbeddingData.text" href="#dist.main.LogEmbeddingData.text">text</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="dist.main.NoVariable" href="#dist.main.NoVariable">NoVariable</a></code></h4>
</li>
<li>
<h4><code><a title="dist.main.ParsingOutput" href="#dist.main.ParsingOutput">ParsingOutput</a></code></h4>
<ul class="">
<li><code><a title="dist.main.ParsingOutput.event_id" href="#dist.main.ParsingOutput.event_id">event_id</a></code></li>
<li><code><a title="dist.main.ParsingOutput.template" href="#dist.main.ParsingOutput.template">template</a></code></li>
<li><code><a title="dist.main.ParsingOutput.variables" href="#dist.main.ParsingOutput.variables">variables</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="dist.main.TripletCoef" href="#dist.main.TripletCoef">TripletCoef</a></code></h4>
<ul class="">
<li><code><a title="dist.main.TripletCoef.coef_count_matrix" href="#dist.main.TripletCoef.coef_count_matrix">coef_count_matrix</a></code></li>
<li><code><a title="dist.main.TripletCoef.coef_embeddings_matrix" href="#dist.main.TripletCoef.coef_embeddings_matrix">coef_embeddings_matrix</a></code></li>
<li><code><a title="dist.main.TripletCoef.coef_variables_matrix" href="#dist.main.TripletCoef.coef_variables_matrix">coef_variables_matrix</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="dist.main.TripletMatrix" href="#dist.main.TripletMatrix">TripletMatrix</a></code></h4>
<ul class="">
<li><code><a title="dist.main.TripletMatrix.count_matrix" href="#dist.main.TripletMatrix.count_matrix">count_matrix</a></code></li>
<li><code><a title="dist.main.TripletMatrix.embeddings_matrix" href="#dist.main.TripletMatrix.embeddings_matrix">embeddings_matrix</a></code></li>
<li><code><a title="dist.main.TripletMatrix.variables_matrix" href="#dist.main.TripletMatrix.variables_matrix">variables_matrix</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>