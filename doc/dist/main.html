<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>dist.main API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>dist.main</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from typing import *  # type: ignore
from typing import Any, Dict, List, Optional, Tuple, Union
import torch
import sklearn.preprocessing as skPrepro
import sklearn.metrics as skMetrics
from dist.parser import get_parsing_drainparser, ParsedLine

&#34;&#34;&#34;File of code: disclaimer functions comes from the repository https://github.com/AndressaStefany/severityPrediction&#34;&#34;&#34;
# tye hints
LlamaTokenizer = Union[&#34;trf.LlamaTokenizer&#34;, &#34;trf.LlamaTokenizerFast&#34;]
LlamaModel = &#34;trf.LlamaForCausalLM&#34;
PoolingOperationCode = Literal[&#34;mean&#34;, &#34;sum&#34;]
PoolingFn = Callable[[&#34;torch.Tensor&#34;], &#34;torch.Tensor&#34;]
ModelName = Literal[&#34;meta-llama/Llama-2-13b-chat-hf&#34;, &#34;meta-llama/Llama-2-7b-chat-hf&#34;]
DatasetName = Literal[&#34;eclipse_72k&#34;, &#34;mozilla_200k&#34;]
BugId: int
ParserTypes = Literal[&#34;drain&#34;]
EmbedderType = Literal[&#34;llama-13b&#34;, &#34;tfidf&#34;]
EmbeddingDistanceType = Literal[&#34;cosine&#34;, &#34;euclidean&#34;]
ClusteringType = Literal[&#34;kmedoid&#34;, &#34;dbscan&#34;]
# typehint imports
import transformers as trf
import torch
import pandas as pd
import numpy as np



class LogData(TypedDict):
    &#34;&#34;&#34;
    - event_id: str, Unique string per bug_id
    - text: str, Text of the error
    - line_num: str, Plan id of the log: with log_name constitute the build_log
    &#34;&#34;&#34;

    event_id: str
    text: str
    line_num: str


class TripletMatrix(TypedDict):
    &#34;&#34;&#34;
    - variables_matrix: np.ndarray, matrix distances
    - embeddings_matrix: np.ndarray, embeddings distances
    - count_matrix: np.ndarray, count of line distances
    &#34;&#34;&#34;

    variables_matrix: np.ndarray
    embeddings_matrix: np.ndarray
    count_matrix: np.ndarray


class TripletCoef(TypedDict):
    &#34;&#34;&#34;
    - coef_variables_matrix: coefficient for the matrix distances
    - coef_embeddings_matrix: coefficient for the embeddings distances
    - coef_count_matrix: coefficient for the count of line distances
    &#34;&#34;&#34;

    coef_variables_matrix: float
    coef_embeddings_matrix: float
    coef_count_matrix: float


class LineTrackerException(Exception):
    &#34;&#34;&#34;Base class for the LineTracker exceptions&#34;&#34;&#34;


class EmptyLog(LineTrackerException):
    &#34;&#34;&#34;Exception when no logs is found&#34;&#34;&#34;

    def __init__(self, msg, logs: List[Dict[str, Any]]):
        super().__init__(msg)
        self.logs = logs


class NoVariable(LineTrackerException):
    &#34;&#34;&#34;Exception when no variables are inside log lines&#34;&#34;&#34;

    def __init__(self, msg, logs: List[Dict[str, Any]]):
        super().__init__(msg)
        self.logs = logs


class ParsingOutput(TypedDict):
    &#34;&#34;&#34;
    - event_id: str, Unique string per bug_id
    - template: str, the template used in this event
    - variables: List[str], the variables in this event
    &#34;&#34;&#34;

    event_id: str
    template: str
    variables: List[str]


class LogEmbeddingData(TypedDict):
    &#34;&#34;&#34;
    - event_id: str, Unique string per bug_id
    - text: str, the source text provided to the model to make the embedding
    - embedding: np.ndarray, the embedding generated by the model
    &#34;&#34;&#34;

    event_id: str
    text: str
    embedding: np.ndarray

class ClusteringAlgorithmOutput(TypedDict):
    type: str
    clustering: Dict[int, int]
    hyperparameters: Dict[str, Any]
    
class ClusteringAlgorithmOutputKMedoid(ClusteringAlgorithmOutput):
    type: str
    clustering: Dict[int, int]
    hyperparameters: Dict[str, Any]
    score: float

def get_parser_fn(
    parser_type: ParserTypes,
) -&gt; Callable[[List[LogData]], List[ParsingOutput]]:
    &#34;&#34;&#34;Get the function for the parser&#34;&#34;&#34;
    if parser_type == &#34;drain&#34;:
        return lambda events: get_parsing_drainparser(
            events,
            depth=5,
            similarity_threshold=0.4,
            max_children=3,
        )
    else:
        raise ValueError(f&#34;Expecting parser type to be among {&#39;,&#39;.join(get_args(ParserTypes))}&#34;)

def get_embedder(embedder_type: EmbedderType) -&gt; Callable[[List[LogData]], Generator[LogEmbeddingData, None, None]]:
    &#34;&#34;&#34;Get the function to generate the embeddings&#34;&#34;&#34;
    if embedder_type == &#34;llama-13b&#34;:
        return get_embedder_fn(embedder_type, pooling_code=&#39;mean&#39;, model_name=&#39;meta-llama/Llama-2-13b-chat-hf&#39;,limit_tokens=1000)
    elif embedder_type == &#34;tfidf&#34;:
        return generate_tfidf_embeddings
    else:
        raise ValueError(f&#34;Expecting embedder_type to be among {&#39;,&#39;.join(get_args(EmbedderType))}&#34;)

def get_emb_dist_fn(embedding_distance: EmbeddingDistanceType) -&gt; Callable[[np.ndarray], np.ndarray]:
    &#34;&#34;&#34;Get the function to generate the normalized (0-1) embeddings distances from the embeddings&#34;&#34;&#34;
    if embedding_distance == &#39;cosine&#39;:
        # in case of cosine distance that can take values between 0 and 2 we divide the result by 2 to come back between 0 and 1
        return lambda data: get_distance_matrix(data, metric=embedding_distance)/2
    elif embedding_distance == &#39;euclidean&#39;:
        # in case of euclidean distance that can take values unbouded we do a standard 0-1 normalization
        def fn_euclidean(data):
            d = get_distance_matrix(data, metric=embedding_distance)
            return (d-np.min(d))/(np.max(d)-np.min(d))
        return fn_euclidean
    else:
        raise ValueError(f&#34;Expecting embedding_distance to be among {&#39;,&#39;.join(get_args(EmbeddingDistanceType))}&#34;)
        
def get_clustering_fn(clustering_type: ClusteringType, must_link: Optional[List[Tuple[int,int]]] = None, cannot_link: Optional[List[Tuple[int,int]]] = None, epsilon: Optional[float] = None) -&gt; Callable[[np.ndarray], ClusteringAlgorithmOutput]:
    &#34;&#34;&#34;Get the function to generate the clustering from the combined distance matrix&#34;&#34;&#34;
    if clustering_type == &#39;kmedoid&#39;:
        assert epsilon is None, &#34;epsilon is not used for kmedoid&#34;
        return lambda combined_matrix: best_clustering_kmedoid(combined_matrix, must_link=must_link, cannot_link=cannot_link)
    elif clustering_type == &#39;dbscan&#39;:
        assert (must_link is None and cannot_link is None), f&#34;For dbscan must_link and cannot_link must be None as this option is not supported ({must_link=}, {cannot_link=})&#34;
        assert epsilon is not None
        return lambda combined_matrix: clustering_dbscan(combined_matrix, epsilon=epsilon)
    else:
        raise ValueError(f&#34;Expecting embedding_distance to be among {&#39;,&#39;.join(get_args(ClusteringType))}&#34;)


def get_variable_matrix(
    parsed_events: List[List[str]],
) -&gt; np.ndarray:
    &#34;&#34;&#34;Build the variable matrix from parsed logs
    
    # Arguments
    - parsed_events: List[List[str]], for each log line the variables inside this line. !! warning !! can be empty if there are no variable for a line
    
    # Returns
    - np.ndarray a one hot encoding indicating for each line if any of the variables inside the full log file is seen in this line
    &#34;&#34;&#34;
    binarizer = skPrepro.MultiLabelBinarizer(sparse_output=False)
    matrix_variables = binarizer.fit_transform(
        parsed_events
    )
    if matrix_variables.shape[0] == 0:
        raise EmptyLog(&#34;No logs in the logs provided&#34;, logs=parsed_events)  # type: ignore
    if matrix_variables.shape[1] == 0:
        raise NoVariable(&#34;No variables in the logs provided&#34;, logs=parsed_events)  # type: ignore
    return matrix_variables.astype(bool)  # type: ignore

def get_distance_matrix(
    embeddings: np.ndarray,
    metric: Literal[&#34;jaccard&#34;, &#34;cosine&#34;, &#34;euclidean&#34;],
) -&gt; np.ndarray:
    &#34;&#34;&#34;Generate a matrix with the distance between each pairs of lines using the metric provided
    
    # Arguments
    - embeddings: np.ndarray, (n_lines, size_embedding), for each log line the embedding associated
    - metric: Literal[&#34;jaccard&#34;, &#34;cosine&#34;, &#34;euclidean&#34;], the metric to use
    
    # Returns
    - np.ndarray (n_lines, n_lines) the pairwise distance between the embeddings
    &#34;&#34;&#34;
    return skMetrics.pairwise_distances(embeddings, metric=metric)

def execute_full_pipeline(
    logs: List[LogData],
    triplet_coefficient: TripletCoef,
    parser: Callable[[List[LogData]], List[ParsedLine]],
    embedder: Callable[[List[LogData]], Generator[np.ndarray, None, None]],
    emb_dist_fn: Callable[[np.ndarray], np.ndarray],
    clustering_fn: Callable[[np.ndarray], ClusteringAlgorithmOutput],
    float_precision: type = np.float32,
) -&gt; ClusteringAlgorithmOutput:
    &#34;&#34;&#34;Cluster logs provided in argument into groups of related log lines
    # Arguments
    - logs: List[LogData], the log lines
    - triplet_coefficient: TripletCoef, the three coefficients to use to ponderate the matrices
    - parser: Callable[[List[LogData]], List[ParsedLine]], a function that from the list of logs lines can generate for each line
    - embedder: Callable[[List[LogData]], Generator[np.ndarray, None, None]], the function that can generate embeddings from logs
    - emb_dist_fn: Callable[[np.ndarray], np.ndarray], given all embeddings of each log lines of the same log file, generate the normalized (between 0 and 1) distances between all embeddings
    - clustering_fn:  Callable[[np.ndarray], ClusteringAlgorithmOutput], taking the combined matrix with the coefficients provided, clusters the logs
    - float_precision: type = np.float32, the precision to use for all floating point matrices
    &#34;&#34;&#34;
    # 1. parse the logs
    parsed_logs: List[ParsedLine] = parser(logs)
    parsed_variables = [e[&#39;variables&#39;] for e in parsed_logs]
    # 2. build the variable matrix (alreay normalized matrix as it has values between 0 and 1)
    variables_matrix = get_variable_matrix(parsed_variables)
    variables_distance_matrix: np.ndarray = get_distance_matrix(
        variables_matrix,
        metric=&#34;jaccard&#34;,
    ).astype(float_precision)
    del variables_matrix
    # 3. build the embeddings
    embeddings: np.ndarray = np.array(
        [embedding for embedding in embedder(logs)]
    ).astype(float_precision)
    # 4. build the distance matrix
    embeddings_distance_matrix = emb_dist_fn(embeddings).astype(float_precision)
    max_v, min_v = np.max(embeddings_distance_matrix), np.min(
        embeddings_distance_matrix
    )
    assert (
        max_v &lt;= 1 and min_v &gt;= 0
    ), f&#34;Expecting the matrix to be normalized with values in the interval [0,1] but found values of embeddings distance between [{min_v},{max_v}]. check your emb_dist_fn&#34;
    del embeddings
    # 5. build the count matrix
    count_matrix = get_count_distance_matrix(logs, count_matrix_mode=&#34;absolute&#34;).astype(
        float_precision
    )
    # 6. merge the matrices with triplet coefficient
    combined_matrix = combine_matrices(
        TripletMatrix(
            variables_matrix=variables_distance_matrix,
            embeddings_matrix=embeddings_distance_matrix,
            count_matrix=count_matrix,
        ),
        triplet_coef=triplet_coefficient,
    ).astype(float_precision)
    # note: values will be between 0 and 3 (addition of 3 matrices normalized between 0 and 3)
    del variables_distance_matrix
    del embeddings_distance_matrix
    # 7. run the clustering algorithm with the constraints
    clustering_output = clustering_fn(combined_matrix)
    # 8. return the result
    return clustering_output</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="dist.main.execute_full_pipeline"><code class="name flex">
<span>def <span class="ident">execute_full_pipeline</span></span>(<span>logs: List[<a title="dist.main.LogData" href="#dist.main.LogData">LogData</a>], triplet_coefficient: <a title="dist.main.TripletCoef" href="#dist.main.TripletCoef">TripletCoef</a>, parser: Callable[[List[<a title="dist.main.LogData" href="#dist.main.LogData">LogData</a>]], List[<a title="dist.parser.ParsedLine" href="parser.html#dist.parser.ParsedLine">ParsedLine</a>]], embedder: Callable[[List[<a title="dist.main.LogData" href="#dist.main.LogData">LogData</a>]], Generator[numpy.ndarray, None, None]], emb_dist_fn: Callable[[numpy.ndarray], numpy.ndarray], clustering_fn: Callable[[numpy.ndarray], <a title="dist.main.ClusteringAlgorithmOutput" href="#dist.main.ClusteringAlgorithmOutput">ClusteringAlgorithmOutput</a>], float_precision: type = numpy.float32) ‑> <a title="dist.main.ClusteringAlgorithmOutput" href="#dist.main.ClusteringAlgorithmOutput">ClusteringAlgorithmOutput</a></span>
</code></dt>
<dd>
<div class="desc"><p>Cluster logs provided in argument into groups of related log lines</p>
<h1 id="arguments">Arguments</h1>
<ul>
<li>logs: List[LogData], the log lines</li>
<li>triplet_coefficient: TripletCoef, the three coefficients to use to ponderate the matrices</li>
<li>parser: Callable[[List[LogData]], List[ParsedLine]], a function that from the list of logs lines can generate for each line</li>
<li>embedder: Callable[[List[LogData]], Generator[np.ndarray, None, None]], the function that can generate embeddings from logs</li>
<li>emb_dist_fn: Callable[[np.ndarray], np.ndarray], given all embeddings of each log lines of the same log file, generate the normalized (between 0 and 1) distances between all embeddings</li>
<li>clustering_fn:
Callable[[np.ndarray], ClusteringAlgorithmOutput], taking the combined matrix with the coefficients provided, clusters the logs</li>
<li>float_precision: type = np.float32, the precision to use for all floating point matrices</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def execute_full_pipeline(
    logs: List[LogData],
    triplet_coefficient: TripletCoef,
    parser: Callable[[List[LogData]], List[ParsedLine]],
    embedder: Callable[[List[LogData]], Generator[np.ndarray, None, None]],
    emb_dist_fn: Callable[[np.ndarray], np.ndarray],
    clustering_fn: Callable[[np.ndarray], ClusteringAlgorithmOutput],
    float_precision: type = np.float32,
) -&gt; ClusteringAlgorithmOutput:
    &#34;&#34;&#34;Cluster logs provided in argument into groups of related log lines
    # Arguments
    - logs: List[LogData], the log lines
    - triplet_coefficient: TripletCoef, the three coefficients to use to ponderate the matrices
    - parser: Callable[[List[LogData]], List[ParsedLine]], a function that from the list of logs lines can generate for each line
    - embedder: Callable[[List[LogData]], Generator[np.ndarray, None, None]], the function that can generate embeddings from logs
    - emb_dist_fn: Callable[[np.ndarray], np.ndarray], given all embeddings of each log lines of the same log file, generate the normalized (between 0 and 1) distances between all embeddings
    - clustering_fn:  Callable[[np.ndarray], ClusteringAlgorithmOutput], taking the combined matrix with the coefficients provided, clusters the logs
    - float_precision: type = np.float32, the precision to use for all floating point matrices
    &#34;&#34;&#34;
    # 1. parse the logs
    parsed_logs: List[ParsedLine] = parser(logs)
    parsed_variables = [e[&#39;variables&#39;] for e in parsed_logs]
    # 2. build the variable matrix (alreay normalized matrix as it has values between 0 and 1)
    variables_matrix = get_variable_matrix(parsed_variables)
    variables_distance_matrix: np.ndarray = get_distance_matrix(
        variables_matrix,
        metric=&#34;jaccard&#34;,
    ).astype(float_precision)
    del variables_matrix
    # 3. build the embeddings
    embeddings: np.ndarray = np.array(
        [embedding for embedding in embedder(logs)]
    ).astype(float_precision)
    # 4. build the distance matrix
    embeddings_distance_matrix = emb_dist_fn(embeddings).astype(float_precision)
    max_v, min_v = np.max(embeddings_distance_matrix), np.min(
        embeddings_distance_matrix
    )
    assert (
        max_v &lt;= 1 and min_v &gt;= 0
    ), f&#34;Expecting the matrix to be normalized with values in the interval [0,1] but found values of embeddings distance between [{min_v},{max_v}]. check your emb_dist_fn&#34;
    del embeddings
    # 5. build the count matrix
    count_matrix = get_count_distance_matrix(logs, count_matrix_mode=&#34;absolute&#34;).astype(
        float_precision
    )
    # 6. merge the matrices with triplet coefficient
    combined_matrix = combine_matrices(
        TripletMatrix(
            variables_matrix=variables_distance_matrix,
            embeddings_matrix=embeddings_distance_matrix,
            count_matrix=count_matrix,
        ),
        triplet_coef=triplet_coefficient,
    ).astype(float_precision)
    # note: values will be between 0 and 3 (addition of 3 matrices normalized between 0 and 3)
    del variables_distance_matrix
    del embeddings_distance_matrix
    # 7. run the clustering algorithm with the constraints
    clustering_output = clustering_fn(combined_matrix)
    # 8. return the result
    return clustering_output</code></pre>
</details>
</dd>
<dt id="dist.main.get_clustering_fn"><code class="name flex">
<span>def <span class="ident">get_clustering_fn</span></span>(<span>clustering_type: Literal['kmedoid', 'dbscan'], must_link: Optional[List[Tuple[int, int]]] = None, cannot_link: Optional[List[Tuple[int, int]]] = None, epsilon: Optional[float] = None) ‑> Callable[[numpy.ndarray], <a title="dist.main.ClusteringAlgorithmOutput" href="#dist.main.ClusteringAlgorithmOutput">ClusteringAlgorithmOutput</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>Get the function to generate the clustering from the combined distance matrix</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_clustering_fn(clustering_type: ClusteringType, must_link: Optional[List[Tuple[int,int]]] = None, cannot_link: Optional[List[Tuple[int,int]]] = None, epsilon: Optional[float] = None) -&gt; Callable[[np.ndarray], ClusteringAlgorithmOutput]:
    &#34;&#34;&#34;Get the function to generate the clustering from the combined distance matrix&#34;&#34;&#34;
    if clustering_type == &#39;kmedoid&#39;:
        assert epsilon is None, &#34;epsilon is not used for kmedoid&#34;
        return lambda combined_matrix: best_clustering_kmedoid(combined_matrix, must_link=must_link, cannot_link=cannot_link)
    elif clustering_type == &#39;dbscan&#39;:
        assert (must_link is None and cannot_link is None), f&#34;For dbscan must_link and cannot_link must be None as this option is not supported ({must_link=}, {cannot_link=})&#34;
        assert epsilon is not None
        return lambda combined_matrix: clustering_dbscan(combined_matrix, epsilon=epsilon)
    else:
        raise ValueError(f&#34;Expecting embedding_distance to be among {&#39;,&#39;.join(get_args(ClusteringType))}&#34;)</code></pre>
</details>
</dd>
<dt id="dist.main.get_distance_matrix"><code class="name flex">
<span>def <span class="ident">get_distance_matrix</span></span>(<span>embeddings: numpy.ndarray, metric: Literal['jaccard', 'cosine', 'euclidean']) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Generate a matrix with the distance between each pairs of lines using the metric provided</p>
<h1 id="arguments">Arguments</h1>
<ul>
<li>embeddings: np.ndarray, (n_lines, size_embedding), for each log line the embedding associated</li>
<li>metric: Literal["jaccard", "cosine", "euclidean"], the metric to use</li>
</ul>
<h1 id="returns">Returns</h1>
<ul>
<li>np.ndarray (n_lines, n_lines) the pairwise distance between the embeddings</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_distance_matrix(
    embeddings: np.ndarray,
    metric: Literal[&#34;jaccard&#34;, &#34;cosine&#34;, &#34;euclidean&#34;],
) -&gt; np.ndarray:
    &#34;&#34;&#34;Generate a matrix with the distance between each pairs of lines using the metric provided
    
    # Arguments
    - embeddings: np.ndarray, (n_lines, size_embedding), for each log line the embedding associated
    - metric: Literal[&#34;jaccard&#34;, &#34;cosine&#34;, &#34;euclidean&#34;], the metric to use
    
    # Returns
    - np.ndarray (n_lines, n_lines) the pairwise distance between the embeddings
    &#34;&#34;&#34;
    return skMetrics.pairwise_distances(embeddings, metric=metric)</code></pre>
</details>
</dd>
<dt id="dist.main.get_emb_dist_fn"><code class="name flex">
<span>def <span class="ident">get_emb_dist_fn</span></span>(<span>embedding_distance: Literal['cosine', 'euclidean']) ‑> Callable[[numpy.ndarray], numpy.ndarray]</span>
</code></dt>
<dd>
<div class="desc"><p>Get the function to generate the normalized (0-1) embeddings distances from the embeddings</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_emb_dist_fn(embedding_distance: EmbeddingDistanceType) -&gt; Callable[[np.ndarray], np.ndarray]:
    &#34;&#34;&#34;Get the function to generate the normalized (0-1) embeddings distances from the embeddings&#34;&#34;&#34;
    if embedding_distance == &#39;cosine&#39;:
        # in case of cosine distance that can take values between 0 and 2 we divide the result by 2 to come back between 0 and 1
        return lambda data: get_distance_matrix(data, metric=embedding_distance)/2
    elif embedding_distance == &#39;euclidean&#39;:
        # in case of euclidean distance that can take values unbouded we do a standard 0-1 normalization
        def fn_euclidean(data):
            d = get_distance_matrix(data, metric=embedding_distance)
            return (d-np.min(d))/(np.max(d)-np.min(d))
        return fn_euclidean
    else:
        raise ValueError(f&#34;Expecting embedding_distance to be among {&#39;,&#39;.join(get_args(EmbeddingDistanceType))}&#34;)</code></pre>
</details>
</dd>
<dt id="dist.main.get_embedder"><code class="name flex">
<span>def <span class="ident">get_embedder</span></span>(<span>embedder_type: Literal['llama-13b', 'tfidf']) ‑> Callable[[List[<a title="dist.main.LogData" href="#dist.main.LogData">LogData</a>]], Generator[<a title="dist.main.LogEmbeddingData" href="#dist.main.LogEmbeddingData">LogEmbeddingData</a>, None, None]]</span>
</code></dt>
<dd>
<div class="desc"><p>Get the function to generate the embeddings</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_embedder(embedder_type: EmbedderType) -&gt; Callable[[List[LogData]], Generator[LogEmbeddingData, None, None]]:
    &#34;&#34;&#34;Get the function to generate the embeddings&#34;&#34;&#34;
    if embedder_type == &#34;llama-13b&#34;:
        return get_embedder_fn(embedder_type, pooling_code=&#39;mean&#39;, model_name=&#39;meta-llama/Llama-2-13b-chat-hf&#39;,limit_tokens=1000)
    elif embedder_type == &#34;tfidf&#34;:
        return generate_tfidf_embeddings
    else:
        raise ValueError(f&#34;Expecting embedder_type to be among {&#39;,&#39;.join(get_args(EmbedderType))}&#34;)</code></pre>
</details>
</dd>
<dt id="dist.main.get_parser_fn"><code class="name flex">
<span>def <span class="ident">get_parser_fn</span></span>(<span>parser_type: Literal['drain']) ‑> Callable[[List[<a title="dist.main.LogData" href="#dist.main.LogData">LogData</a>]], List[<a title="dist.main.ParsingOutput" href="#dist.main.ParsingOutput">ParsingOutput</a>]]</span>
</code></dt>
<dd>
<div class="desc"><p>Get the function for the parser</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_parser_fn(
    parser_type: ParserTypes,
) -&gt; Callable[[List[LogData]], List[ParsingOutput]]:
    &#34;&#34;&#34;Get the function for the parser&#34;&#34;&#34;
    if parser_type == &#34;drain&#34;:
        return lambda events: get_parsing_drainparser(
            events,
            depth=5,
            similarity_threshold=0.4,
            max_children=3,
        )
    else:
        raise ValueError(f&#34;Expecting parser type to be among {&#39;,&#39;.join(get_args(ParserTypes))}&#34;)</code></pre>
</details>
</dd>
<dt id="dist.main.get_variable_matrix"><code class="name flex">
<span>def <span class="ident">get_variable_matrix</span></span>(<span>parsed_events: List[List[str]]) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Build the variable matrix from parsed logs</p>
<h1 id="arguments">Arguments</h1>
<ul>
<li>parsed_events: List[List[str]], for each log line the variables inside this line. !! warning !! can be empty if there are no variable for a line</li>
</ul>
<h1 id="returns">Returns</h1>
<ul>
<li>np.ndarray a one hot encoding indicating for each line if any of the variables inside the full log file is seen in this line</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_variable_matrix(
    parsed_events: List[List[str]],
) -&gt; np.ndarray:
    &#34;&#34;&#34;Build the variable matrix from parsed logs
    
    # Arguments
    - parsed_events: List[List[str]], for each log line the variables inside this line. !! warning !! can be empty if there are no variable for a line
    
    # Returns
    - np.ndarray a one hot encoding indicating for each line if any of the variables inside the full log file is seen in this line
    &#34;&#34;&#34;
    binarizer = skPrepro.MultiLabelBinarizer(sparse_output=False)
    matrix_variables = binarizer.fit_transform(
        parsed_events
    )
    if matrix_variables.shape[0] == 0:
        raise EmptyLog(&#34;No logs in the logs provided&#34;, logs=parsed_events)  # type: ignore
    if matrix_variables.shape[1] == 0:
        raise NoVariable(&#34;No variables in the logs provided&#34;, logs=parsed_events)  # type: ignore
    return matrix_variables.astype(bool)  # type: ignore</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="dist.main.ClusteringAlgorithmOutput"><code class="flex name class">
<span>class <span class="ident">ClusteringAlgorithmOutput</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>dict() -&gt; new empty dictionary
dict(mapping) -&gt; new dictionary initialized from a mapping object's
(key, value) pairs
dict(iterable) -&gt; new dictionary initialized as if via:
d = {}
for k, v in iterable:
d[k] = v
dict(**kwargs) -&gt; new dictionary initialized with the name=value pairs
in the keyword argument list.
For example:
dict(one=1, two=2)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ClusteringAlgorithmOutput(TypedDict):
    type: str
    clustering: Dict[int, int]
    hyperparameters: Dict[str, Any]</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.dict</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="dist.main.ClusteringAlgorithmOutput.clustering"><code class="name">var <span class="ident">clustering</span> : Dict[int, int]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dist.main.ClusteringAlgorithmOutput.hyperparameters"><code class="name">var <span class="ident">hyperparameters</span> : Dict[str, Any]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dist.main.ClusteringAlgorithmOutput.type"><code class="name">var <span class="ident">type</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="dist.main.ClusteringAlgorithmOutputKMedoid"><code class="flex name class">
<span>class <span class="ident">ClusteringAlgorithmOutputKMedoid</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>dict() -&gt; new empty dictionary
dict(mapping) -&gt; new dictionary initialized from a mapping object's
(key, value) pairs
dict(iterable) -&gt; new dictionary initialized as if via:
d = {}
for k, v in iterable:
d[k] = v
dict(**kwargs) -&gt; new dictionary initialized with the name=value pairs
in the keyword argument list.
For example:
dict(one=1, two=2)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ClusteringAlgorithmOutputKMedoid(ClusteringAlgorithmOutput):
    type: str
    clustering: Dict[int, int]
    hyperparameters: Dict[str, Any]
    score: float</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.dict</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="dist.main.ClusteringAlgorithmOutputKMedoid.clustering"><code class="name">var <span class="ident">clustering</span> : Dict[int, int]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dist.main.ClusteringAlgorithmOutputKMedoid.hyperparameters"><code class="name">var <span class="ident">hyperparameters</span> : Dict[str, Any]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dist.main.ClusteringAlgorithmOutputKMedoid.score"><code class="name">var <span class="ident">score</span> : float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dist.main.ClusteringAlgorithmOutputKMedoid.type"><code class="name">var <span class="ident">type</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="dist.main.EmptyLog"><code class="flex name class">
<span>class <span class="ident">EmptyLog</span></span>
<span>(</span><span>msg, logs: List[Dict[str, Any]])</span>
</code></dt>
<dd>
<div class="desc"><p>Exception when no logs is found</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class EmptyLog(LineTrackerException):
    &#34;&#34;&#34;Exception when no logs is found&#34;&#34;&#34;

    def __init__(self, msg, logs: List[Dict[str, Any]]):
        super().__init__(msg)
        self.logs = logs</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="dist.main.LineTrackerException" href="#dist.main.LineTrackerException">LineTrackerException</a></li>
<li>builtins.Exception</li>
<li>builtins.BaseException</li>
</ul>
</dd>
<dt id="dist.main.LineTrackerException"><code class="flex name class">
<span>class <span class="ident">LineTrackerException</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Base class for the LineTracker exceptions</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class LineTrackerException(Exception):
    &#34;&#34;&#34;Base class for the LineTracker exceptions&#34;&#34;&#34;</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.Exception</li>
<li>builtins.BaseException</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="dist.main.EmptyLog" href="#dist.main.EmptyLog">EmptyLog</a></li>
<li><a title="dist.main.NoVariable" href="#dist.main.NoVariable">NoVariable</a></li>
</ul>
</dd>
<dt id="dist.main.LogData"><code class="flex name class">
<span>class <span class="ident">LogData</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><ul>
<li>event_id: str, Unique string per bug_id</li>
<li>text: str, Text of the error</li>
<li>line_num: str, Plan id of the log: with log_name constitute the build_log</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class LogData(TypedDict):
    &#34;&#34;&#34;
    - event_id: str, Unique string per bug_id
    - text: str, Text of the error
    - line_num: str, Plan id of the log: with log_name constitute the build_log
    &#34;&#34;&#34;

    event_id: str
    text: str
    line_num: str</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.dict</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="dist.main.LogData.event_id"><code class="name">var <span class="ident">event_id</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dist.main.LogData.line_num"><code class="name">var <span class="ident">line_num</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dist.main.LogData.text"><code class="name">var <span class="ident">text</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="dist.main.LogEmbeddingData"><code class="flex name class">
<span>class <span class="ident">LogEmbeddingData</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><ul>
<li>event_id: str, Unique string per bug_id</li>
<li>text: str, the source text provided to the model to make the embedding</li>
<li>embedding: np.ndarray, the embedding generated by the model</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class LogEmbeddingData(TypedDict):
    &#34;&#34;&#34;
    - event_id: str, Unique string per bug_id
    - text: str, the source text provided to the model to make the embedding
    - embedding: np.ndarray, the embedding generated by the model
    &#34;&#34;&#34;

    event_id: str
    text: str
    embedding: np.ndarray</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.dict</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="dist.main.LogEmbeddingData.embedding"><code class="name">var <span class="ident">embedding</span> : numpy.ndarray</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dist.main.LogEmbeddingData.event_id"><code class="name">var <span class="ident">event_id</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dist.main.LogEmbeddingData.text"><code class="name">var <span class="ident">text</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="dist.main.NoVariable"><code class="flex name class">
<span>class <span class="ident">NoVariable</span></span>
<span>(</span><span>msg, logs: List[Dict[str, Any]])</span>
</code></dt>
<dd>
<div class="desc"><p>Exception when no variables are inside log lines</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class NoVariable(LineTrackerException):
    &#34;&#34;&#34;Exception when no variables are inside log lines&#34;&#34;&#34;

    def __init__(self, msg, logs: List[Dict[str, Any]]):
        super().__init__(msg)
        self.logs = logs</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="dist.main.LineTrackerException" href="#dist.main.LineTrackerException">LineTrackerException</a></li>
<li>builtins.Exception</li>
<li>builtins.BaseException</li>
</ul>
</dd>
<dt id="dist.main.ParsingOutput"><code class="flex name class">
<span>class <span class="ident">ParsingOutput</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><ul>
<li>event_id: str, Unique string per bug_id</li>
<li>template: str, the template used in this event</li>
<li>variables: List[str], the variables in this event</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ParsingOutput(TypedDict):
    &#34;&#34;&#34;
    - event_id: str, Unique string per bug_id
    - template: str, the template used in this event
    - variables: List[str], the variables in this event
    &#34;&#34;&#34;

    event_id: str
    template: str
    variables: List[str]</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.dict</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="dist.main.ParsingOutput.event_id"><code class="name">var <span class="ident">event_id</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dist.main.ParsingOutput.template"><code class="name">var <span class="ident">template</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dist.main.ParsingOutput.variables"><code class="name">var <span class="ident">variables</span> : List[str]</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="dist.main.TripletCoef"><code class="flex name class">
<span>class <span class="ident">TripletCoef</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><ul>
<li>coef_variables_matrix: coefficient for the matrix distances</li>
<li>coef_embeddings_matrix: coefficient for the embeddings distances</li>
<li>coef_count_matrix: coefficient for the count of line distances</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class TripletCoef(TypedDict):
    &#34;&#34;&#34;
    - coef_variables_matrix: coefficient for the matrix distances
    - coef_embeddings_matrix: coefficient for the embeddings distances
    - coef_count_matrix: coefficient for the count of line distances
    &#34;&#34;&#34;

    coef_variables_matrix: float
    coef_embeddings_matrix: float
    coef_count_matrix: float</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.dict</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="dist.main.TripletCoef.coef_count_matrix"><code class="name">var <span class="ident">coef_count_matrix</span> : float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dist.main.TripletCoef.coef_embeddings_matrix"><code class="name">var <span class="ident">coef_embeddings_matrix</span> : float</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dist.main.TripletCoef.coef_variables_matrix"><code class="name">var <span class="ident">coef_variables_matrix</span> : float</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="dist.main.TripletMatrix"><code class="flex name class">
<span>class <span class="ident">TripletMatrix</span></span>
<span>(</span><span>*args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><ul>
<li>variables_matrix: np.ndarray, matrix distances</li>
<li>embeddings_matrix: np.ndarray, embeddings distances</li>
<li>count_matrix: np.ndarray, count of line distances</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class TripletMatrix(TypedDict):
    &#34;&#34;&#34;
    - variables_matrix: np.ndarray, matrix distances
    - embeddings_matrix: np.ndarray, embeddings distances
    - count_matrix: np.ndarray, count of line distances
    &#34;&#34;&#34;

    variables_matrix: np.ndarray
    embeddings_matrix: np.ndarray
    count_matrix: np.ndarray</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.dict</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="dist.main.TripletMatrix.count_matrix"><code class="name">var <span class="ident">count_matrix</span> : numpy.ndarray</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dist.main.TripletMatrix.embeddings_matrix"><code class="name">var <span class="ident">embeddings_matrix</span> : numpy.ndarray</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="dist.main.TripletMatrix.variables_matrix"><code class="name">var <span class="ident">variables_matrix</span> : numpy.ndarray</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="dist" href="index.html">dist</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="dist.main.execute_full_pipeline" href="#dist.main.execute_full_pipeline">execute_full_pipeline</a></code></li>
<li><code><a title="dist.main.get_clustering_fn" href="#dist.main.get_clustering_fn">get_clustering_fn</a></code></li>
<li><code><a title="dist.main.get_distance_matrix" href="#dist.main.get_distance_matrix">get_distance_matrix</a></code></li>
<li><code><a title="dist.main.get_emb_dist_fn" href="#dist.main.get_emb_dist_fn">get_emb_dist_fn</a></code></li>
<li><code><a title="dist.main.get_embedder" href="#dist.main.get_embedder">get_embedder</a></code></li>
<li><code><a title="dist.main.get_parser_fn" href="#dist.main.get_parser_fn">get_parser_fn</a></code></li>
<li><code><a title="dist.main.get_variable_matrix" href="#dist.main.get_variable_matrix">get_variable_matrix</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="dist.main.ClusteringAlgorithmOutput" href="#dist.main.ClusteringAlgorithmOutput">ClusteringAlgorithmOutput</a></code></h4>
<ul class="">
<li><code><a title="dist.main.ClusteringAlgorithmOutput.clustering" href="#dist.main.ClusteringAlgorithmOutput.clustering">clustering</a></code></li>
<li><code><a title="dist.main.ClusteringAlgorithmOutput.hyperparameters" href="#dist.main.ClusteringAlgorithmOutput.hyperparameters">hyperparameters</a></code></li>
<li><code><a title="dist.main.ClusteringAlgorithmOutput.type" href="#dist.main.ClusteringAlgorithmOutput.type">type</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="dist.main.ClusteringAlgorithmOutputKMedoid" href="#dist.main.ClusteringAlgorithmOutputKMedoid">ClusteringAlgorithmOutputKMedoid</a></code></h4>
<ul class="">
<li><code><a title="dist.main.ClusteringAlgorithmOutputKMedoid.clustering" href="#dist.main.ClusteringAlgorithmOutputKMedoid.clustering">clustering</a></code></li>
<li><code><a title="dist.main.ClusteringAlgorithmOutputKMedoid.hyperparameters" href="#dist.main.ClusteringAlgorithmOutputKMedoid.hyperparameters">hyperparameters</a></code></li>
<li><code><a title="dist.main.ClusteringAlgorithmOutputKMedoid.score" href="#dist.main.ClusteringAlgorithmOutputKMedoid.score">score</a></code></li>
<li><code><a title="dist.main.ClusteringAlgorithmOutputKMedoid.type" href="#dist.main.ClusteringAlgorithmOutputKMedoid.type">type</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="dist.main.EmptyLog" href="#dist.main.EmptyLog">EmptyLog</a></code></h4>
</li>
<li>
<h4><code><a title="dist.main.LineTrackerException" href="#dist.main.LineTrackerException">LineTrackerException</a></code></h4>
</li>
<li>
<h4><code><a title="dist.main.LogData" href="#dist.main.LogData">LogData</a></code></h4>
<ul class="">
<li><code><a title="dist.main.LogData.event_id" href="#dist.main.LogData.event_id">event_id</a></code></li>
<li><code><a title="dist.main.LogData.line_num" href="#dist.main.LogData.line_num">line_num</a></code></li>
<li><code><a title="dist.main.LogData.text" href="#dist.main.LogData.text">text</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="dist.main.LogEmbeddingData" href="#dist.main.LogEmbeddingData">LogEmbeddingData</a></code></h4>
<ul class="">
<li><code><a title="dist.main.LogEmbeddingData.embedding" href="#dist.main.LogEmbeddingData.embedding">embedding</a></code></li>
<li><code><a title="dist.main.LogEmbeddingData.event_id" href="#dist.main.LogEmbeddingData.event_id">event_id</a></code></li>
<li><code><a title="dist.main.LogEmbeddingData.text" href="#dist.main.LogEmbeddingData.text">text</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="dist.main.NoVariable" href="#dist.main.NoVariable">NoVariable</a></code></h4>
</li>
<li>
<h4><code><a title="dist.main.ParsingOutput" href="#dist.main.ParsingOutput">ParsingOutput</a></code></h4>
<ul class="">
<li><code><a title="dist.main.ParsingOutput.event_id" href="#dist.main.ParsingOutput.event_id">event_id</a></code></li>
<li><code><a title="dist.main.ParsingOutput.template" href="#dist.main.ParsingOutput.template">template</a></code></li>
<li><code><a title="dist.main.ParsingOutput.variables" href="#dist.main.ParsingOutput.variables">variables</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="dist.main.TripletCoef" href="#dist.main.TripletCoef">TripletCoef</a></code></h4>
<ul class="">
<li><code><a title="dist.main.TripletCoef.coef_count_matrix" href="#dist.main.TripletCoef.coef_count_matrix">coef_count_matrix</a></code></li>
<li><code><a title="dist.main.TripletCoef.coef_embeddings_matrix" href="#dist.main.TripletCoef.coef_embeddings_matrix">coef_embeddings_matrix</a></code></li>
<li><code><a title="dist.main.TripletCoef.coef_variables_matrix" href="#dist.main.TripletCoef.coef_variables_matrix">coef_variables_matrix</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="dist.main.TripletMatrix" href="#dist.main.TripletMatrix">TripletMatrix</a></code></h4>
<ul class="">
<li><code><a title="dist.main.TripletMatrix.count_matrix" href="#dist.main.TripletMatrix.count_matrix">count_matrix</a></code></li>
<li><code><a title="dist.main.TripletMatrix.embeddings_matrix" href="#dist.main.TripletMatrix.embeddings_matrix">embeddings_matrix</a></code></li>
<li><code><a title="dist.main.TripletMatrix.variables_matrix" href="#dist.main.TripletMatrix.variables_matrix">variables_matrix</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>