{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transforma arquivos para modelagem geral de tópicos\n",
    "\n",
    "import re\n",
    "\n",
    "dataset = \"bgl\"\n",
    "file = open(\"ground_truths/\" + dataset + \".txt\", \"r\")\n",
    "LINE_PATTERN = \"#[0-9]+#\"\n",
    "SUMMARY_PATTERN = \"#summary:#\"\n",
    "line_file = []\n",
    "summary_file = []\n",
    "line_match = True\n",
    "summary_match = True\n",
    "line_count = 0\n",
    "\n",
    "for line in file:\n",
    "\n",
    "        if len(line) == 1:                  \n",
    "            summary_match = False\n",
    "            line_match = False\n",
    "            continue\n",
    "        elif re.match(LINE_PATTERN, line):            \n",
    "            line_match = True\n",
    "            continue\n",
    "        elif re.match(SUMMARY_PATTERN, line):\n",
    "            summary_match = True\n",
    "            continue\n",
    "        elif (line_match):\n",
    "            line_file.append(line)\n",
    "            line_count += 1\n",
    "            continue\n",
    "        elif (summary_match):\n",
    "            for elem in range(line_count):                \n",
    "                summary_file.append(line.rstrip() + '\\n')\n",
    "            line_count = 0   \n",
    "            continue\n",
    "\n",
    "with open (\"ground_truths/\" + dataset + \"_lines.txt\", \"w\") as f:\n",
    "     for line in line_file:\n",
    "          f.write(f\"{line}\")\n",
    "\n",
    "with open (\"ground_truths/\" + dataset + \"_summaries.txt\", \"w\") as f:\n",
    "     for line in summary_file:\n",
    "          f.write(f\"{line}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting Drain Parsing ===\n",
      "c:\\Users\\vbert\\OneDrive\\DOUTORADO Poly Mtl\\Projeto\\CSL\\CSL-1\\ground_truths/\n",
      "Parsing file: c:\\Users\\vbert\\OneDrive\\DOUTORADO Poly Mtl\\Projeto\\CSL\\CSL-1\\ground_truths/bgl_lines.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing Progress:   0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing Progress: 100%|██████████| 2000/2000 [00:00<00:00, 14778.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing done. [Time taken: 0:00:00.286296]\n"
     ]
    }
   ],
   "source": [
    "## Transforma arquivos para modelagem local de tópicos, parseando antes\n",
    "\n",
    "## Drain parameters\n",
    "\n",
    "import DrainMethod\n",
    "import os\n",
    "\n",
    "## Step 1 - Log Parsing Using Drain\n",
    "\n",
    "input_dir = os.path.join(os.getcwd(), \"ground_truths/\") # The input directory of raw logs\n",
    "log_format = '<Content>' # Format of the file, if there are different fields\n",
    "output_dir = input_dir  # The output directory of parsing results\n",
    "logName = dataset + \"_lines.txt\" # Name of file to be parsed\n",
    "#file = open(\"ground_truths/\" + dataset + \"_lines.txt\", \"r\")\n",
    "regex = [] # Regex strings for Drain execution\n",
    "depth = 5 # Max depth of the parsing tree\n",
    "st = 0.6 # Drain similarity threshold\n",
    "dataset = \"bgl\"\n",
    "\n",
    "## Code\n",
    "\n",
    "print('\\n=== Starting Drain Parsing ===')\n",
    "indir = os.path.join(input_dir, os.path.dirname(logName))\n",
    "print(indir)\n",
    "log_file = os.path.basename(logName)\n",
    "\n",
    "parser = DrainMethod.LogParser(log_format=log_format, indir=indir, outdir=output_dir, rex=regex, depth=depth, st=st)\n",
    "parser.parse(log_file)\n",
    "\n",
    "parsedresult=os.path.join(output_dir, log_file + '_structured.csv')   \n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.corpora as corpora\n",
    "import pandas as pd\n",
    "import gensim\n",
    "\n",
    "csv = pd.read_csv(\"ground_truths/bgl_lines.txt_structured.csv\")\n",
    "content = csv[\"EventTemplate\"]\n",
    "num_topics = 10\n",
    "line_file = []\n",
    "line_set = []\n",
    "\n",
    "# Converts sentences to words\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        # deacc=True removes punctuations\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "\n",
    "for idx, line in enumerate(content):\n",
    "    line_set.append(line + '\\n')\n",
    "\n",
    "    if (idx % 20 == 19):\n",
    "        # Converts to words\n",
    "        data_words = list(sent_to_words(line_set))\n",
    "        # Creates dictionary\n",
    "        id2word = corpora.Dictionary(data_words)\n",
    "        # Creates corpora\n",
    "        corpus = [id2word.doc2bow(text) for text in data_words]\n",
    "        # Builds LDA model\n",
    "        lda_model = gensim.models.LdaMulticore(corpus=corpus,id2word=id2word,num_topics=num_topics)\n",
    "        # Gets word topics\n",
    "        x = lda_model.show_topics(num_topics=1, num_words=10,formatted=False)\n",
    "        topics_words = [(tp[0], [wd[0] for wd in tp[1]]) for tp in x]\n",
    "\n",
    "        #Below Code Prints Only Words \n",
    "        for topic,words in topics_words:\n",
    "            summary =  \" \".join(words)\n",
    "\n",
    "        #Appends summary to general line file\n",
    "        for num in range(20):\n",
    "            line_file.append(summary)\n",
    "\n",
    "## Writes external file with created topics\n",
    "with open (\"ground_truths/\" + dataset + \"_local_topics.txt\", \"w\") as f:\n",
    "     for line in line_file:\n",
    "          f.write(f\"{line}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
