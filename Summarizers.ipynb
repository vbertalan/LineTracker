{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thomas A. Anderson is a man living two lives.\n"
     ]
    }
   ],
   "source": [
    "## LexRankSummarizer\n",
    "\n",
    "from sumy.summarizers.lex_rank import LexRankSummarizer #We're choosing Lexrank, other algorithms are also built in\n",
    "from sumy.parsers.plaintext import PlaintextParser #We're choosing a plaintext parser here, other parsers available for HTML etc.\n",
    "from sumy.nlp.tokenizers import Tokenizer \n",
    "\n",
    "text = (\n",
    "    \"Thomas A. Anderson is a man living two lives. By day he is an \"\n",
    "    \"average computer programmer and by night a hacker known as \"\n",
    "    \"Neo. Neo has always questioned his reality, but the truth is \"\n",
    "    \"far beyond his imagination. Neo finds himself targeted by the \"\n",
    "    \"police when he is contacted by Morpheus, a legendary computer \"\n",
    "    \"hacker branded a terrorist by the government. Morpheus awakens \"\n",
    "    \"Neo to the real world, a ravaged wasteland where most of \"\n",
    "    \"humanity have been captured by a race of machines that live \"\n",
    "    \"off of the humans' body heat and electrochemical energy and \"\n",
    "    \"who imprison their minds within an artificial reality known as \"\n",
    "    \"the Matrix. As a rebel against the machines, Neo must return to \"\n",
    "    \"the Matrix and confront the agents: super-powerful computer \"\n",
    "    \"programs devoted to snuffing out Neo and the entire human \"\n",
    "    \"rebellion. \"\n",
    ")\n",
    "\n",
    "#file = \"plain_text.txt\" #name of the plain-text file\n",
    "#parser = PlaintextParser.from_file(file, Tokenizer(\"english\"))\n",
    "\n",
    "# def LexRank(text, max):\n",
    "#     parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
    "#     summarizer = LexRankSummarizer()\n",
    "#     summary = summarizer(parser.document, 1) #Summarize the document with 5 sentences\n",
    "#     #for sentence in summary:\n",
    "#     #    result = sentence\n",
    "#     #    #print (sentence)\n",
    "#     result = str(summary[0]).split()\n",
    "#     result = result[0:max]\n",
    "#     result = ' '.join(result)\n",
    "#     return (result)\n",
    "\n",
    "def LexRank(text, max):\n",
    "    parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
    "    summarizer = LexRankSummarizer()\n",
    "    summary = summarizer(parser.document, 1)\n",
    "    result = str(summary[0]).split()\n",
    "    result = result[0:max]\n",
    "    result = ' '.join(result)\n",
    "    return (result)\n",
    "\n",
    "print(LexRank(text,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By day he is an average computer programmer and by night a hacker known as Neo.\n",
      "By day he is an average computer programmer and by\n"
     ]
    }
   ],
   "source": [
    "## Luhn Summarizer\n",
    "\n",
    "from sumy.summarizers.luhn import LuhnSummarizer\n",
    "summarizer_1 = LuhnSummarizer()\n",
    "summary_1 =summarizer_1(parser.document,1)\n",
    "\n",
    "for sentence in summary_1:\n",
    "    print(sentence)\n",
    "\n",
    "def Luhn(text, max):\n",
    "    parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
    "    summarizer_1 = LuhnSummarizer()\n",
    "    summary = summarizer_1(parser.document, 1)\n",
    "    result = str(summary[0]).split()\n",
    "    result = result[0:max]\n",
    "    result = ' '.join(result)\n",
    "    return (result)\n",
    "\n",
    "print(Luhn(text,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Morpheus awakens Neo to the real world, a ravaged wasteland where most of humanity have been captured by a race of machines that live off of the humans' body heat and electrochemical energy and who imprison their minds within an artificial reality known as the Matrix.\n"
     ]
    }
   ],
   "source": [
    "## LSA Summarizer\n",
    "\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "summarizer_2 = LsaSummarizer()\n",
    "summary_2 =summarizer_2(parser.document,1)\n",
    "\n",
    "for sentence in summary_2:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Morpheus awakens Neo to the real world, a ravaged wasteland where most of humanity have been captured by a race of machines that live off of the humans' body heat and electrochemical energy and who imprison their minds within an artificial reality known as the Matrix.\n"
     ]
    }
   ],
   "source": [
    "## TextRank Summarizer\n",
    "\n",
    "from sumy.summarizers.text_rank import TextRankSummarizer\n",
    "summarizer_3 = TextRankSummarizer()\n",
    "summary_3 =summarizer_3(parser.document,1)\n",
    "for sentence in summary_3:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vbert\\anaconda3\\Lib\\site-packages\\transformers\\models\\t5\\tokenization_t5_fast.py:158: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\vbert\\anaconda3\\Lib\\site-packages\\transformers\\models\\auto\\modeling_auto.py:1479: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> computer programmer and hacker is awaken\n"
     ]
    }
   ],
   "source": [
    "## Google T5 Summarizer\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('t5-base')\n",
    "model = AutoModelWithLMHead.from_pretrained('t5-base', return_dict=True)\n",
    "\n",
    "inputs = tokenizer.encode(\"summarize: \" + text,return_tensors='pt',max_length=512,truncation=True)\n",
    "\n",
    "summary_ids = model.generate(inputs, max_length=10)\n",
    "\n",
    "summary = tokenizer.decode(summary_ids[0])\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vbert\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "c:\\Users\\vbert\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thomas A. Anderson is a man living two lives. As a rebel against the machines, Neo must return to the Matrix and confront the agents: super-powerful computer programs devoted to snuffing out Neo and the entire human rebellion.\n"
     ]
    }
   ],
   "source": [
    "## BERT Summarizer\n",
    "\n",
    "from summarizer import Summarizer\n",
    "\n",
    "text = (\n",
    "    \"Thomas A. Anderson is a man living two lives. By day he is an \"\n",
    "    \"average computer programmer and by night a hacker known as \"\n",
    "    \"Neo. Neo has always questioned his reality, but the truth is \"\n",
    "    \"far beyond his imagination. Neo finds himself targeted by the \"\n",
    "    \"police when he is contacted by Morpheus, a legendary computer \"\n",
    "    \"hacker branded a terrorist by the government. Morpheus awakens \"\n",
    "    \"Neo to the real world, a ravaged wasteland where most of \"\n",
    "    \"humanity have been captured by a race of machines that live \"\n",
    "    \"off of the humans' body heat and electrochemical energy and \"\n",
    "    \"who imprison their minds within an artificial reality known as \"\n",
    "    \"the Matrix. As a rebel against the machines, Neo must return to \"\n",
    "    \"the Matrix and confront the agents: super-powerful computer \"\n",
    "    \"programs devoted to snuffing out Neo and the entire human \"\n",
    "    \"rebellion. \"\n",
    ")\n",
    "\n",
    "model = Summarizer()\n",
    "\n",
    "result = model(text, num_sentences=2)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thomas A. Anderson is a man living two lives.\n"
     ]
    }
   ],
   "source": [
    "## SBERT Summarizer\n",
    "\n",
    "from summarizer.sbert import SBertSummarizer\n",
    "\n",
    "text = (\n",
    "    \"Thomas A. Anderson is a man living two lives. By day he is an \"\n",
    "    \"average computer programmer and by night a hacker known as \"\n",
    "    \"Neo. Neo has always questioned his reality, but the truth is \"\n",
    "    \"far beyond his imagination. Neo finds himself targeted by the \"\n",
    "    \"police when he is contacted by Morpheus, a legendary computer \"\n",
    "    \"hacker branded a terrorist by the government. Morpheus awakens \"\n",
    "    \"Neo to the real world, a ravaged wasteland where most of \"\n",
    "    \"humanity have been captured by a race of machines that live \"\n",
    "    \"off of the humans' body heat and electrochemical energy and \"\n",
    "    \"who imprison their minds within an artificial reality known as \"\n",
    "    \"the Matrix. As a rebel against the machines, Neo must return to \"\n",
    "    \"the Matrix and confront the agents: super-powerful computer \"\n",
    "    \"programs devoted to snuffing out Neo and the entire human \"\n",
    "    \"rebellion. \"\n",
    ")\n",
    "\n",
    "model = SBertSummarizer('paraphrase-MiniLM-L6-v2')\n",
    "result = model(text, num_sentences=1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vbert\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "c:\\Users\\vbert\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\Users\\vbert\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "c:\\Users\\vbert\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\Users\\vbert\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "c:\\Users\\vbert\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\Users\\vbert\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "c:\\Users\\vbert\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\Users\\vbert\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "c:\\Users\\vbert\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[481.9498291015625, 295.1265563964844, 202.5259246826172, 124.87324523925781, 51.752540588378906]\n"
     ]
    }
   ],
   "source": [
    "## Calculating Elbow\n",
    "\n",
    "from summarizer import Summarizer\n",
    "\n",
    "text = (\n",
    "    \"Thomas A. Anderson is a man living two lives. By day he is an \"\n",
    "    \"average computer programmer and by night a hacker known as \"\n",
    "    \"Neo. Neo has always questioned his reality, but the truth is \"\n",
    "    \"far beyond his imagination. Neo finds himself targeted by the \"\n",
    "    \"police when he is contacted by Morpheus, a legendary computer \"\n",
    "    \"hacker branded a terrorist by the government. Morpheus awakens \"\n",
    "    \"Neo to the real world, a ravaged wasteland where most of \"\n",
    "    \"humanity have been captured by a race of machines that live \"\n",
    "    \"off of the humans' body heat and electrochemical energy and \"\n",
    "    \"who imprison their minds within an artificial reality known as \"\n",
    "    \"the Matrix. As a rebel against the machines, Neo must return to \"\n",
    "    \"the Matrix and confront the agents: super-powerful computer \"\n",
    "    \"programs devoted to snuffing out Neo and the entire human \"\n",
    "    \"rebellion. \"\n",
    ")\n",
    "model = Summarizer()\n",
    "res = model.calculate_elbow(text, k_max=10)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vbert\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "c:\\Users\\vbert\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\Users\\vbert\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "c:\\Users\\vbert\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\Users\\vbert\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "c:\\Users\\vbert\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\Users\\vbert\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "c:\\Users\\vbert\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\Users\\vbert\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "c:\\Users\\vbert\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "## Calculate optimal number of sentences\n",
    "\n",
    "from summarizer import Summarizer\n",
    "\n",
    "text = (\n",
    "    \"Thomas A. Anderson is a man living two lives. By day he is an \"\n",
    "    \"average computer programmer and by night a hacker known as \"\n",
    "    \"Neo. Neo has always questioned his reality, but the truth is \"\n",
    "    \"far beyond his imagination. Neo finds himself targeted by the \"\n",
    "    \"police when he is contacted by Morpheus, a legendary computer \"\n",
    "    \"hacker branded a terrorist by the government. Morpheus awakens \"\n",
    "    \"Neo to the real world, a ravaged wasteland where most of \"\n",
    "    \"humanity have been captured by a race of machines that live \"\n",
    "    \"off of the humans' body heat and electrochemical energy and \"\n",
    "    \"who imprison their minds within an artificial reality known as \"\n",
    "    \"the Matrix. As a rebel against the machines, Neo must return to \"\n",
    "    \"the Matrix and confront the agents: super-powerful computer \"\n",
    "    \"programs devoted to snuffing out Neo and the entire human \"\n",
    "    \"rebellion. \"\n",
    ")\n",
    "model = Summarizer()\n",
    "res = model.calculate_optimal_k(text, k_max=10)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after function definition on line 58 (2274062423.py, line 61)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[98], line 61\u001b[1;36m\u001b[0m\n\u001b[1;33m    def SBert(text, max):\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after function definition on line 58\n"
     ]
    }
   ],
   "source": [
    "## LexRankSummarizer\n",
    "\n",
    "from sumy.summarizers.text_rank import TextRankSummarizer\n",
    "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.summarizers.luhn import LuhnSummarizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "from sumy.nlp.tokenizers import Tokenizer \n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
    "from summarizer import Summarizer\n",
    "import torch\n",
    "\n",
    "def LexRank(text, max):\n",
    "    parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
    "    summarizer = LexRankSummarizer()\n",
    "    summary = summarizer(parser.document, 1)\n",
    "    result = str(summary[0]).split()\n",
    "    result = result[0:max]\n",
    "    result = ' '.join(result)\n",
    "    return (result)\n",
    "\n",
    "def Luhn(text, max):\n",
    "    parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
    "    summarizer = LuhnSummarizer()\n",
    "    summary = summarizer(parser.document, 1)\n",
    "    result = str(summary[0]).split()\n",
    "    result = result[0:max]\n",
    "    result = ' '.join(result)\n",
    "    return (result)\n",
    "\n",
    "def LSA(text, max):\n",
    "    parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
    "    summarizer = LsaSummarizer()\n",
    "    summary = summarizer(parser.document, 1)\n",
    "    result = str(summary[0]).split()\n",
    "    result = result[0:max]\n",
    "    result = ' '.join(result)\n",
    "    return (result)\n",
    "\n",
    "def TextRank(text, max):\n",
    "    parser = PlaintextParser.from_string(text, Tokenizer(\"english\"))\n",
    "    summarizer = TextRankSummarizer()\n",
    "    summary = summarizer(parser.document, 1)\n",
    "    result = str(summary[0]).split()\n",
    "    result = result[0:max]\n",
    "    result = ' '.join(result)\n",
    "    return (result)\n",
    "\n",
    "def T5(text, max):\n",
    "    tokenizer = AutoTokenizer.from_pretrained('t5-base')\n",
    "    model = AutoModelWithLMHead.from_pretrained('t5-base', return_dict=True)\n",
    "\n",
    "    inputs = tokenizer.encode(\"summarize: \" + text,return_tensors='pt',max_length=512,truncation=True)\n",
    "    summary_ids = model.generate(text, max_length=max)\n",
    "    summary = tokenizer.decode(summary_ids[0])\n",
    "    return (summary)\n",
    "\n",
    "def Bert(text, max):\n",
    "    model = Summarizer()\n",
    "    result = model(text, num_sentences=1)\n",
    "    print(result)\n",
    "\n",
    "def SBert(text, max):\n",
    "    ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RAS APP FATAL ciod : Error creating node map from\n",
      "['RAS APP FATAL ciod : Error creating node map from\n",
      "['RAS APP FATAL ciod : Error creating node map from\n",
      "['RAS APP FATAL ciod : Error creating node map from\n",
      "['RAS APP FATAL ciod : Error creating node map from\n",
      "['RAS APP FATAL ciod : Error creating node map from\n",
      "['RAS APP FATAL ciod : Error creating node map from\n",
      "['RAS APP FATAL ciod : Error creating node map from\n",
      "['RAS APP FATAL ciod : Error creating node map from\n",
      "['RAS APP FATAL ciod : Error creating node map from\n",
      "['RAS APP FATAL ciod : Error creating node map from\n",
      "['RAS APP FATAL ciod : Error creating node map from\n",
      "['RAS APP FATAL ciod : Error creating node map from\n",
      "['RAS APP FATAL ciod : Error creating node map from\n",
      "['RAS APP FATAL ciod : Error creating node map from\n",
      "['RAS APP FATAL ciod : Error creating node map from\n",
      "['RAS APP FATAL ciod : Error creating node map from\n",
      "['RAS APP FATAL ciod : Error creating node map from\n",
      "['RAS APP FATAL ciod : Error creating node map from\n",
      "['RAS APP FATAL ciod : Error creating node map from\n",
      "['RAS APP FATAL ciod : Error creating node map from\n",
      "['RAS APP FATAL ciod : Error creating node map from\n",
      "['RAS APP FATAL ciod : Error creating node map from\n",
      "['RAS APP FATAL ciod : Error creating node map from\n",
      "['RAS APP FATAL ciod : Error creating node map from\n",
      "['RAS APP FATAL ciod : Error creating node map from\n",
      "['RAS APP FATAL ciod : Error creating node map from\n",
      "['RAS APP FATAL ciod : Error creating node map from\n",
      "PGOOD IS NOT ASSERTED.\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY WARNING Node\n",
      "Clock Mode is Low.\n",
      "Clock Mode is Low.\n",
      "Clock Mode is Low.\n",
      "Clock Mode is Low.\n",
      "Clock Mode is Low.\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY WARNING Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY WARNING Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY WARNING Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY WARNING Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY WARNING Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY WARNING Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY ERROR Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY ERROR Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY ERROR Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY ERROR Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY ERROR Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY ERROR Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY ERROR Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY ERROR Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY ERROR Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY ERROR Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY ERROR Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY ERROR Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY ERROR Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY ERROR Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY ERROR Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY ERROR Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY ERROR Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY ERROR Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY ERROR Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY ERROR Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY ERROR Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY ERROR Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY ERROR Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY ERROR Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY ERROR Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY ERROR Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY ERROR Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY ERROR Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY ERROR Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY ERROR Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY ERROR Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY ERROR Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY ERROR Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY ERROR Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY ERROR Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY ERROR Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY ERROR Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY ERROR Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY ERROR Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY ERROR Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY ERROR Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY WARNING Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY WARNING Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY WARNING Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY WARNING Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY WARNING Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY WARNING Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY WARNING Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY WARNING Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY WARNING Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY WARNING Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY WARNING Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY WARNING Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY WARNING Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY WARNING Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY WARNING Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY WARNING Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY WARNING Node\n",
      "The 1.5 volt rail is OK.\\n', 'NULL DISCOVERY WARNING Node\n"
     ]
    }
   ],
   "source": [
    "## Tests summarizers against the ground truth\n",
    "\n",
    "import gensim.corpora as corpora\n",
    "import pandas as pd\n",
    "import gensim\n",
    "\n",
    "csv = pd.read_csv(\"ground_truths/bgl_lines.txt_structured.csv\")\n",
    "content = csv[\"EventTemplate\"]\n",
    "num_topics = 10\n",
    "dataset = \"bgl\"\n",
    "line_file = []\n",
    "line_set = []\n",
    "\n",
    "# Converts sentences to words\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        # deacc=True removes punctuations\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "\n",
    "for idx, line in enumerate(content):\n",
    "    line_set.append(line + '\\n')\n",
    "\n",
    "    if (idx % 20 == 19):\n",
    "        summary = LexRank(line_set,10)\n",
    "        print(summary)\n",
    "\n",
    "        #Appends summary to general line file\n",
    "        for num in range(20):\n",
    "            line_file.append(summary)\n",
    "\n",
    "## Writes external file with created topics\n",
    "with open (\"ground_truths/\" + dataset + \"__lexrank.txt\", \"w\") as f:\n",
    "     for line in line_file:\n",
    "          f.write(f\"{line}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
