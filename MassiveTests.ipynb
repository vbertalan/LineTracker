{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## LIBRARIES ################################## \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import pairwise_distances \n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from bertopic import BERTopic\n",
    "from ast import literal_eval\n",
    "from pathlib import Path\n",
    "from umap import UMAP\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex as re\n",
    "import DrainMethod\n",
    "import contextlib\n",
    "import hdbscan\n",
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "\n",
    "############################## AUXILIARY METHODS ############################## \n",
    "\n",
    "# Code for reading HuggingFace token\n",
    "\n",
    "def get_huggingface_token():\n",
    "    f = open(\"huggingface_token.txt\", \"r\")\n",
    "    return (f.read())\n",
    "\n",
    "# Calls conversion from data to dataframe\n",
    "def load_data():\n",
    "    headers, regex = generate_logformat_regex(log_format)\n",
    "    return log_to_dataframe(os.path.join(indir, logName), regex, headers, log_format)\n",
    "\n",
    "# Preprocesses dataframe with regexes, if necessary - more preprocessing to add\n",
    "def preprocess_df(df_log):\n",
    "    for idx, content in df_log[\"Content\"].items():\n",
    "        for currentRex in regex:\n",
    "            df_log.at[idx,'Content'] = re.sub(currentRex, '<*>', content)\n",
    "    return df_log\n",
    "\n",
    "# Function to generate regular expression to split log messages\n",
    "def generate_logformat_regex(log_format):\n",
    "    headers = []\n",
    "    splitters = re.split(r'(<[^<>]+>)', log_format)\n",
    "    regex = ''\n",
    "    for k in range(len(splitters)):\n",
    "        if k % 2 == 0:\n",
    "            splitter = re.sub(' +', '\\\\\\s+', splitters[k])\n",
    "            regex += splitter\n",
    "        else:\n",
    "            header = splitters[k].strip('<').strip('>')\n",
    "            regex += f'(?P<{header}>.*?)'\n",
    "            headers.append(header)\n",
    "    regex = re.compile('^' + regex + '$')\n",
    "    return headers, regex\n",
    "\n",
    "# Function to transform log file to dataframe \n",
    "def log_to_dataframe(log_file, regex, headers, logformat):\n",
    "    log_messages = []\n",
    "    linecount = 0\n",
    "    with open(log_file, 'r') as fin:\n",
    "        for line in fin.readlines():\n",
    "            with contextlib.suppress(Exception):\n",
    "                match = regex.search(line.strip())\n",
    "                message = [match.group(header) for header in headers]\n",
    "                log_messages.append(message)\n",
    "                linecount += 1\n",
    "    logdf = pd.DataFrame(log_messages, columns=headers)\n",
    "    logdf.insert(0, 'LineId', None)\n",
    "    logdf['LineId'] = [i + 1 for i in range(linecount)]\n",
    "    return logdf\n",
    "\n",
    "# Transforms the dataset, creating raw vector file\n",
    "def transform_dataset(raw_content):\n",
    "    \n",
    "    path_to_file = os.path.join(vector_dir, logName + '_vectors_TFIDF.vec')\n",
    "    path = Path(path_to_file)\n",
    "    vectors_tfidf = []\n",
    "\n",
    "    # if (path.is_file()):\n",
    "    #     vectors_tfidf = pickle.load(open(path_to_file, 'rb'))\n",
    "    # else:\n",
    "    #     # Using TFIDF Vectorizer \n",
    "    #     print(\"Iniciando encode\")\n",
    "    #     tr_idf_model  = TfidfVectorizer()\n",
    "    #     vectors_tfidf = tr_idf_model.fit_transform(raw_content)\n",
    "    #     pickle.dump(vectors_tfidf, open(path_to_file, 'wb'))\n",
    "    \n",
    "    # Using TFIDF Vectorizer \n",
    "    tr_idf_model  = TfidfVectorizer()\n",
    "    vectors_tfidf = tr_idf_model.fit_transform(raw_content)\n",
    "    pickle.dump(vectors_tfidf, open(path_to_file, 'wb'))\n",
    "\n",
    "    return vectors_tfidf\n",
    "\n",
    "def creates_lists(clusterer):\n",
    "    ## General Parameters\n",
    "\n",
    "    cluster_idxs = []\n",
    "    cluster_lines = []\n",
    "    output_dir = os.path.join(os.getcwd(), \"results\")  # The output directory of parsing results\n",
    "    output_csv = os.path.join(output_dir, log_file + '_structured.csv') \n",
    "\n",
    "    ## Code\n",
    "\n",
    "    # Reads parameters list\n",
    "    full_df = pd.read_csv(output_csv)\n",
    "    elem_df = full_df[\"EventTemplate\"]\n",
    "\n",
    "    # Creates blank lists\n",
    "    for elem in range (clusterer.labels_.max()+1):\n",
    "        cluster_idxs.append([])\n",
    "        cluster_lines.append([])\n",
    "\n",
    "    # Populate the lists with cluster elements\n",
    "    for idx, elem in np.ndenumerate(clusterer.labels_):\n",
    "        if elem != -1:\n",
    "            cluster_idxs[elem].append(idx[0])\n",
    "            cluster_lines[elem].append(elem_df[idx[0]])\n",
    "        \n",
    "    return (cluster_idxs, cluster_lines)\n",
    "\n",
    "################################# MAIN METHODS ################################ \n",
    "\n",
    "# Code for reading HuggingFace token\n",
    "\n",
    "def get_huggingface_token():\n",
    "    f = open(\"huggingface_token.txt\", \"r\")\n",
    "    return (f.read())\n",
    "\n",
    "# Parse logs using Drain\n",
    "\n",
    "def parse_logs(st=0.5, depth=5):\n",
    "    st = st # Drain similarity threshold\n",
    "    depth = depth # Max depth of the parsing tree\n",
    "\n",
    "    ## Code\n",
    "    parser = DrainMethod.LogParser(log_format=log_format, indir=indir, outdir=output_dir, rex=regex, depth=depth, st=st)\n",
    "    parser.parse(log_file)\n",
    "\n",
    "    parsedresult=os.path.join(output_dir, log_file + '_structured.csv')   \n",
    "\n",
    "# Creates embeddings for log file\n",
    "def transform(logName):\n",
    "    log_df = load_data()\n",
    "    log_df = preprocess_df(log_df)\n",
    "    return transform_dataset(log_df[\"Content\"])\n",
    "\n",
    "# Creates distance matrix, using Euclidean distance\n",
    "def create_distance_matrix(vector_df):\n",
    "    # Using Euclidean Distance between the rows of the TFIDF Matrix\n",
    "    tfidf_distance = pairwise_distances(vector_df, metric=\"euclidean\", n_jobs=-1)\n",
    "    #Normalizes Distance Matrix with Min-Max\n",
    "    min_val = np.min(tfidf_distance)\n",
    "    max_val = np.max(tfidf_distance)\n",
    "    tfidf_distance = (tfidf_distance - min_val) / (max_val - min_val)\n",
    "    return (tfidf_distance)\n",
    "\n",
    "# Creates variable matrix, using Jaccard distance\n",
    "def create_variable_matrix():\n",
    "    ## General Parameters\n",
    "    output_dir = os.path.join(os.getcwd(), \"results\")  # The output directory of parsing results\n",
    "    output_csv = os.path.join(output_dir, log_file + '_structured.csv') \n",
    "\n",
    "    ## Code\n",
    "    # Reads parameters list\n",
    "    full_df = pd.read_csv(output_csv)\n",
    "    var_df = full_df[\"ParameterList\"]\n",
    "\n",
    "    # Breaks the string into lists\n",
    "    for i, line in var_df.items():\n",
    "        var_df.at[i] = literal_eval(var_df.at[i])\n",
    "\n",
    "    # Transforms variable list to variable sparse matrix\n",
    "    mlb = MultiLabelBinarizer(sparse_output=True)\n",
    "    var_df = mlb.fit_transform(var_df)\n",
    "    var_distance = pairwise_distances(np.asarray(var_df.todense()), metric=\"jaccard\", n_jobs=-1)\n",
    "    return (var_distance)\n",
    "\n",
    "def creates_closeness_matrix(tfidf_distance):\n",
    "    # Creates Count Matrix using line numbers from log lines as the counter\n",
    "    count_list = []\n",
    "    n = len(tfidf_distance)\n",
    "    count_distance = np.zeros(shape=(n, n), dtype=int)\n",
    "    for i in range(n):\n",
    "            count_list.append(i)\n",
    "\n",
    "    # Using a Subtraction Distance using the line numbers as a Count Matrix\n",
    "    count_array = np.array(count_list)\n",
    "    for x in count_array:\n",
    "        for y in count_array:\n",
    "            count_distance[x,y] = abs(x-y)\n",
    "    # Normalizes Distance Matrix with Min-Max\n",
    "    min_val = np.min(count_distance)\n",
    "    max_val = np.max(count_distance)\n",
    "    count_distance = (count_distance - min_val) / (max_val - min_val)\n",
    "    return (count_distance)\n",
    "\n",
    "def saves_matrices(distance_mat, variable_mat, closeness_mat):\n",
    "    np.save(\"tfidf_distance_\" + logName + \".csv\", distance_mat)\n",
    "    np.save(\"var_distance_\" + logName + \".csv\", variable_mat)\n",
    "    np.save(\"count_distance_\" + logName + \".csv\", closeness_mat)\n",
    "\n",
    "def loads_matrices():\n",
    "    tfidf_distance = np.load(\"tfidf_distance_\" + logName + \".csv\")\n",
    "    count_distance = np.load(\"count_distance_\" + logName + \".csv\")\n",
    "    var_distance = np.load(\"var_distance_\" + logName + \".csv\") \n",
    "    return (tfidf_distance, count_distance, var_distance)\n",
    "\n",
    "def joins_matrices(tfidf_distance, var_distance, count_distance, alpha, beta, gamma):\n",
    "\n",
    "    if alpha+beta+gamma > 1:\n",
    "        raise Exception(\"Valores devem somar 1!\")\n",
    "\n",
    "    # New matrices, corrected by the weights\n",
    "    tfidf_distance_wtd = np.dot(alpha,tfidf_distance)\n",
    "    var_distance_wtd = np.dot(beta, var_distance)\n",
    "    count_distance_wtd = np.dot(gamma, count_distance)\n",
    "\n",
    "    # Sums remaining matrices\n",
    "    unified_matrix = np.asarray(tfidf_distance_wtd + var_distance_wtd + count_distance_wtd)\n",
    "    return (unified_matrix)\n",
    "\n",
    "def cluster_hdbscan(unified_matrix, cluster_size, mn_samples, cluster_selection_epsilon, alpha, leaf_size):\n",
    "    ## Clusters with HDBSCAN\n",
    "    clusterer = hdbscan.HDBSCAN(min_cluster_size=cluster_size,min_samples=mn_samples,metric='precomputed',\n",
    "                                cluster_selection_epsilon=cluster_selection_epsilon, alpha=alpha, leaf_size=leaf_size, \n",
    "                                allow_single_cluster=False,cluster_selection_method='eom',\n",
    "                                gen_min_span_tree=True)\n",
    "\n",
    "    clusterer.fit(unified_matrix)\n",
    "\n",
    "    ## Checks number of outliers\n",
    "    cont = np.count_nonzero(clusterer.labels_ == -1)\n",
    "    return (clusterer)\n",
    "\n",
    "def cluster_kmedoids(unified_matrix, cluster_num):\n",
    "    ## Clusters with cluster_kmedoids\n",
    "\n",
    "    clusterer = KMedoids(n_clusters=cluster_num)\n",
    "    clusterer.fit(unified_matrix)\n",
    "\n",
    "    ## Checks number of outliers\n",
    "    cont = np.count_nonzero(clusterer.labels_ == -1)\n",
    "    return (clusterer)\n",
    "\n",
    "def cluster_hdbscan_raw_data(data, cluster_size, mn_samples, cluster_selection_epsilon, alpha, leaf_size):\n",
    "    ## Clusters with HDBSCAN\n",
    "    clusterer = hdbscan.HDBSCAN(min_cluster_size=cluster_size,min_samples=mn_samples,metric='euclidean',\n",
    "                                cluster_selection_epsilon=cluster_selection_epsilon, alpha=alpha, leaf_size=leaf_size, \n",
    "                                allow_single_cluster=False,cluster_selection_method='eom',\n",
    "                                gen_min_span_tree=False)\n",
    "\n",
    "    clusterer.fit(data)\n",
    "\n",
    "    return (clusterer)\n",
    "\n",
    "def find_topics_bertopic(cluster_list, cluster_number, num_topics):\n",
    "        \n",
    "        umap_model = UMAP(init='random')\n",
    "        cluster_model = KMedoids(n_clusters = 1)\n",
    "        vectorizer_model = CountVectorizer(stop_words=\"english\")\n",
    "        sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\", token=get_huggingface_token())\n",
    "        topic_model = BERTopic(embedding_model=sentence_model, hdbscan_model=cluster_model, \n",
    "                               vectorizer_model=vectorizer_model, umap_model=umap_model, \n",
    "                               top_n_words=10)\n",
    "\n",
    "        #Applies BertTopic\n",
    "        topics, probs = topic_model.fit_transform(cluster_list[cluster_number])\n",
    "\n",
    "        #Gets summary of topics\n",
    "        topic_model.get_topic(0)\n",
    "        top_topic = topic_model.get_topic(0)\n",
    "        words = [i[0] for i in top_topic]\n",
    "        summary = ' '.join(words)\n",
    "\n",
    "        return (summary)\n",
    "\n",
    "def bertopic_previous_clustering(clusterer):\n",
    "    cluster_idxs, cluster_lines = creates_lists(clusterer)\n",
    "    cluster_topic = []\n",
    "    topic_summaries = []\n",
    "\n",
    "    ## Creates list of boolean values, representing summarized topics\n",
    "    for idx in range(clusterer.labels_.max()):\n",
    "        cluster_topic.append(None)\n",
    "\n",
    "    for i, elem in enumerate(clusterer.labels_):\n",
    "\n",
    "        ## For each cluster, maps topics, and defines them as the summary\n",
    "        if (cluster_topic[elem-1] == None):\n",
    "            summary = find_topics_bertopic(cluster_lines, elem-1, 1)\n",
    "            cluster_topic[elem-1] = summary\n",
    "        \n",
    "        if elem == -1:\n",
    "            topic_summaries.append(\"\")\n",
    "        else:\n",
    "            topic_summaries.append(cluster_topic[elem-1])\n",
    "        \n",
    "        target_file = \"ground_truths/\" + dataset + \"_bert_topics_tests.txt\"\n",
    "        with open (target_file, \"w\") as f:\n",
    "            for line in topic_summaries:\n",
    "                f.write(f\"{line}\\n\")\n",
    "\n",
    "    return topic_summaries\n",
    "\n",
    "def consider_previous_clustering():\n",
    "    ## Tests with BerTopic\n",
    "\n",
    "    from sklearn_extra.cluster import KMedoids\n",
    "    from bertopic import BERTopic\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import pickle\n",
    "    import os\n",
    "\n",
    "    #dataset = \"Zookeeper\"\n",
    "    target_file = \"ground_truths/\" + dataset + \"_lines.txt_structured.csv\"\n",
    "    csv = pd.read_csv(target_file)\n",
    "    content = csv[\"EventTemplate\"]\n",
    "    num_topics = 10\n",
    "    line_file = []\n",
    "    line_set = []\n",
    "\n",
    "    from bertopic.dimensionality import BaseCluster\n",
    "    from bertopic.dimensionality import BaseDimensionalityReduction\n",
    "\n",
    "    empty_cluster_model = BaseCluster()\n",
    "    empty_reduction_model = BaseDimensionalityReduction()\n",
    "    topic_model = BERTopic(hdbscan_model=empty_cluster_model, umap_model=empty_reduction_model)\n",
    "\n",
    "    for idx, line in enumerate(content):\n",
    "\n",
    "        line_set.append(line + '\\n')\n",
    "\n",
    "        if (idx % 20 == 19):\n",
    "    \n",
    "            #print(\"Chegamos ao idx {}\".format(idx))\n",
    "\n",
    "            #Applies BertTopic\n",
    "            topics, probs = topic_model.fit_transform(line_set)\n",
    "\n",
    "            #Gets summary of topics\n",
    "            topic_model.get_topic(0)\n",
    "            top_topic = topic_model.get_topic(0)\n",
    "            words = [i[0] for i in top_topic]\n",
    "            summary = ' '.join(words)\n",
    "\n",
    "            #Finds most representative line inside the cluster\n",
    "            best_line = find_best_line(line_set, summary)\n",
    "\n",
    "            for num in range(20):\n",
    "                line_file.append(summary)\n",
    "\n",
    "            line_set = []\n",
    "\n",
    "    ## Writes external file with created topics\n",
    "    with open (\"ground_truths/\" + dataset + \"_bert_topics.txt\", \"w\") as f:\n",
    "        for line in line_file:\n",
    "            f.write(f\"{line}\\n\")\n",
    "    \n",
    "    return line_file\n",
    "\n",
    "def create_new_bertopic_model():\n",
    "    lines = []\n",
    "    with open('ground_truths/' + dataset + '_lines.txt', 'r') as line_file:\n",
    "        for line in line_file:\n",
    "            lines.append(line)\n",
    "\n",
    "    umap_model = UMAP(init='random')\n",
    "    vectorizer_model = CountVectorizer(stop_words=\"english\")\n",
    "    sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\", token=get_huggingface_token())\n",
    "    topic_model = BERTopic(embedding_model=sentence_model, vectorizer_model=vectorizer_model, \n",
    "                        umap_model=umap_model, top_n_words=10)\n",
    "    topics, probs = topic_model.fit_transform(lines)\n",
    "    return (topic_model)\n",
    "\n",
    "def bertopic_new_clustering():\n",
    "\n",
    "    topic_model = create_new_bertopic_model()\n",
    "    cluster_topic = []\n",
    "    topic_summaries = []\n",
    "\n",
    "    for elem in topic_model.topics_:\n",
    "        \n",
    "        line_topic = topic_model.get_topic(elem)\n",
    "        words = [i[0] for i in line_topic]\n",
    "        summary = ' '.join(words)\n",
    "        topic_summaries.append(summary)\n",
    "\n",
    "\n",
    "    target_file = \"ground_truths/\" + dataset + \"_bert_topics_tests.txt\"\n",
    "\n",
    "    ## Writes external file with created topics\n",
    "    with open (target_file, \"w\") as f:\n",
    "        for line in topic_summaries:\n",
    "            f.write(f\"{line}\\n\")\n",
    "\n",
    "    return topic_summaries\n",
    "\n",
    "## Method to find the most representative line inside the cluster\n",
    "\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "\n",
    "tk = WhitespaceTokenizer()\n",
    "\n",
    "## raw_lines = list of lines inside LogSummary's cluster\n",
    "## word_list = list of tokens composed by the LDA/BertTopic\n",
    "def find_best_line(raw_lines, word_list):\n",
    "    closest_line = 0\n",
    "    similar_tokens = 0\n",
    "    max_similarity = 0\n",
    "    for idx, line in enumerate(raw_lines):\n",
    "        tokenized_line = tk.tokenize(line.lower())\n",
    "        for token in tokenized_line:\n",
    "            if token in word_list:\n",
    "                similar_tokens += 1\n",
    "        #print (\"Line {} has {} identical tokens\".format(idx, similar_tokens))\n",
    "        if similar_tokens > max_similarity:\n",
    "           max_similarity = similar_tokens\n",
    "           closest_line = idx\n",
    "        similar_tokens = 0\n",
    "    return (raw_lines[closest_line])        \n",
    "\n",
    "def calculates_metrics():\n",
    "    \n",
    "    from rouge import Rouge \n",
    "    rouge = Rouge()\n",
    "\n",
    "    count_precision = 0\n",
    "    count_recall = 0\n",
    "    count_f1 = 0\n",
    "    total_lines = 2000\n",
    "\n",
    "    target_file = \"_bert_topics_tests.txt\"\n",
    "\n",
    "    # Opens external files with ground truth summaries and created topics\n",
    "    with open('ground_truths/' + dataset + '_summaries.txt', 'r') as summaries, \\\n",
    "        open('ground_truths/' + dataset + target_file, 'r') as topics:\n",
    "        for line_summary, line_topic in zip(summaries, topics):\n",
    "            line_summary = line_summary[:-2]\n",
    "            line_summaries = line_summary.split(\";\")\n",
    "\n",
    "            for summary in line_summaries:\n",
    "                current_precision = 0\n",
    "                current_recall = 0\n",
    "                current_f1 = 0\n",
    "                metrics = rouge.get_scores(line_topic, summary)[0]['rouge-1']  \n",
    "\n",
    "                ## If the summary improves the f1 score, saves its metrics\n",
    "                if (current_f1 < metrics['f']):\n",
    "                    current_precision = metrics['p']\n",
    "                    current_recall = metrics['r']\n",
    "                    current_f1 = metrics['f']\n",
    "            \n",
    "            count_precision += current_precision\n",
    "            count_recall += current_recall        \n",
    "            count_f1 += current_f1\n",
    "\n",
    "    final_precision = count_precision/total_lines\n",
    "    final_recall = count_recall/total_lines\n",
    "    final_f1 = count_f1/total_lines\n",
    "\n",
    "    final = \"The precision is {}, the recall is {}, the f1 score is {}\".format(final_precision, final_recall, final_f1)\n",
    "    print (final)\n",
    "    return (final)\n",
    "\n",
    "## Testa usando o cluster antigo, e BerTopic neutro em clusterização e redução de dimensionalidade\n",
    "def tests_predefined_rawdata(drain_st, drain_depth, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size):\n",
    "    parameters = (\"Testing predefined clustering and raw data matrix with drain st {}, drain depth {}, min cluster size {}, min samples {}, cluster selection epsilon {}, alpha {}, and leaf size {}\".\n",
    "          format(drain_st, drain_depth, alpha, beta, gamma, min_cluster_size,min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size))\n",
    "    print(parameters)\n",
    "    parse_logs(drain_st, drain_depth)\n",
    "    consider_previous_clustering()\n",
    "    final = calculates_metrics()\n",
    "    return (final)\n",
    "\n",
    "## Testa usando nova clusterização do BerTopic, usando os raw files. \n",
    "def tests_hdbscan_rawdata(drain_st, drain_depth, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size):\n",
    "    parameters = (\"Testing predefined clustering and raw data matrix with drain st {}, drain depth {}, min cluster size {}, min samples {}, cluster selection epsilon {}, alpha {}, and leaf size {}\".\n",
    "          format(drain_st, drain_depth, alpha, beta, gamma, min_cluster_size,min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size))\n",
    "    print(parameters)\n",
    "    parse_logs(drain_st, drain_depth)\n",
    "    vector_df = transform(os.path.basename(logName))\n",
    "    find_topics_bertopic(vector_)\n",
    "    final = calculates_metrics()\n",
    "    return (final)\n",
    "\n",
    "\n",
    "\n",
    "## Tests BerTopic With Pre-Defined Clustering (Ground Truth) and Pre-Computed Matrix (Distance Matrix)\n",
    "def tests_predefined_precomputed(drain_st, drain_depth, alpha, beta, gamma, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size):\n",
    "    parameters = (\"Testing predefined clustering and precomputed matrix with drain st {}, drain depth {}, alpha {}, beta {}, gamma {}, min cluster size {}, min samples {}, cluster selection epsilon {}, alpha {}, and leaf size {}\".\n",
    "          format(drain_st, drain_depth, alpha, beta, gamma, min_cluster_size,min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size))\n",
    "    print(parameters)\n",
    "    parse_logs(drain_st, drain_depth)\n",
    "    vector_df = transform(os.path.basename(logName))\n",
    "    distance_matrix = create_distance_matrix(vector_df)\n",
    "    variable_matrix = create_variable_matrix()\n",
    "    closeness_matrix = creates_closeness_matrix(distance_matrix)\n",
    "    joint_matrix = joins_matrices(distance_matrix, variable_matrix, closeness_matrix, \n",
    "                                alpha, beta, gamma)\n",
    "    clustering = cluster_hdbscan(joint_matrix, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "    topic_summaries = bertopic_previous_clustering(clustering)\n",
    "\n",
    "    final = calculates_metrics()\n",
    "\n",
    "    return (final)\n",
    "\n",
    "\n",
    "## Tests BerTopic With Generated Clustering (Ground Truth) and Pre-Computed Matrix (Distance Matrix)\n",
    "def tests_generated_precomputed(drain_st, drain_depth, alpha, beta, gamma, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size):\n",
    "    parameters = (\"Testing generated clustering and precomputed matrix with drain st {}, drain depth {}, alpha {}, beta {}, gamma {}, min cluster size {}, min samples {}, cluster selection epsilon {}, alpha {}, and leaf size {}\".\n",
    "          format(drain_st, drain_depth, alpha, beta, gamma, min_cluster_size,min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size))\n",
    "    print(parameters)\n",
    "    vector_df = transform(os.path.basename(logName))\n",
    "    distance_matrix = create_distance_matrix(vector_df)\n",
    "    variable_matrix = create_variable_matrix()\n",
    "    closeness_matrix = creates_closeness_matrix(distance_matrix)\n",
    "    joint_matrix = joins_matrices(distance_matrix, variable_matrix, closeness_matrix, \n",
    "                                alpha, beta, gamma)\n",
    "    clustering = cluster_hdbscan(joint_matrix, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "    topic_summaries = bertopic_new_clustering()\n",
    "    final = calculates_metrics()\n",
    "    return (final)\n",
    "\n",
    "## Tests BerTopic With KMedoids\n",
    "def tests_generated_precomputed_kmedoids(drain_st, drain_depth, alpha, beta, gamma, cluster_num):\n",
    "    parameters = (\"Testing generated clustering and precomputed matrix with drain st {}, drain depth {}, alpha {}, beta {}, gamma {}, cluster_num {}\".\n",
    "          format(drain_st, drain_depth, alpha, beta, gamma, cluster_num))\n",
    "    print(parameters)\n",
    "    vector_df = transform(os.path.basename(logName))\n",
    "    distance_matrix = create_distance_matrix(vector_df)\n",
    "    variable_matrix = create_variable_matrix()\n",
    "    closeness_matrix = creates_closeness_matrix(distance_matrix)\n",
    "    joint_matrix = joins_matrices(distance_matrix, variable_matrix, closeness_matrix, \n",
    "                                alpha, beta, gamma)\n",
    "    clustering = cluster_kmedoids(joint_matrix, cluster_num)\n",
    "    topic_summaries = bertopic_new_clustering()\n",
    "    final = calculates_metrics()\n",
    "    return (final)\n",
    "\n",
    "## Tests BerTopic With Generated Clustering (Ground Truth) and Raw Data (Distance Matrix)\n",
    "def tests_generated_rawdata(drain_st, drain_depth, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size):\n",
    "    parameters = (\"Testing generated clustering and raw data matrix with drain st {}, drain depth {}, min cluster size {}, min samples {}, cluster selection epsilon {}, alpha clustering {}, and leaf size {}\".\n",
    "          format(drain_st, drain_depth, alpha, beta, gamma, min_cluster_size,min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size))\n",
    "    print(parameters)\n",
    "    vector_df = transform(os.path.basename(logName))\n",
    "    \n",
    "    clustering = cluster_hdbscan_raw_data(vector_df, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "    topic_summaries = bertopic_new_clustering()\n",
    "\n",
    "    final = calculates_metrics()\n",
    "    return (final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing predefined clustering and raw data matrix with drain st 0.5, drain depth 5, min cluster size 0.7, min samples 0.2, cluster selection epsilon 0.1, alpha 5, and leaf size 5\n",
      "The precision is 0.024242460317460357, the recall is 0.11371666666666658, the f1 score is 0.032262259662750356\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The precision is 0.024242460317460357, the recall is 0.11371666666666658, the f1 score is 0.032262259662750356'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## General parameters \n",
    "\n",
    "dataset = \"Proxifier\" # The name of the dataset being tested\n",
    "\n",
    "input_dir = os.path.join(os.getcwd(), \"ground_truths\") # The input directory of raw logs\n",
    "output_dir = os.path.join(os.getcwd(), \"results\")  # The output directory of parsing results\n",
    "vector_dir = os.path.join(os.getcwd(), \"vectors\")  # The vector directory of converted logs\n",
    "logName = dataset + '_lines.txt' # Name of file to be parsed\n",
    "log_format = '<Content>' # Format of the file, if there are different fields\n",
    "regex = [] # Regex strings for Drain execution\n",
    "indir = os.path.join(input_dir, os.path.dirname(logName))\n",
    "log_file = os.path.basename(logName)\n",
    "\n",
    "## Pipeline of methods\n",
    "\n",
    "drain_st = 0.5\n",
    "drain_depth = 5\n",
    "alpha = 0.7\n",
    "beta = 0.2\n",
    "gamma = 0.1\n",
    "min_cluster_size = 5\n",
    "min_samples = 5\n",
    "cluster_selection_epsilon = 0.0\n",
    "alpha_clustering = 1.0\n",
    "leaf_size = 40\n",
    "\n",
    "tests_predefined_rawdata(drain_st, drain_depth, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "tests_hdbscan_rawdata(drain_st, drain_depth, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Calculating Elbow\n",
    "\n",
    "def clusters_elbow (unified_matrix, dataset):\n",
    "    ## Clusters with cluster_kmedoids and silhouette score\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib\n",
    "\n",
    "    # Finding the optimal number of clusters using Elbow Method\n",
    "    wcss = []\n",
    "    max_clusters = 30\n",
    "    for i in range(1, max_clusters):\n",
    "        kmedoids = KMedoids(n_clusters=i, random_state=42)\n",
    "        kmedoids.fit(unified_matrix)\n",
    "        wcss.append(kmedoids.inertia_)\n",
    "    plt.gca().get_xaxis().get_major_formatter().set_useOffset(False)\n",
    "    plt.plot(range(1, max_clusters), wcss)\n",
    "    plt.title('Elbow Method for {}'.format(dataset))\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('WCSS')\n",
    "    plt.show()    \n",
    "\n",
    "def cluster_kmedoids_silhouette(unified_matrix, cluster_num):\n",
    "    ## Clusters with cluster_kmedoids and silhouette score\n",
    "    from sklearn.metrics import silhouette_score\n",
    "\n",
    "    clusterer = KMedoids(n_clusters=cluster_num, random_state=42)\n",
    "    #clusterer.fit(unified_matrix)\n",
    "    #print(\"Para {} clusters, o silhouette score é {}\".format(cluster_num,silhouette_score(unified_matrix, clusterer(unified_matrix))))\n",
    "    print(\"Para {} clusters, o silhouette score é {}\".format(cluster_num, silhouette_score(unified_matrix, clusterer.fit_predict(unified_matrix))))\n",
    "\n",
    "\n",
    "dataset = \"bgl\" # The name of the dataset being tested\n",
    "\n",
    "input_dir = os.path.join(os.getcwd(), \"ground_truths\") # The input directory of raw logs\n",
    "output_dir = os.path.join(os.getcwd(), \"results\")  # The output directory of parsing results\n",
    "vector_dir = os.path.join(os.getcwd(), \"vectors\")  # The vector directory of converted logs\n",
    "logName = dataset + '_lines.txt' # Name of file to be parsed\n",
    "log_format = '<Content>' # Format of the file, if there are different fields\n",
    "regex = [] # Regex strings for Drain execution\n",
    "indir = os.path.join(input_dir, os.path.dirname(logName))\n",
    "log_file = os.path.basename(logName)\n",
    "\n",
    "alpha = 0.3\n",
    "beta = 0.4\n",
    "gamma = 0.3\n",
    "vector_df = transform(os.path.basename(logName))\n",
    "distance_matrix = create_distance_matrix(vector_df)\n",
    "variable_matrix = create_variable_matrix()\n",
    "closeness_matrix = creates_closeness_matrix(distance_matrix)\n",
    "joint_matrix = joins_matrices(distance_matrix, variable_matrix, closeness_matrix, \n",
    "                                alpha, beta, gamma)\n",
    "clusters_elbow(joint_matrix, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para 2 clusters, o silhouette score é 0.555929128650499\n",
      "Para 3 clusters, o silhouette score é 0.07002702964854944\n",
      "Para 4 clusters, o silhouette score é 0.3672270239911916\n",
      "Para 5 clusters, o silhouette score é 0.3692600984353187\n",
      "Para 6 clusters, o silhouette score é 0.2919297517241138\n",
      "Para 7 clusters, o silhouette score é 0.2866827591642309\n",
      "Para 8 clusters, o silhouette score é 0.22216780396007346\n",
      "Para 9 clusters, o silhouette score é 0.24174398032298783\n",
      "Para 10 clusters, o silhouette score é 0.2512194626720594\n",
      "Para 11 clusters, o silhouette score é 0.25785586011449985\n",
      "Para 12 clusters, o silhouette score é 0.26648702266148466\n",
      "Para 13 clusters, o silhouette score é 0.2547833706596458\n",
      "Para 14 clusters, o silhouette score é 0.24928914065545654\n",
      "Para 15 clusters, o silhouette score é 0.24349399325216853\n",
      "Para 16 clusters, o silhouette score é 0.2292731640595482\n",
      "Para 17 clusters, o silhouette score é 0.2533668440231919\n",
      "Para 18 clusters, o silhouette score é 0.25367015793340175\n",
      "Para 19 clusters, o silhouette score é 0.2510090215341836\n",
      "Para 20 clusters, o silhouette score é 0.2664954827451621\n",
      "Para 21 clusters, o silhouette score é 0.2778888256303078\n",
      "Para 22 clusters, o silhouette score é 0.27652211403352195\n",
      "Para 23 clusters, o silhouette score é 0.2862624181951229\n",
      "Para 24 clusters, o silhouette score é 0.2895566867713505\n",
      "Para 25 clusters, o silhouette score é 0.2946443155175861\n",
      "Para 26 clusters, o silhouette score é 0.3091174264956375\n",
      "Para 27 clusters, o silhouette score é 0.2753674564332921\n",
      "Para 28 clusters, o silhouette score é 0.27518348900961426\n",
      "Para 29 clusters, o silhouette score é 0.2750436012043185\n"
     ]
    }
   ],
   "source": [
    "#cluster_kmedoids_silhouette(joint_matrix, 20)\n",
    "\n",
    "for i in range (2,30):\n",
    "    cluster_kmedoids_silhouette(joint_matrix, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing predefined clustering and raw data matrix with drain st 0.5, drain depth 5, min cluster size 0.7, min samples 0.2, cluster selection epsilon 0.1, alpha 5, and leaf size 5\n",
      "The precision is 0.024242460317460357, the recall is 0.11371666666666658, the f1 score is 0.032262259662750356\n",
      "*****\n",
      "Testing predefined clustering and precomputed matrix with drain st 0.5, drain depth 5, alpha 0.7, beta 0.2, gamma 0.1, min cluster size 5, min samples 5, cluster selection epsilon 0.0, alpha 1.0, and leaf size 40\n",
      "The precision is 0.01561309523809528, the recall is 0.08391666666666658, the f1 score is 0.021333423289262778\n",
      "Testing predefined clustering and precomputed matrix with drain st 0.5, drain depth 5, alpha 1, beta 0, gamma 0, min cluster size 5, min samples 5, cluster selection epsilon 0.0, alpha 1.0, and leaf size 40\n",
      "The precision is 0.024242460317460357, the recall is 0.11371666666666658, the f1 score is 0.032262259662750356\n",
      "Testing predefined clustering and precomputed matrix with drain st 0.5, drain depth 5, alpha 0, beta 1, gamma 0, min cluster size 5, min samples 5, cluster selection epsilon 0.0, alpha 1.0, and leaf size 40\n",
      "The precision is 0.03877619047619036, the recall is 0.2729499999999999, the f1 score is 0.0597558740703392\n",
      "Testing predefined clustering and precomputed matrix with drain st 0.5, drain depth 5, alpha 0.2, beta 0.1, gamma 0.7, min cluster size 5, min samples 5, cluster selection epsilon 0.0, alpha 1.0, and leaf size 40\n",
      "The precision is 0.017017460317460337, the recall is 0.07791666666666676, the f1 score is 0.02287572126373176\n",
      "Testing predefined clustering and precomputed matrix with drain st 0.5, drain depth 5, alpha 0.9, beta 0.1, gamma 0, min cluster size 5, min samples 5, cluster selection epsilon 0.0, alpha 1.0, and leaf size 40\n",
      "The precision is 0.055441865079364876, the recall is 0.4182583333333327, the f1 score is 0.08811462898907589\n",
      "Testing predefined clustering and precomputed matrix with drain st 0.5, drain depth 5, alpha 0.5, beta 0.5, gamma 0, min cluster size 5, min samples 5, cluster selection epsilon 0.0, alpha 1.0, and leaf size 40\n",
      "The precision is 0.018284126984127, the recall is 0.08330000000000001, the f1 score is 0.025075030283378544\n",
      "Testing predefined clustering and precomputed matrix with drain st 0.5, drain depth 5, alpha 0.1, beta 0.9, gamma 0, min cluster size 5, min samples 5, cluster selection epsilon 0.0, alpha 1.0, and leaf size 40\n",
      "The precision is 0.02228333333333335, the recall is 0.08741666666666653, the f1 score is 0.029935064573526984\n",
      "*****\n",
      "Testing generated clustering and raw data matrix with drain st 0.5, drain depth 5, min cluster size 0.7, min samples 0.2, cluster selection epsilon 0.1, alpha clustering 5, and leaf size 5\n",
      "The precision is 0.04329999999999994, the recall is 0.3056833333333341, the f1 score is 0.06963128182643806\n",
      "*****\n",
      "Testing generated clustering and precomputed matrix with drain st 0.5, drain depth 5, alpha 0.7, beta 0.2, gamma 0.1, min cluster size 5, min samples 5, cluster selection epsilon 0.0, alpha 1.0, and leaf size 40\n",
      "The precision is 0.045049999999999896, the recall is 0.3261166666666674, the f1 score is 0.07280648581859003\n",
      "Testing generated clustering and precomputed matrix with drain st 0.5, drain depth 5, alpha 1, beta 0, gamma 0, min cluster size 5, min samples 5, cluster selection epsilon 0.0, alpha 1.0, and leaf size 40\n",
      "The precision is 0.047299999999999835, the recall is 0.33308333333333395, the f1 score is 0.07592419302695162\n",
      "Testing generated clustering and precomputed matrix with drain st 0.5, drain depth 5, alpha 0, beta 1, gamma 0, min cluster size 5, min samples 5, cluster selection epsilon 0.0, alpha 1.0, and leaf size 40\n",
      "The precision is 0.04399999999999984, the recall is 0.316133333333334, the f1 score is 0.0711822738907103\n",
      "Testing generated clustering and precomputed matrix with drain st 0.5, drain depth 5, alpha 0.2, beta 0.1, gamma 0.7, min cluster size 5, min samples 5, cluster selection epsilon 0.0, alpha 1.0, and leaf size 40\n",
      "The precision is 0.04739999999999984, the recall is 0.3303833333333341, the f1 score is 0.07586282938970638\n",
      "Testing generated clustering and precomputed matrix with drain st 0.5, drain depth 5, alpha 0.9, beta 0.1, gamma 0, min cluster size 5, min samples 5, cluster selection epsilon 0.0, alpha 1.0, and leaf size 40\n",
      "The precision is 0.0441499999999998, the recall is 0.3297333333333341, the f1 score is 0.07220628186782724\n",
      "Testing generated clustering and precomputed matrix with drain st 0.5, drain depth 5, alpha 0.5, beta 0.5, gamma 0, min cluster size 5, min samples 5, cluster selection epsilon 0.0, alpha 1.0, and leaf size 40\n",
      "The precision is 0.045999999999999916, the recall is 0.31903333333333406, the f1 score is 0.07345552425015944\n",
      "Testing generated clustering and precomputed matrix with drain st 0.5, drain depth 5, alpha 0.1, beta 0.9, gamma 0, min cluster size 5, min samples 5, cluster selection epsilon 0.0, alpha 1.0, and leaf size 40\n",
      "The precision is 0.04464999999999988, the recall is 0.3217333333333341, the f1 score is 0.07209643337063033\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The precision is 0.04464999999999988, the recall is 0.3217333333333341, the f1 score is 0.07209643337063033'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## General parameters \n",
    "\n",
    "dataset = \"Proxifier\" # The name of the dataset being tested\n",
    "\n",
    "input_dir = os.path.join(os.getcwd(), \"ground_truths\") # The input directory of raw logs\n",
    "output_dir = os.path.join(os.getcwd(), \"results\")  # The output directory of parsing results\n",
    "vector_dir = os.path.join(os.getcwd(), \"vectors\")  # The vector directory of converted logs\n",
    "logName = dataset + '_lines.txt' # Name of file to be parsed\n",
    "log_format = '<Content>' # Format of the file, if there are different fields\n",
    "regex = [] # Regex strings for Drain execution\n",
    "indir = os.path.join(input_dir, os.path.dirname(logName))\n",
    "log_file = os.path.basename(logName)\n",
    "\n",
    "## Pipeline of methods\n",
    "\n",
    "drain_st = 0.5\n",
    "drain_depth = 5\n",
    "alpha = 0.7\n",
    "beta = 0.2\n",
    "gamma = 0.1\n",
    "min_cluster_size = 5\n",
    "min_samples = 5\n",
    "cluster_selection_epsilon = 0.0\n",
    "alpha_clustering = 1.0\n",
    "leaf_size = 40\n",
    "\n",
    "tests_predefined_rawdata(drain_st, drain_depth, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "\n",
    "print(\"*****\")\n",
    "\n",
    "tests_predefined_precomputed(drain_st, drain_depth, alpha, beta, gamma, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "tests_predefined_precomputed(drain_st, drain_depth, 1, 0, 0, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "tests_predefined_precomputed(drain_st, drain_depth, 0, 1, 0, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "tests_predefined_precomputed(drain_st, drain_depth, 0.2, 0.1, 0.7, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "tests_predefined_precomputed(drain_st, drain_depth, 0.9, 0.1, 0, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "tests_predefined_precomputed(drain_st, drain_depth, 0.5, 0.5, 0, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "tests_predefined_precomputed(drain_st, drain_depth, 0.1, 0.9, 0, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "\n",
    "print(\"*****\")\n",
    "\n",
    "tests_generated_rawdata(drain_st, drain_depth, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "\n",
    "print(\"*****\")\n",
    "\n",
    "tests_generated_precomputed(drain_st, drain_depth, alpha, beta, gamma, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "tests_generated_precomputed(drain_st, drain_depth, 1, 0, 0, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "tests_generated_precomputed(drain_st, drain_depth, 0, 1, 0, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "tests_generated_precomputed(drain_st, drain_depth, 0.2, 0.1, 0.7, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "tests_generated_precomputed(drain_st, drain_depth, 0.9, 0.1, 0, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "tests_generated_precomputed(drain_st, drain_depth, 0.5, 0.5, 0, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "tests_generated_precomputed(drain_st, drain_depth, 0.1, 0.9, 0, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing generated clustering and precomputed matrix with drain st 0.5, drain depth 5, alpha 0.3, beta 0.4, gamma 0.3, cluster_num 8\n",
      "The precision is 0.21934047619047772, the recall is 0.5385023809523839, the f1 score is 0.30430764386567183\n",
      "Testing generated clustering and precomputed matrix with drain st 0.5, drain depth 5, alpha 0.3, beta 0.4, gamma 0.3, cluster_num 20\n",
      "The precision is 0.2224547619047638, the recall is 0.5466690476190507, the f1 score is 0.3088331183687678\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The precision is 0.2224547619047638, the recall is 0.5466690476190507, the f1 score is 0.3088331183687678'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tests_hdbscan(drain_st, drain_depth, alpha, beta, gamma, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size):\n",
    "    parameters = (\"Testing generated clustering and precomputed matrix with drain st {}, drain depth {}, alpha {}, beta {}, gamma {}, min cluster size {}, min samples {}, cluster selection epsilon {}, alpha {}, and leaf size {}\".\n",
    "          format(drain_st, drain_depth, alpha, beta, gamma, min_cluster_size,min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size))\n",
    "    print(parameters)\n",
    "    vector_df = transform(os.path.basename(logName))\n",
    "    distance_matrix = create_distance_matrix(vector_df)\n",
    "    variable_matrix = create_variable_matrix()\n",
    "    closeness_matrix = creates_closeness_matrix(distance_matrix)\n",
    "    joint_matrix = joins_matrices(distance_matrix, variable_matrix, closeness_matrix, \n",
    "                                alpha, beta, gamma)\n",
    "    clustering = cluster_hdbscan(joint_matrix, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "    topic_summaries = bertopic_new_clustering()\n",
    "    final = calculates_metrics()\n",
    "    return (final)\n",
    "\n",
    "def tests_kmedoids(drain_st, drain_depth, alpha, beta, gamma, cluster_num):\n",
    "    parameters = (\"Testing generated clustering and precomputed matrix with drain st {}, drain depth {}, alpha {}, beta {}, gamma {}, cluster_num {}\".\n",
    "          format(drain_st, drain_depth, alpha, beta, gamma, cluster_num))\n",
    "    print(parameters)\n",
    "    vector_df = transform(os.path.basename(logName))\n",
    "    distance_matrix = create_distance_matrix(vector_df)\n",
    "    variable_matrix = create_variable_matrix()\n",
    "    closeness_matrix = creates_closeness_matrix(distance_matrix)\n",
    "    joint_matrix = joins_matrices(distance_matrix, variable_matrix, closeness_matrix,alpha, beta, gamma)\n",
    "    clustering = cluster_kmedoids(joint_matrix, cluster_num)\n",
    "    topic_summaries = bertopic_new_clustering()\n",
    "    final = calculates_metrics()\n",
    "    return (final)\n",
    "\n",
    "## General parameters \n",
    "\n",
    "dataset = \"bgl\" # The name of the dataset being tested\n",
    "\n",
    "input_dir = os.path.join(os.getcwd(), \"ground_truths\") # The input directory of raw logs\n",
    "output_dir = os.path.join(os.getcwd(), \"results\")  # The output directory of parsing results\n",
    "vector_dir = os.path.join(os.getcwd(), \"vectors\")  # The vector directory of converted logs\n",
    "logName = dataset + '_lines.txt' # Name of file to be parsed\n",
    "log_format = '<Content>' # Format of the file, if there are different fields\n",
    "regex = [] # Regex strings for Drain execution\n",
    "indir = os.path.join(input_dir, os.path.dirname(logName))\n",
    "log_file = os.path.basename(logName)\n",
    "\n",
    "min_cluster_size = 5\n",
    "min_samples = 5\n",
    "cluster_selection_epsilon = 0.0\n",
    "alpha_clustering = 1.0\n",
    "leaf_size = 40\n",
    "\n",
    "## Pipeline of methods\n",
    "\n",
    "drain_st = 0.5\n",
    "drain_depth = 5\n",
    "alpha = 0.3\n",
    "beta = 0.4\n",
    "gamma = 0.3\n",
    "cluster_num = 2\n",
    "\n",
    "#tests_hdbscan(drain_st, drain_depth, alpha, beta, gamma, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "tests_kmedoids(drain_st, drain_depth, alpha, beta, gamma, 8)\n",
    "tests_kmedoids(drain_st, drain_depth, alpha, beta, gamma, 20)\n",
    "# print(\"***\")\n",
    "# tests_hdbscan(drain_st, drain_depth, 1, 0, 0, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "# tests_kmedoids(drain_st, drain_depth, 1, 0, 0, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "# print(\"***\")\n",
    "# tests_hdbscan(drain_st, drain_depth, 0, 1, 0, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "# tests_kmedoids(drain_st, drain_depth, 0, 1, 0, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "# print(\"***\")\n",
    "# tests_hdbscan(drain_st, drain_depth, 0.2, 0.1, 0.7, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "# tests_kmedoids(drain_st, drain_depth,  0.2, 0.1, 0.7, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "# print(\"***\")\n",
    "# tests_hdbscan(drain_st, drain_depth, 0.9, 0.1, 0, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "# tests_kmedoids(drain_st, drain_depth, 0.9, 0.1, 0, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "# print(\"***\")\n",
    "# tests_hdbscan(drain_st, drain_depth, 0.5, 0.5, 0, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "# tests_kmedoids(drain_st, drain_depth, 0.5, 0.5, 0, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "# print(\"***\")\n",
    "# tests_hdbscan(drain_st, drain_depth, 0.1, 0.9, 0, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "# tests_kmedoids(drain_st, drain_depth, 0.1, 0.9, 0, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "# print(\"***\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests_predefined_rawdata(drain_st, drain_depth, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "\n",
    "print(\"*****\")\n",
    "\n",
    "tests_generated_rawdata(drain_st, drain_depth, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing predefined clustering and precomputed matrix with drain st 0.5, drain depth 5, alpha 0.7, beta 0.2, gamma 0.1, min cluster size 5, min samples 5, cluster selection epsilon 0.0, alpha 1.0, and leaf size 40\n",
      "The precision is 0.09790496031746, the recall is 0.20224166666666718, the f1 score is 0.12862649979774687\n",
      "Testing predefined clustering and precomputed matrix with drain st 0.5, drain depth 5, alpha 0.7, beta 0.2, gamma 0.1, min cluster size 5, min samples 5, cluster selection epsilon 0.0, alpha 0.75, and leaf size 40\n",
      "The precision is 0.10692817460317404, the recall is 0.21532499999999993, the f1 score is 0.1398958468749993\n",
      "Testing predefined clustering and precomputed matrix with drain st 0.5, drain depth 5, alpha 0.7, beta 0.2, gamma 0.1, min cluster size 5, min samples 5, cluster selection epsilon 0.0, alpha 0.5, and leaf size 40\n",
      "The precision is 0.10592817460317405, the recall is 0.21332499999999988, the f1 score is 0.13856251355499927\n",
      "Testing predefined clustering and precomputed matrix with drain st 0.5, drain depth 5, alpha 0.7, beta 0.2, gamma 0.1, min cluster size 5, min samples 5, cluster selection epsilon 0.0, alpha 0.25, and leaf size 40\n",
      "The precision is 0.10175674603174564, the recall is 0.208525, the f1 score is 0.13367789827554033\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The precision is 0.10175674603174564, the recall is 0.208525, the f1 score is 0.13367789827554033'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## General parameters \n",
    "\n",
    "dataset = \"bgl\" # The name of the dataset being tested\n",
    "\n",
    "input_dir = os.path.join(os.getcwd(), \"ground_truths\") # The input directory of raw logs\n",
    "output_dir = os.path.join(os.getcwd(), \"results\")  # The output directory of parsing results\n",
    "vector_dir = os.path.join(os.getcwd(), \"vectors\")  # The vector directory of converted logs\n",
    "logName = dataset + '_lines.txt' # Name of file to be parsed\n",
    "log_format = '<Content>' # Format of the file, if there are different fields\n",
    "regex = [] # Regex strings for Drain execution\n",
    "indir = os.path.join(input_dir, os.path.dirname(logName))\n",
    "log_file = os.path.basename(logName)\n",
    "\n",
    "## Pipeline of methods\n",
    "\n",
    "drain_st = 0.5\n",
    "drain_depth = 5\n",
    "alpha = 0.7\n",
    "beta = 0.2\n",
    "gamma = 0.1\n",
    "min_cluster_size = 5\n",
    "min_samples = 5\n",
    "cluster_selection_epsilon = 0.0\n",
    "alpha_clustering = 1.0\n",
    "leaf_size = 40\n",
    "\n",
    "tests_predefined_precomputed(drain_st, drain_depth, alpha, beta, gamma, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "# tests_predefined_precomputed(drain_st, drain_depth, alpha, beta, gamma, min_cluster_size, min_samples, cluster_selection_epsilon, 0.9, leaf_size)\n",
    "# tests_predefined_precomputed(drain_st, drain_depth, alpha, beta, gamma, min_cluster_size, min_samples, cluster_selection_epsilon, 0.8, leaf_size)\n",
    "tests_predefined_precomputed(drain_st, drain_depth, alpha, beta, gamma, min_cluster_size, min_samples, cluster_selection_epsilon, 0.75, leaf_size)\n",
    "tests_predefined_precomputed(drain_st, drain_depth, alpha, beta, gamma, min_cluster_size, min_samples, cluster_selection_epsilon, 0.5, leaf_size)\n",
    "tests_predefined_precomputed(drain_st, drain_depth, alpha, beta, gamma, min_cluster_size, min_samples, cluster_selection_epsilon, 0.25, leaf_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tests_predefined_rawdata() takes 7 positional arguments but 10 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m alpha_clustering \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m     25\u001b[0m leaf_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m40\u001b[39m\n\u001b[0;32m---> 27\u001b[0m \u001b[43mtests_predefined_rawdata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdrain_st\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrain_depth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_cluster_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcluster_selection_epsilon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha_clustering\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleaf_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m tests_predefined_precomputed(drain_st, drain_depth, alpha, beta, gamma, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n\u001b[1;32m     29\u001b[0m tests_generated_rawdata(drain_st, drain_depth, alpha, beta, gamma, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
      "\u001b[0;31mTypeError\u001b[0m: tests_predefined_rawdata() takes 7 positional arguments but 10 were given"
     ]
    }
   ],
   "source": [
    "## General parameters \n",
    "\n",
    "dataset = \"spark\" # The name of the dataset being tested\n",
    "\n",
    "input_dir = os.path.join(os.getcwd(), \"ground_truths\") # The input directory of raw logs\n",
    "output_dir = os.path.join(os.getcwd(), \"results\")  # The output directory of parsing results\n",
    "vector_dir = os.path.join(os.getcwd(), \"vectors\")  # The vector directory of converted logs\n",
    "logName = dataset + '_lines.txt' # Name of file to be parsed\n",
    "log_format = '<Content>' # Format of the file, if there are different fields\n",
    "regex = [] # Regex strings for Drain execution\n",
    "indir = os.path.join(input_dir, os.path.dirname(logName))\n",
    "log_file = os.path.basename(logName)\n",
    "\n",
    "## Pipeline of methods\n",
    "\n",
    "drain_st = 0.5\n",
    "drain_depth = 5\n",
    "alpha = 0.2\n",
    "beta = 0.1\n",
    "gamma = 0.7\n",
    "min_cluster_size = 5\n",
    "min_samples = 5\n",
    "cluster_selection_epsilon = 0\n",
    "alpha_clustering = 1.0\n",
    "leaf_size = 40\n",
    "\n",
    "tests_predefined_rawdata(drain_st, drain_depth, alpha, beta, gamma, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "tests_predefined_precomputed(drain_st, drain_depth, alpha, beta, gamma, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "tests_generated_rawdata(drain_st, drain_depth, alpha, beta, gamma, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "tests_generated_precomputed(drain_st, drain_depth, alpha, beta, gamma, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing generated clustering and precomputed matrix with drain st 0.5, drain depth 5, alpha 0.5, beta 0.5, gamma 0, min cluster size 2, min samples 5, cluster selection epsilon 0.75, alpha 0.25, and leaf size 5\n",
      "The precision is 0.21889047619047822, the recall is 0.5466357142857173, the f1 score is 0.3049342172738324\n",
      "Testing generated clustering and precomputed matrix with drain st 0.5, drain depth 5, alpha 0.5, beta 0.5, gamma 0, min cluster size 10, min samples 5, cluster selection epsilon 0.75, alpha 0.25, and leaf size 5\n",
      "The precision is 0.22290476190476347, the recall is 0.5466357142857173, the f1 score is 0.3092675505844053\n",
      "Testing generated clustering and precomputed matrix with drain st 0.5, drain depth 5, alpha 0.5, beta 0.5, gamma 0, min cluster size 20, min samples 5, cluster selection epsilon 0.75, alpha 0.25, and leaf size 5\n",
      "The precision is 0.2204047619047635, the recall is 0.5459690476190502, the f1 score is 0.3066082099585741\n",
      "Testing generated clustering and precomputed matrix with drain st 0.5, drain depth 5, alpha 0.5, beta 0.5, gamma 0, min cluster size 5, min samples 2, cluster selection epsilon 0.75, alpha 0.25, and leaf size 5\n",
      "The precision is 0.22330476190476356, the recall is 0.5476357142857173, the f1 score is 0.30983897913950736\n",
      "Testing generated clustering and precomputed matrix with drain st 0.5, drain depth 5, alpha 0.5, beta 0.5, gamma 0, min cluster size 5, min samples 10, cluster selection epsilon 0.75, alpha 0.25, and leaf size 5\n",
      "The precision is 0.22219047619047796, the recall is 0.5463500000000029, the f1 score is 0.3085493864043744\n",
      "Testing generated clustering and precomputed matrix with drain st 0.5, drain depth 5, alpha 0.5, beta 0.5, gamma 0, min cluster size 5, min samples 20, cluster selection epsilon 0.75, alpha 0.25, and leaf size 5\n",
      "The precision is 0.22325476190476348, the recall is 0.5478023809523841, the f1 score is 0.30980601211754133\n",
      "Testing generated clustering and precomputed matrix with drain st 0.5, drain depth 5, alpha 0.5, beta 0.5, gamma 0, min cluster size 5, min samples 5, cluster selection epsilon 0.5, alpha 0.25, and leaf size 5\n",
      "The precision is 0.22147797619047804, the recall is 0.5431595238095271, the f1 score is 0.30730393966323605\n",
      "Testing generated clustering and precomputed matrix with drain st 0.5, drain depth 5, alpha 0.5, beta 0.5, gamma 0, min cluster size 5, min samples 5, cluster selection epsilon 0.25, alpha 0.25, and leaf size 5\n",
      "The precision is 0.21991904761904976, the recall is 0.5404035714285746, the f1 score is 0.30535140793827353\n",
      "Testing generated clustering and precomputed matrix with drain st 0.5, drain depth 5, alpha 0.5, beta 0.5, gamma 0, min cluster size 5, min samples 5, cluster selection epsilon 1, alpha 0.25, and leaf size 5\n",
      "The precision is 0.22220476190476357, the recall is 0.5516357142857174, the f1 score is 0.309377440678112\n",
      "Testing generated clustering and precomputed matrix with drain st 0.5, drain depth 5, alpha 0.5, beta 0.5, gamma 0, min cluster size 5, min samples 5, cluster selection epsilon 0.75, alpha 0.1, and leaf size 5\n",
      "The precision is 0.22259047619047814, the recall is 0.5464785714285743, the f1 score is 0.3089203389993374\n",
      "Testing generated clustering and precomputed matrix with drain st 0.5, drain depth 5, alpha 0.5, beta 0.5, gamma 0, min cluster size 5, min samples 5, cluster selection epsilon 0.75, alpha 0.5, and leaf size 5\n",
      "The precision is 0.22204047619047793, the recall is 0.5496357142857173, the f1 score is 0.3088729784834022\n",
      "Testing generated clustering and precomputed matrix with drain st 0.5, drain depth 5, alpha 0.5, beta 0.5, gamma 0, min cluster size 5, min samples 5, cluster selection epsilon 0.75, alpha 0.75, and leaf size 5\n",
      "The precision is 0.22254047619047798, the recall is 0.545278571428575, the f1 score is 0.308643116187863\n",
      "Testing generated clustering and precomputed matrix with drain st 0.5, drain depth 5, alpha 0.5, beta 0.5, gamma 0, min cluster size 5, min samples 5, cluster selection epsilon 0.75, alpha 0.1, and leaf size 2\n",
      "The precision is 0.22342619047619208, the recall is 0.5492785714285743, the f1 score is 0.31004238358552844\n",
      "Testing generated clustering and precomputed matrix with drain st 0.5, drain depth 5, alpha 0.5, beta 0.5, gamma 0, min cluster size 5, min samples 5, cluster selection epsilon 0.75, alpha 0.5, and leaf size 10\n",
      "The precision is 0.22189047619047791, the recall is 0.5449928571428597, the f1 score is 0.3079908860646943\n",
      "Testing generated clustering and precomputed matrix with drain st 0.5, drain depth 5, alpha 0.5, beta 0.5, gamma 0, min cluster size 5, min samples 5, cluster selection epsilon 0.75, alpha 0.75, and leaf size 20\n",
      "The precision is 0.22544047619047766, the recall is 0.5522071428571461, the f1 score is 0.31267991660237066\n",
      "Testing generated clustering and precomputed matrix with drain st 0.2, drain depth 5, alpha 0.5, beta 0.5, gamma 0, min cluster size 5, min samples 5, cluster selection epsilon 0.75, alpha 0.25, and leaf size 5\n",
      "The precision is 0.22325476190476354, the recall is 0.5467785714285742, the f1 score is 0.3096302956838334\n",
      "Testing generated clustering and precomputed matrix with drain st 0.7, drain depth 5, alpha 0.5, beta 0.5, gamma 0, min cluster size 5, min samples 5, cluster selection epsilon 0.75, alpha 0.25, and leaf size 5\n",
      "The precision is 0.22414047619047775, the recall is 0.5492547619047645, the f1 score is 0.3108841829654793\n",
      "Testing generated clustering and precomputed matrix with drain st 0.1, drain depth 5, alpha 0.5, beta 0.5, gamma 0, min cluster size 5, min samples 5, cluster selection epsilon 0.75, alpha 0.25, and leaf size 5\n",
      "The precision is 0.22314047619047786, the recall is 0.5471357142857172, the f1 score is 0.30961473671760803\n",
      "Testing generated clustering and precomputed matrix with drain st 0.5, drain depth 5, alpha 0.5, beta 0.5, gamma 0, min cluster size 5, min samples 5, cluster selection epsilon 0.75, alpha 0.25, and leaf size 5\n",
      "The precision is 0.22415476190476352, the recall is 0.5498023809523841, the f1 score is 0.3110587593575122\n",
      "Testing generated clustering and precomputed matrix with drain st 0.5, drain depth 5, alpha 0.5, beta 0.5, gamma 0, min cluster size 5, min samples 5, cluster selection epsilon 0.75, alpha 0.25, and leaf size 5\n",
      "The precision is 0.22250476190476356, the recall is 0.5427071428571465, the f1 score is 0.3081880418562275\n",
      "Testing generated clustering and precomputed matrix with drain st 0.5, drain depth 5, alpha 0.5, beta 0.5, gamma 0, min cluster size 5, min samples 5, cluster selection epsilon 0.75, alpha 0.25, and leaf size 5\n",
      "The precision is 0.2210547619047639, the recall is 0.5456880952380979, the f1 score is 0.3071842495643068\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The precision is 0.2210547619047639, the recall is 0.5456880952380979, the f1 score is 0.3071842495643068'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tests_generated_precomputed(drain_st, drain_depth, 0.5, 0.5, 0, 2, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "tests_generated_precomputed(drain_st, drain_depth, 0.5, 0.5, 0, 10, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "tests_generated_precomputed(drain_st, drain_depth, 0.5, 0.5, 0, 20, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "\n",
    "tests_generated_precomputed(drain_st, drain_depth, 0.5, 0.5, 0, min_samples, 2, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "tests_generated_precomputed(drain_st, drain_depth, 0.5, 0.5, 0, min_samples, 10, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "tests_generated_precomputed(drain_st, drain_depth, 0.5, 0.5, 0, min_samples, 20, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "\n",
    "tests_generated_precomputed(drain_st, drain_depth, 0.5, 0.5, 0, min_cluster_size, min_samples, 0.5, alpha_clustering, leaf_size)\n",
    "tests_generated_precomputed(drain_st, drain_depth, 0.5, 0.5, 0, min_cluster_size, min_samples, 0.25, alpha_clustering, leaf_size)\n",
    "tests_generated_precomputed(drain_st, drain_depth, 0.5, 0.5, 0, min_cluster_size, min_samples, 1, alpha_clustering, leaf_size)\n",
    "\n",
    "tests_generated_precomputed(drain_st, drain_depth, 0.5, 0.5, 0, min_cluster_size, min_samples, cluster_selection_epsilon, 0.1, leaf_size)\n",
    "tests_generated_precomputed(drain_st, drain_depth, 0.5, 0.5, 0, min_cluster_size, min_samples, cluster_selection_epsilon, 0.5, leaf_size)\n",
    "tests_generated_precomputed(drain_st, drain_depth, 0.5, 0.5, 0, min_cluster_size, min_samples, cluster_selection_epsilon, 0.75, leaf_size)\n",
    "\n",
    "tests_generated_precomputed(drain_st, drain_depth, 0.5, 0.5, 0, min_cluster_size, min_samples, cluster_selection_epsilon, 0.1, 2)\n",
    "tests_generated_precomputed(drain_st, drain_depth, 0.5, 0.5, 0, min_cluster_size, min_samples, cluster_selection_epsilon, 0.5, 10)\n",
    "tests_generated_precomputed(drain_st, drain_depth, 0.5, 0.5, 0, min_cluster_size, min_samples, cluster_selection_epsilon, 0.75, 20)\n",
    "\n",
    "tests_generated_precomputed(0.2, drain_depth, 0.5, 0.5, 0, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "tests_generated_precomputed(0.7, drain_depth, 0.5, 0.5, 0, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "tests_generated_precomputed(0.1, drain_depth, 0.5, 0.5, 0, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teste com generated, raw data\n",
      "Testing generated clustering and raw data matrix with drain st 0.5, drain depth 5, alpha 0.7, beta 0.2, gamma 0.1, min cluster size 5, min samples 5, cluster selection epsilon 0.75, alpha 0.25, and leaf size 5\n",
      "The precision is 0.2219547619047634, the recall is 0.5487547619047641, the f1 score is 0.3085791214071742\n",
      "Testing generated clustering and raw data matrix with drain st 0.5, drain depth 5, alpha 0.7, beta 0.2, gamma 0.1, min cluster size 5, min samples 5, cluster selection epsilon 0.75, alpha 0.25, and leaf size 20\n",
      "The precision is 0.22070476190476354, the recall is 0.5389214285714313, the f1 score is 0.30576227158699276\n",
      "Testing generated clustering and raw data matrix with drain st 0.5, drain depth 5, alpha 0.7, beta 0.2, gamma 0.1, min cluster size 5, min samples 5, cluster selection epsilon 0.75, alpha 0.25, and leaf size 40\n",
      "The precision is 0.22099047619047768, the recall is 0.5439690476190503, the f1 score is 0.3069049132513597\n",
      "Testing generated clustering and precomputed matrix with drain st 0.5, drain depth 5, alpha 0.5, beta 0.5, gamma 0, min cluster size 5, min samples 5, cluster selection epsilon 0.75, alpha 0.75, and leaf size 20\n",
      "The precision is 0.22309047619047764, the recall is 0.5484452380952405, the f1 score is 0.30958817112806764\n",
      "Testing generated clustering and precomputed matrix with drain st 0.5, drain depth 5, alpha 0.5, beta 0.5, gamma 0, min cluster size 5, min samples 5, cluster selection epsilon 0.75, alpha 0.5, and leaf size 20\n",
      "The precision is 0.22069047619047802, the recall is 0.5471833333333361, the f1 score is 0.30716580332921317\n",
      "Testing generated clustering and precomputed matrix with drain st 0.5, drain depth 5, alpha 0.5, beta 0.5, gamma 0, min cluster size 5, min samples 5, cluster selection epsilon 0.75, alpha 0.25, and leaf size 20\n",
      "The precision is 0.2245404761904779, the recall is 0.5514928571428603, the f1 score is 0.311729690378217\n",
      "Testing generated clustering and precomputed matrix with drain st 0.5, drain depth 5, alpha 0.5, beta 0.5, gamma 0, min cluster size 5, min samples 5, cluster selection epsilon 0.75, alpha 0.1, and leaf size 20\n",
      "The precision is 0.22141904761904924, the recall is 0.5466357142857169, the f1 score is 0.30790824325868116\n",
      "Testing generated clustering and precomputed matrix with drain st 0.5, drain depth 5, alpha 0.5, beta 0.5, gamma 0, min cluster size 5, min samples 5, cluster selection epsilon 0.75, alpha 0.75, and leaf size 40\n",
      "The precision is 0.21899047619047815, the recall is 0.5416119047619072, the f1 score is 0.3043960299925204\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The precision is 0.21899047619047815, the recall is 0.5416119047619072, the f1 score is 0.3043960299925204'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## General parameters \n",
    "\n",
    "dataset = \"bgl\" # The name of the dataset being tested\n",
    "\n",
    "input_dir = os.path.join(os.getcwd(), \"ground_truths\") # The input directory of raw logs\n",
    "output_dir = os.path.join(os.getcwd(), \"results\")  # The output directory of parsing results\n",
    "vector_dir = os.path.join(os.getcwd(), \"vectors\")  # The vector directory of converted logs\n",
    "logName = dataset + '_lines.txt' # Name of file to be parsed\n",
    "log_format = '<Content>' # Format of the file, if there are different fields\n",
    "regex = [] # Regex strings for Drain execution\n",
    "indir = os.path.join(input_dir, os.path.dirname(logName))\n",
    "log_file = os.path.basename(logName)\n",
    "\n",
    "## Pipeline of methods\n",
    "\n",
    "drain_st = 0.5\n",
    "drain_depth = 5\n",
    "alpha = 0.7\n",
    "beta = 0.2\n",
    "gamma = 0.1\n",
    "min_cluster_size = 5\n",
    "min_samples = 5\n",
    "cluster_selection_epsilon = 0.75\n",
    "alpha_clustering = 0.25\n",
    "leaf_size = 5\n",
    "\n",
    "print (\"teste com generated, raw data\")\n",
    "tests_generated_rawdata(drain_st, drain_depth, alpha, beta, gamma, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "tests_generated_rawdata(drain_st, drain_depth, alpha, beta, gamma, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, 20)\n",
    "tests_generated_rawdata(drain_st, drain_depth, alpha, beta, gamma, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, 40)\n",
    "tests_generated_precomputed(drain_st, drain_depth, 0.5, 0.5, 0, min_cluster_size, min_samples, cluster_selection_epsilon, 0.75, 20)\n",
    "tests_generated_precomputed(drain_st, drain_depth, 0.5, 0.5, 0, min_cluster_size, min_samples, cluster_selection_epsilon, 0.5, 20)\n",
    "tests_generated_precomputed(drain_st, drain_depth, 0.5, 0.5, 0, min_cluster_size, min_samples, cluster_selection_epsilon, 0.25, 20)\n",
    "tests_generated_precomputed(drain_st, drain_depth, 0.5, 0.5, 0, min_cluster_size, min_samples, cluster_selection_epsilon, 0.1, 20)\n",
    "tests_generated_precomputed(drain_st, drain_depth, 0.5, 0.5, 0, min_cluster_size, min_samples, cluster_selection_epsilon, 0.75, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing generated clustering and precomputed matrix with drain st 0.5, drain depth 5, alpha 0.5, beta 0.5, gamma 0, min cluster size 5, min samples 5, cluster selection epsilon 0.75, alpha 0.25, and leaf size 20\n",
      "The precision is 0.22269047619047777, the recall is 0.5463357142857174, the f1 score is 0.30900997483000603\n",
      "Testing generated clustering and precomputed matrix with drain st 0.5, drain depth 5, alpha 0.5, beta 0.5, gamma 0, min cluster size 5, min samples 5, cluster selection epsilon 0.75, alpha 0.25, and leaf size 20\n",
      "The precision is 0.22149047619047774, the recall is 0.5442547619047644, the f1 score is 0.3073996342224408\n",
      "Testing generated clustering and precomputed matrix with drain st 0.5, drain depth 5, alpha 0.5, beta 0.5, gamma 0, min cluster size 5, min samples 5, cluster selection epsilon 0.75, alpha 0.25, and leaf size 20\n",
      "The precision is 0.22079047619047784, the recall is 0.5406357142857173, the f1 score is 0.3061869645280193\n",
      "Testing generated clustering and precomputed matrix with drain st 0.5, drain depth 5, alpha 0.5, beta 0.5, gamma 0, min cluster size 5, min samples 5, cluster selection epsilon 0.75, alpha 0.25, and leaf size 40\n",
      "The precision is 0.22110476190476314, the recall is 0.5431833333333362, the f1 score is 0.30693400178219116\n",
      "Testing generated clustering and precomputed matrix with drain st 0.5, drain depth 5, alpha 0.5, beta 0.5, gamma 0, min cluster size 5, min samples 5, cluster selection epsilon 0.75, alpha 0.25, and leaf size 40\n",
      "The precision is 0.2208904761904783, the recall is 0.5436357142857182, the f1 score is 0.3067510670548428\n",
      "Testing generated clustering and precomputed matrix with drain st 0.5, drain depth 5, alpha 0.5, beta 0.5, gamma 0, min cluster size 5, min samples 5, cluster selection epsilon 0.75, alpha 0.25, and leaf size 40\n",
      "The precision is 0.22440714285714447, the recall is 0.5446357142857179, the f1 score is 0.3109563117958716\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The precision is 0.22440714285714447, the recall is 0.5446357142857179, the f1 score is 0.3109563117958716'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tests_generated_precomputed(drain_st, drain_depth, 0.5, 0.5, 0, min_cluster_size, min_samples, cluster_selection_epsilon, 0.25, 20)\n",
    "tests_generated_precomputed(drain_st, drain_depth, 0.5, 0.5, 0, min_cluster_size, min_samples, cluster_selection_epsilon, 0.25, 20)\n",
    "tests_generated_precomputed(drain_st, drain_depth, 0.5, 0.5, 0, min_cluster_size, min_samples, cluster_selection_epsilon, 0.25, 20)\n",
    "tests_generated_precomputed(drain_st, drain_depth, 0.5, 0.5, 0, min_cluster_size, min_samples, cluster_selection_epsilon, 0.25, 40)\n",
    "tests_generated_precomputed(drain_st, drain_depth, 0.5, 0.5, 0, min_cluster_size, min_samples, cluster_selection_epsilon, 0.25, 40)\n",
    "tests_generated_precomputed(drain_st, drain_depth, 0.5, 0.5, 0, min_cluster_size, min_samples, cluster_selection_epsilon, 0.25, 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing generated clustering and precomputed matrix with drain st 0.5, drain depth 2, alpha 0.5, beta 0.5, gamma 0, min cluster size 5, min samples 5, cluster selection epsilon 0.75, alpha 0.25, and leaf size 5\n",
      "The precision is 0.22350476190476357, the recall is 0.5477785714285744, the f1 score is 0.31002773157455493\n",
      "Testing generated clustering and precomputed matrix with drain st 0.5, drain depth 7, alpha 0.5, beta 0.5, gamma 0, min cluster size 5, min samples 5, cluster selection epsilon 0.75, alpha 0.25, and leaf size 5\n",
      "The precision is 0.2169047619047641, the recall is 0.5474702380952405, the f1 score is 0.30256890158135746\n",
      "Testing generated clustering and precomputed matrix with drain st 0.5, drain depth 10, alpha 0.5, beta 0.5, gamma 0, min cluster size 5, min samples 5, cluster selection epsilon 0.75, alpha 0.25, and leaf size 5\n",
      "The precision is 0.22219047619047794, the recall is 0.5459214285714317, the f1 score is 0.30835201513205607\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The precision is 0.22219047619047794, the recall is 0.5459214285714317, the f1 score is 0.30835201513205607'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tests_generated_precomputed(drain_st, 2, 0.5, 0.5, 0, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "tests_generated_precomputed(drain_st, 7, 0.5, 0.5, 0, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "tests_generated_precomputed(drain_st, 10, 0.5, 0.5, 0, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing previous clustering with drain st 0.5, drain depth 5, alpha 0.7, beta 0.2, gamma 0.1, min cluster size 5, min samples 5, cluster selection epsilon 0.75, alpha 1.0, and leaf size 10\n",
      "The precision is 0.06799999999999994, the recall is 0.16934999999999992, the f1 score is 0.09437618911321943\n",
      "Testing previous clustering with drain st 0.3, drain depth 5, alpha 0.7, beta 0.2, gamma 0.1, min cluster size 5, min samples 5, cluster selection epsilon 0.75, alpha 1.0, and leaf size 10\n",
      "The precision is 0.06216666666666657, the recall is 0.12985000000000005, the f1 score is 0.0812571418434352\n",
      "Testing previous clustering with drain st 0.1, drain depth 5, alpha 0.7, beta 0.2, gamma 0.1, min cluster size 5, min samples 5, cluster selection epsilon 0.75, alpha 1.0, and leaf size 10\n",
      "The precision is 0.0, the recall is 0.0, the f1 score is 0.0\n",
      "Testing previous clustering with drain st 0.5, drain depth 3, alpha 0.7, beta 0.2, gamma 0.1, min cluster size 5, min samples 5, cluster selection epsilon 0.75, alpha 1.0, and leaf size 10\n",
      "The precision is 0.06799999999999994, the recall is 0.16934999999999992, the f1 score is 0.09437618911321943\n",
      "Testing previous clustering with drain st 0.5, drain depth 5, alpha 0.7, beta 0.2, gamma 0.1, min cluster size 5, min samples 5, cluster selection epsilon 0.75, alpha 1.0, and leaf size 10\n",
      "The precision is 0.06799999999999994, the recall is 0.16934999999999992, the f1 score is 0.09437618911321943\n",
      "Testing previous clustering with drain st 0.5, drain depth 5, alpha 1, beta 0, gamma 0, min cluster size 5, min samples 5, cluster selection epsilon 0.75, alpha 1.0, and leaf size 10\n",
      "The precision is 0.07359404761904716, the recall is 0.18912499999999915, the f1 score is 0.10314706805417456\n",
      "Testing previous clustering with drain st 0.5, drain depth 5, alpha 0, beta 1, gamma 0, min cluster size 5, min samples 5, cluster selection epsilon 0.75, alpha 1.0, and leaf size 10\n",
      "The precision is 0.04886527777777765, the recall is 0.11933333333333342, the f1 score is 0.067342656315845\n",
      "Testing previous clustering with drain st 0.5, drain depth 5, alpha 0.2, beta 0.1, gamma 0.7, min cluster size 5, min samples 5, cluster selection epsilon 0.75, alpha 1.0, and leaf size 10\n",
      "The precision is 0.028888888888888804, the recall is 0.06900000000000002, the f1 score is 0.04021977977181789\n",
      "Testing previous clustering with drain st 0.5, drain depth 5, alpha 0.9, beta 0.1, gamma 0, min cluster size 5, min samples 5, cluster selection epsilon 0.75, alpha 1.0, and leaf size 10\n",
      "The precision is 0.07187976190476202, the recall is 0.17174999999999987, the f1 score is 0.09854180698372765\n",
      "Testing previous clustering with drain st 0.5, drain depth 5, alpha 0.5, beta 0.5, gamma 0, min cluster size 5, min samples 5, cluster selection epsilon 0.75, alpha 1.0, and leaf size 10\n",
      "The precision is 0.06929801587301596, the recall is 0.16041666666666718, the f1 score is 0.0942057708525766\n",
      "Testing previous clustering with drain st 0.5, drain depth 5, alpha 0.1, beta 0.9, gamma 0, min cluster size 5, min samples 5, cluster selection epsilon 0.75, alpha 1.0, and leaf size 10\n",
      "The precision is 0.09171170634920686, the recall is 0.20509047619047688, the f1 score is 0.1240935378071072\n",
      "Testing previous clustering with drain st 0.5, drain depth 5, alpha 0.7, beta 0.2, gamma 0.1, min cluster size 10, min samples 5, cluster selection epsilon 0.75, alpha 1.0, and leaf size 10\n",
      "The precision is 0.05778333333333337, the recall is 0.13893333333333352, the f1 score is 0.08029285607085875\n",
      "Testing previous clustering with drain st 0.5, drain depth 5, alpha 0.7, beta 0.2, gamma 0.1, min cluster size 5, min samples 10, cluster selection epsilon 0.75, alpha 1.0, and leaf size 10\n",
      "The precision is 0.05778333333333337, the recall is 0.13893333333333352, the f1 score is 0.08029285607085875\n",
      "Testing previous clustering with drain st 0.5, drain depth 5, alpha 0.7, beta 0.2, gamma 0.1, min cluster size 5, min samples 5, cluster selection epsilon 0.5, alpha 1.0, and leaf size 10\n",
      "The precision is 0.07998293650793627, the recall is 0.17157499999999992, the f1 score is 0.10608088982460125\n",
      "Testing new clustering with drain st 0.5, drain depth 5, alpha 0.7, beta 0.2, gamma 0.1, min cluster size 5, min samples 5, cluster selection epsilon 0.75, alpha 1.0, and leaf size 10\n",
      "The precision is 0.22494047619047783, the recall is 0.5509214285714313, the f1 score is 0.3119830840551544\n",
      "Testing new clustering with drain st 0.3, drain depth 5, alpha 0.7, beta 0.2, gamma 0.1, min cluster size 5, min samples 5, cluster selection epsilon 0.75, alpha 1.0, and leaf size 10\n",
      "The precision is 0.22182380952381098, the recall is 0.5476357142857169, the f1 score is 0.3083237166346465\n",
      "Testing new clustering with drain st 0.1, drain depth 5, alpha 0.7, beta 0.2, gamma 0.1, min cluster size 5, min samples 5, cluster selection epsilon 0.75, alpha 1.0, and leaf size 10\n",
      "The precision is 0.2244404761904779, the recall is 0.5506119047619077, the f1 score is 0.3114343249698453\n",
      "Testing new clustering with drain st 0.5, drain depth 3, alpha 0.7, beta 0.2, gamma 0.1, min cluster size 5, min samples 5, cluster selection epsilon 0.75, alpha 1.0, and leaf size 10\n",
      "The precision is 0.22329047619047795, the recall is 0.5483023809523835, the f1 score is 0.3099627221047121\n",
      "Testing new clustering with drain st 0.5, drain depth 5, alpha 0.7, beta 0.2, gamma 0.1, min cluster size 5, min samples 5, cluster selection epsilon 0.75, alpha 1.0, and leaf size 10\n",
      "The precision is 0.2218404761904781, the recall is 0.5417785714285747, the f1 score is 0.30742070530008536\n",
      "Testing new clustering with drain st 0.5, drain depth 5, alpha 1, beta 0, gamma 0, min cluster size 5, min samples 5, cluster selection epsilon 0.75, alpha 1.0, and leaf size 10\n",
      "The precision is 0.22785476190476325, the recall is 0.5533380952380983, the f1 score is 0.31579340701710534\n",
      "Testing new clustering with drain st 0.5, drain depth 5, alpha 0, beta 1, gamma 0, min cluster size 5, min samples 5, cluster selection epsilon 0.75, alpha 1.0, and leaf size 10\n",
      "The precision is 0.2240047619047635, the recall is 0.5493023809523839, the f1 score is 0.31082799013206847\n",
      "Testing new clustering with drain st 0.5, drain depth 5, alpha 0.2, beta 0.1, gamma 0.7, min cluster size 5, min samples 5, cluster selection epsilon 0.75, alpha 1.0, and leaf size 10\n",
      "The precision is 0.22184047619047786, the recall is 0.5458023809523843, the f1 score is 0.3080514333498848\n",
      "Testing new clustering with drain st 0.5, drain depth 5, alpha 0.9, beta 0.1, gamma 0, min cluster size 5, min samples 5, cluster selection epsilon 0.75, alpha 1.0, and leaf size 10\n",
      "The precision is 0.22319047619047783, the recall is 0.5479690476190505, the f1 score is 0.30976205606583285\n",
      "Testing new clustering with drain st 0.5, drain depth 5, alpha 0.5, beta 0.5, gamma 0, min cluster size 5, min samples 5, cluster selection epsilon 0.75, alpha 1.0, and leaf size 10\n",
      "The precision is 0.224533333333335, the recall is 0.551088095238098, the f1 score is 0.31151758289024445\n",
      "Testing new clustering with drain st 0.5, drain depth 5, alpha 0.1, beta 0.9, gamma 0, min cluster size 5, min samples 5, cluster selection epsilon 0.75, alpha 1.0, and leaf size 10\n",
      "The precision is 0.2241047619047635, the recall is 0.5496357142857173, the f1 score is 0.3109818362823643\n",
      "Testing new clustering with drain st 0.5, drain depth 5, alpha 0.7, beta 0.2, gamma 0.1, min cluster size 10, min samples 5, cluster selection epsilon 0.75, alpha 1.0, and leaf size 10\n",
      "The precision is 0.21964047619047797, the recall is 0.5446357142857176, the f1 score is 0.3056348832453068\n",
      "Testing new clustering with drain st 0.5, drain depth 5, alpha 0.7, beta 0.2, gamma 0.1, min cluster size 5, min samples 10, cluster selection epsilon 0.75, alpha 1.0, and leaf size 10\n",
      "The precision is 0.22379047619047782, the recall is 0.5493023809523839, the f1 score is 0.3105972209045478\n",
      "Testing new clustering with drain st 0.5, drain depth 5, alpha 0.7, beta 0.2, gamma 0.1, min cluster size 5, min samples 5, cluster selection epsilon 0.5, alpha 1.0, and leaf size 10\n",
      "The precision is 0.2206047619047642, the recall is 0.5433690476190511, the f1 score is 0.30656685130716455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The precision is 0.2206047619047642, the recall is 0.5433690476190511, the f1 score is 0.30656685130716455'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## General parameters \n",
    "\n",
    "dataset = \"hdfs\" # The name of the dataset being tested\n",
    "\n",
    "input_dir = os.path.join(os.getcwd(), \"ground_truths\") # The input directory of raw logs\n",
    "output_dir = os.path.join(os.getcwd(), \"results\")  # The output directory of parsing results\n",
    "vector_dir = os.path.join(os.getcwd(), \"vectors\")  # The vector directory of converted logs\n",
    "logName = dataset + '_lines.txt' # Name of file to be parsed\n",
    "log_format = '<Content>' # Format of the file, if there are different fields\n",
    "regex = [] # Regex strings for Drain execution\n",
    "indir = os.path.join(input_dir, os.path.dirname(logName))\n",
    "log_file = os.path.basename(logName)\n",
    "\n",
    "## Pipeline of methods\n",
    "\n",
    "drain_st = 0.5\n",
    "drain_depth = 5\n",
    "alpha = 0.7\n",
    "beta = 0.2\n",
    "gamma = 0.1\n",
    "min_cluster_size = 5\n",
    "min_samples = 5\n",
    "cluster_selection_epsilon = 0.75\n",
    "alpha_clustering = 1.0\n",
    "leaf_size = 10\n",
    "\n",
    "previous_clustering(drain_st, drain_depth, alpha, beta, gamma, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "previous_clustering(0.3, drain_depth, alpha, beta, gamma, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "previous_clustering(0.1, drain_depth, alpha, beta, gamma, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "previous_clustering(drain_st, 3, alpha, beta, gamma, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "previous_clustering(drain_st, 5, alpha, beta, gamma, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "previous_clustering(drain_st, drain_depth, 1, 0, 0, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "previous_clustering(drain_st, drain_depth, 0, 1, 0, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "previous_clustering(drain_st, drain_depth, 0.2, 0.1, 0.7, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "previous_clustering(drain_st, drain_depth, 0.9, 0.1, 0, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "previous_clustering(drain_st, drain_depth, 0.5, 0.5, 0, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "previous_clustering(drain_st, drain_depth, 0.1, 0.9, 0, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "previous_clustering(drain_st, drain_depth, alpha, beta, gamma, 10, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "previous_clustering(drain_st, drain_depth, alpha, beta, gamma, min_cluster_size, 10, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "previous_clustering(drain_st, drain_depth, alpha, beta, gamma, min_cluster_size, min_samples, 0.5, alpha_clustering, leaf_size)\n",
    "\n",
    "new_clustering(drain_st, drain_depth, alpha, beta, gamma, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "new_clustering(0.3, drain_depth, alpha, beta, gamma, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "new_clustering(0.1, drain_depth, alpha, beta, gamma, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "new_clustering(drain_st, 3, alpha, beta, gamma, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "new_clustering(drain_st, 5, alpha, beta, gamma, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "new_clustering(drain_st, drain_depth, 1, 0, 0, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "new_clustering(drain_st, drain_depth, 0, 1, 0, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "new_clustering(drain_st, drain_depth, 0.2, 0.1, 0.7, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "new_clustering(drain_st, drain_depth, 0.9, 0.1, 0, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "new_clustering(drain_st, drain_depth, 0.5, 0.5, 0, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "new_clustering(drain_st, drain_depth, 0.1, 0.9, 0, min_cluster_size, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "new_clustering(drain_st, drain_depth, alpha, beta, gamma, 10, min_samples, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "new_clustering(drain_st, drain_depth, alpha, beta, gamma, min_cluster_size, 10, cluster_selection_epsilon, alpha_clustering, leaf_size)\n",
    "new_clustering(drain_st, drain_depth, alpha, beta, gamma, min_cluster_size, min_samples, 0.5, alpha_clustering, leaf_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing previous clustering with drain st 0.5, drain depth 5, alpha 0.7, beta 0.2, gamma 0.1, min cluster size 5, min samples 5 and cluster selection epsilon 0.75\n",
      "The precision is 0.09753333333333203, the recall is 0.292, the f1 score is 0.1460346437193026\n",
      "Testing previous clustering with drain st 0.3, drain depth 5, alpha 0.7, beta 0.2, gamma 0.1, min cluster size 5, min samples 5 and cluster selection epsilon 0.75\n",
      "The precision is 0.09753333333333203, the recall is 0.292, the f1 score is 0.1460346437193026\n",
      "Testing previous clustering with drain st 0.1, drain depth 5, alpha 0.7, beta 0.2, gamma 0.1, min cluster size 5, min samples 5 and cluster selection epsilon 0.75\n",
      "The precision is 0.09753333333333203, the recall is 0.292, the f1 score is 0.1460346437193026\n",
      "Testing previous clustering with drain st 0.5, drain depth 3, alpha 0.7, beta 0.2, gamma 0.1, min cluster size 5, min samples 5 and cluster selection epsilon 0.75\n",
      "The precision is 0.09753333333333203, the recall is 0.292, the f1 score is 0.1460346437193026\n",
      "Testing previous clustering with drain st 0.5, drain depth 5, alpha 0.7, beta 0.2, gamma 0.1, min cluster size 5, min samples 5 and cluster selection epsilon 0.75\n",
      "The precision is 0.09753333333333203, the recall is 0.292, the f1 score is 0.1460346437193026\n",
      "Testing previous clustering with drain st 0.5, drain depth 5, alpha 1, beta 0, gamma 0, min cluster size 5, min samples 5 and cluster selection epsilon 0.75\n",
      "The precision is 0.10934999999999831, the recall is 0.3157500000000003, the f1 score is 0.16181135296560278\n",
      "Testing previous clustering with drain st 0.5, drain depth 5, alpha 0, beta 1, gamma 0, min cluster size 5, min samples 5 and cluster selection epsilon 0.75\n",
      "The precision is 0.06624999999999838, the recall is 0.31816666666666626, the f1 score is 0.10941025454306451\n",
      "Testing previous clustering with drain st 0.5, drain depth 5, alpha 0.3, beta 0.4, gamma 0.3, min cluster size 5, min samples 5 and cluster selection epsilon 0.75\n",
      "The precision is 0.11999999999999825, the recall is 0.33666666666666684, the f1 score is 0.17611110862499887\n",
      "Testing previous clustering with drain st 0.5, drain depth 5, alpha 0.9, beta 0.1, gamma 0, min cluster size 5, min samples 5 and cluster selection epsilon 0.75\n",
      "The precision is 0.10623333333333175, the recall is 0.30975000000000014, the f1 score is 0.1576895581291296\n",
      "Testing previous clustering with drain st 0.5, drain depth 5, alpha 0.5, beta 0.5, gamma 0, min cluster size 5, min samples 5 and cluster selection epsilon 0.75\n",
      "The precision is 0.11014999999999832, the recall is 0.31675000000000036, the f1 score is 0.16278143842806653\n",
      "Testing previous clustering with drain st 0.5, drain depth 5, alpha 0.1, beta 0.9, gamma 0, min cluster size 5, min samples 5 and cluster selection epsilon 0.75\n",
      "The precision is 0.11014999999999832, the recall is 0.31675000000000036, the f1 score is 0.16278143842806653\n",
      "Testing previous clustering with drain st 0.5, drain depth 5, alpha 0.7, beta 0.2, gamma 0.1, min cluster size 10, min samples 5 and cluster selection epsilon 0.75\n",
      "The precision is 0.09553333333333222, the recall is 0.2879999999999999, the f1 score is 0.14336797707930285\n",
      "Testing previous clustering with drain st 0.5, drain depth 5, alpha 0.7, beta 0.2, gamma 0.1, min cluster size 5, min samples 10 and cluster selection epsilon 0.75\n",
      "The precision is 0.0912333333333325, the recall is 0.27558333333333335, the f1 score is 0.13700366094306846\n",
      "Testing previous clustering with drain st 0.5, drain depth 5, alpha 0.7, beta 0.2, gamma 0.1, min cluster size 5, min samples 5 and cluster selection epsilon 0.5\n",
      "The precision is 0.09753333333333203, the recall is 0.292, the f1 score is 0.1460346437193026\n",
      "Testing new clustering with drain st 0.5, drain depth 5, alpha 0.7, beta 0.2, gamma 0.1, min cluster size 5, min samples 5 and cluster selection epsilon 0.75\n",
      "The precision is 0.07869999999999834, the recall is 0.366166666666667, the f1 score is 0.12897252542485801\n",
      "Testing new clustering with drain st 0.3, drain depth 5, alpha 0.7, beta 0.2, gamma 0.1, min cluster size 5, min samples 5 and cluster selection epsilon 0.75\n",
      "The precision is 0.07809999999999832, the recall is 0.36416666666666686, the f1 score is 0.12804944850178118\n",
      "Testing new clustering with drain st 0.1, drain depth 5, alpha 0.7, beta 0.2, gamma 0.1, min cluster size 5, min samples 5 and cluster selection epsilon 0.75\n",
      "The precision is 0.07854999999999833, the recall is 0.365916666666667, the f1 score is 0.12876098696447835\n",
      "Testing new clustering with drain st 0.5, drain depth 3, alpha 0.7, beta 0.2, gamma 0.1, min cluster size 5, min samples 5 and cluster selection epsilon 0.75\n",
      "The precision is 0.0779499999999983, the recall is 0.3639166666666667, the f1 score is 0.12783791003607606\n",
      "Testing new clustering with drain st 0.5, drain depth 5, alpha 0.7, beta 0.2, gamma 0.1, min cluster size 5, min samples 5 and cluster selection epsilon 0.75\n",
      "The precision is 0.07854999999999832, the recall is 0.36575000000000024, the f1 score is 0.1287481664491102\n",
      "Testing new clustering with drain st 0.5, drain depth 5, alpha 1, beta 0, gamma 0, min cluster size 5, min samples 5 and cluster selection epsilon 0.75\n",
      "The precision is 0.07814999999999832, the recall is 0.3643333333333335, the f1 score is 0.12812637157870427\n",
      "Testing new clustering with drain st 0.5, drain depth 5, alpha 0, beta 1, gamma 0, min cluster size 5, min samples 5 and cluster selection epsilon 0.75\n",
      "The precision is 0.07784999999999831, the recall is 0.36333333333333345, the f1 score is 0.1276648331171658\n",
      "Testing new clustering with drain st 0.5, drain depth 5, alpha 0.2, beta 0.1, gamma 0.7, min cluster size 5, min samples 5 and cluster selection epsilon 0.75\n",
      "The precision is 0.07879999999999833, the recall is 0.366666666666667, the f1 score is 0.12913919208874688\n",
      "Testing new clustering with drain st 0.5, drain depth 5, alpha 0.9, beta 0.1, gamma 0, min cluster size 5, min samples 5 and cluster selection epsilon 0.75\n",
      "The precision is 0.07849999999999832, the recall is 0.3655000000000002, the f1 score is 0.12866483311716576\n",
      "Testing new clustering with drain st 0.5, drain depth 5, alpha 0.5, beta 0.5, gamma 0, min cluster size 5, min samples 5 and cluster selection epsilon 0.75\n",
      "The precision is 0.07879999999999833, the recall is 0.366666666666667, the f1 score is 0.12913919208874688\n",
      "Testing new clustering with drain st 0.5, drain depth 5, alpha 0.1, beta 0.9, gamma 0, min cluster size 5, min samples 5 and cluster selection epsilon 0.75\n",
      "The precision is 0.07839999999999832, the recall is 0.3653333333333336, the f1 score is 0.1285238074733623\n",
      "Testing new clustering with drain st 0.5, drain depth 5, alpha 0.7, beta 0.2, gamma 0.1, min cluster size 10, min samples 5 and cluster selection epsilon 0.75\n",
      "The precision is 0.07859999999999832, the recall is 0.3660000000000002, the f1 score is 0.12883149978105463\n",
      "Testing new clustering with drain st 0.5, drain depth 5, alpha 0.7, beta 0.2, gamma 0.1, min cluster size 5, min samples 10 and cluster selection epsilon 0.75\n",
      "The precision is 0.07839999999999832, the recall is 0.3653333333333335, the f1 score is 0.12852380747336237\n",
      "Testing new clustering with drain st 0.5, drain depth 5, alpha 0.7, beta 0.2, gamma 0.1, min cluster size 5, min samples 5 and cluster selection epsilon 0.5\n",
      "The precision is 0.07859999999999832, the recall is 0.3660000000000002, the f1 score is 0.12883149978105463\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The precision is 0.07859999999999832, the recall is 0.3660000000000002, the f1 score is 0.12883149978105463'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## General parameters \n",
    "\n",
    "dataset = \"hdfs\" # The name of the dataset being tested\n",
    "\n",
    "input_dir = os.path.join(os.getcwd(), \"ground_truths\") # The input directory of raw logs\n",
    "output_dir = os.path.join(os.getcwd(), \"results\")  # The output directory of parsing results\n",
    "vector_dir = os.path.join(os.getcwd(), \"vectors\")  # The vector directory of converted logs\n",
    "logName = dataset + '_lines.txt' # Name of file to be parsed\n",
    "log_format = '<Content>' # Format of the file, if there are different fields\n",
    "regex = [] # Regex strings for Drain execution\n",
    "indir = os.path.join(input_dir, os.path.dirname(logName))\n",
    "log_file = os.path.basename(logName)\n",
    "\n",
    "## Pipeline of methods\n",
    "\n",
    "drain_st = 0.5\n",
    "drain_depth = 5\n",
    "alpha = 0.7\n",
    "beta = 0.2\n",
    "gamma = 0.1\n",
    "min_cluster_size = 5\n",
    "min_samples = 5\n",
    "cluster_selection_epsilon = 0.75\n",
    "\n",
    "previous_clustering(drain_st, drain_depth, alpha, beta, gamma, min_cluster_size, min_samples, cluster_selection_epsilon)\n",
    "previous_clustering(0.3, drain_depth, alpha, beta, gamma, min_cluster_size, min_samples, cluster_selection_epsilon)\n",
    "previous_clustering(0.1, drain_depth, alpha, beta, gamma, min_cluster_size, min_samples, cluster_selection_epsilon)\n",
    "previous_clustering(drain_st, 3, alpha, beta, gamma, min_cluster_size, min_samples, cluster_selection_epsilon)\n",
    "previous_clustering(drain_st, 5, alpha, beta, gamma, min_cluster_size, min_samples, cluster_selection_epsilon)\n",
    "previous_clustering(drain_st, drain_depth, 1, 0, 0, min_cluster_size, min_samples, cluster_selection_epsilon)\n",
    "previous_clustering(drain_st, drain_depth, 0, 1, 0, min_cluster_size, min_samples, cluster_selection_epsilon)\n",
    "previous_clustering(drain_st, drain_depth, 0.3, 0.4, 0.3, min_cluster_size, min_samples, cluster_selection_epsilon)\n",
    "previous_clustering(drain_st, drain_depth, 0.9, 0.1, 0, min_cluster_size, min_samples, cluster_selection_epsilon)\n",
    "previous_clustering(drain_st, drain_depth, 0.5, 0.5, 0, min_cluster_size, min_samples, cluster_selection_epsilon)\n",
    "previous_clustering(drain_st, drain_depth, 0.1, 0.9, 0, min_cluster_size, min_samples, cluster_selection_epsilon)\n",
    "previous_clustering(drain_st, drain_depth, alpha, beta, gamma, 10, min_samples, cluster_selection_epsilon)\n",
    "previous_clustering(drain_st, drain_depth, alpha, beta, gamma, min_cluster_size, 10, cluster_selection_epsilon)\n",
    "previous_clustering(drain_st, drain_depth, alpha, beta, gamma, min_cluster_size, min_samples, 0.5)\n",
    "\n",
    "new_clustering(drain_st, drain_depth, alpha, beta, gamma, min_cluster_size, min_samples, cluster_selection_epsilon)\n",
    "new_clustering(0.3, drain_depth, alpha, beta, gamma, min_cluster_size, min_samples, cluster_selection_epsilon)\n",
    "new_clustering(0.1, drain_depth, alpha, beta, gamma, min_cluster_size, min_samples, cluster_selection_epsilon)\n",
    "new_clustering(drain_st, 3, alpha, beta, gamma, min_cluster_size, min_samples, cluster_selection_epsilon)\n",
    "new_clustering(drain_st, 5, alpha, beta, gamma, min_cluster_size, min_samples, cluster_selection_epsilon)\n",
    "new_clustering(drain_st, drain_depth, 1, 0, 0, min_cluster_size, min_samples, cluster_selection_epsilon)\n",
    "new_clustering(drain_st, drain_depth, 0, 1, 0, min_cluster_size, min_samples, cluster_selection_epsilon)\n",
    "new_clustering(drain_st, drain_depth, 0.2, 0.1, 0.7, min_cluster_size, min_samples, cluster_selection_epsilon)\n",
    "new_clustering(drain_st, drain_depth, 0.9, 0.1, 0, min_cluster_size, min_samples, cluster_selection_epsilon)\n",
    "new_clustering(drain_st, drain_depth, 0.5, 0.5, 0, min_cluster_size, min_samples, cluster_selection_epsilon)\n",
    "new_clustering(drain_st, drain_depth, 0.1, 0.9, 0, min_cluster_size, min_samples, cluster_selection_epsilon)\n",
    "new_clustering(drain_st, drain_depth, alpha, beta, gamma, 10, min_samples, cluster_selection_epsilon)\n",
    "new_clustering(drain_st, drain_depth, alpha, beta, gamma, min_cluster_size, 10, cluster_selection_epsilon)\n",
    "new_clustering(drain_st, drain_depth, alpha, beta, gamma, min_cluster_size, min_samples, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing previous clustering with drain st 0.5, drain depth 5, alpha 0.7, beta 0.2, gamma 0.1, min cluster size 5, min samples 5 and cluster selection epsilon 0.75\n",
      "Iniciando encode\n",
      "The precision is 0.055766666666667006, the recall is 0.08873333333333354, the f1 score is 0.0671143818715341\n",
      "Testing previous clustering with drain st 0.3, drain depth 5, alpha 0.7, beta 0.2, gamma 0.1, min cluster size 5, min samples 5 and cluster selection epsilon 0.75\n",
      "The precision is 0.05451666666666701, the recall is 0.08548333333333352, the f1 score is 0.06533965662714547\n",
      "Testing previous clustering with drain st 0.1, drain depth 5, alpha 0.7, beta 0.2, gamma 0.1, min cluster size 5, min samples 5 and cluster selection epsilon 0.75\n",
      "The precision is 0.05696666666666701, the recall is 0.0897333333333335, the f1 score is 0.06844130494866518\n",
      "Testing previous clustering with drain st 0.5, drain depth 3, alpha 0.7, beta 0.2, gamma 0.1, min cluster size 5, min samples 5 and cluster selection epsilon 0.75\n",
      "The precision is 0.057066666666667, the recall is 0.09206666666666685, the f1 score is 0.06890925364537735\n",
      "Testing previous clustering with drain st 0.5, drain depth 5, alpha 0.7, beta 0.2, gamma 0.1, min cluster size 5, min samples 5 and cluster selection epsilon 0.75\n",
      "The precision is 0.055766666666667006, the recall is 0.08873333333333354, the f1 score is 0.0671143818715341\n",
      "Testing previous clustering with drain st 0.5, drain depth 5, alpha 1, beta 0, gamma 0, min cluster size 5, min samples 5 and cluster selection epsilon 0.75\n",
      "The precision is 0.05241388888888885, the recall is 0.08043333333333362, the f1 score is 0.05995308619520028\n",
      "Testing previous clustering with drain st 0.5, drain depth 5, alpha 0, beta 1, gamma 0, min cluster size 5, min samples 5 and cluster selection epsilon 0.75\n",
      "The precision is 0.0399722222222223, the recall is 0.10816666666666633, the f1 score is 0.05610315838665764\n",
      "Testing previous clustering with drain st 0.5, drain depth 5, alpha 0.3, beta 0.4, gamma 0.3, min cluster size 5, min samples 5 and cluster selection epsilon 0.75\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m previous_clustering(drain_st, drain_depth, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, min_cluster_size, min_samples, cluster_selection_epsilon)\n\u001b[1;32m     31\u001b[0m previous_clustering(drain_st, drain_depth, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, min_cluster_size, min_samples, cluster_selection_epsilon)\n\u001b[0;32m---> 32\u001b[0m \u001b[43mprevious_clustering\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdrain_st\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrain_depth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_cluster_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcluster_selection_epsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m previous_clustering(drain_st, drain_depth, \u001b[38;5;241m0.9\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0\u001b[39m, min_cluster_size, min_samples, cluster_selection_epsilon)\n\u001b[1;32m     34\u001b[0m previous_clustering(drain_st, drain_depth, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0\u001b[39m, min_cluster_size, min_samples, cluster_selection_epsilon)\n",
      "Cell \u001b[0;32mIn[15], line 374\u001b[0m, in \u001b[0;36mprevious_clustering\u001b[0;34m(drain_st, drain_depth, alpha, beta, gamma, min_cluster_size, min_samples, cluster_selection_epsilon)\u001b[0m\n\u001b[1;32m    371\u001b[0m joint_matrix \u001b[38;5;241m=\u001b[39m joins_matrices(distance_matrix, variable_matrix, closeness_matrix, \n\u001b[1;32m    372\u001b[0m                             alpha, beta, gamma)\n\u001b[1;32m    373\u001b[0m clustering \u001b[38;5;241m=\u001b[39m cluster_hdbscan(joint_matrix, min_cluster_size, min_samples, cluster_selection_epsilon)\n\u001b[0;32m--> 374\u001b[0m topic_summaries \u001b[38;5;241m=\u001b[39m \u001b[43mbertopic_previous_clustering\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclustering\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    375\u001b[0m final \u001b[38;5;241m=\u001b[39m calculates_metrics()\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (final)\n",
      "Cell \u001b[0;32mIn[15], line 266\u001b[0m, in \u001b[0;36mbertopic_previous_clustering\u001b[0;34m(clusterer)\u001b[0m\n\u001b[1;32m    261\u001b[0m     cluster_topic\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, elem \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(clusterer\u001b[38;5;241m.\u001b[39mlabels_):\n\u001b[1;32m    264\u001b[0m \n\u001b[1;32m    265\u001b[0m     \u001b[38;5;66;03m## For each cluster, maps topics, and defines them as the summary\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[43mcluster_topic\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    267\u001b[0m         summary \u001b[38;5;241m=\u001b[39m find_topics_bertopic(cluster_lines, elem\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    268\u001b[0m         cluster_topic[elem\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m summary\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "## General parameters \n",
    "\n",
    "dataset = \"Zookeeper\" # The name of the dataset being tested\n",
    "\n",
    "input_dir = os.path.join(os.getcwd(), \"ground_truths\") # The input directory of raw logs\n",
    "output_dir = os.path.join(os.getcwd(), \"results\")  # The output directory of parsing results\n",
    "vector_dir = os.path.join(os.getcwd(), \"vectors\")  # The vector directory of converted logs\n",
    "logName = dataset + '_lines.txt' # Name of file to be parsed\n",
    "log_format = '<Content>' # Format of the file, if there are different fields\n",
    "regex = [] # Regex strings for Drain execution\n",
    "indir = os.path.join(input_dir, os.path.dirname(logName))\n",
    "log_file = os.path.basename(logName)\n",
    "\n",
    "## Pipeline of methods\n",
    "\n",
    "drain_st = 0.5\n",
    "drain_depth = 5\n",
    "alpha = 0.7\n",
    "beta = 0.2\n",
    "gamma = 0.1\n",
    "min_cluster_size = 5\n",
    "min_samples = 5\n",
    "cluster_selection_epsilon = 0.75\n",
    "\n",
    "previous_clustering(drain_st, drain_depth, alpha, beta, gamma, min_cluster_size, min_samples, cluster_selection_epsilon)\n",
    "previous_clustering(0.3, drain_depth, alpha, beta, gamma, min_cluster_size, min_samples, cluster_selection_epsilon)\n",
    "previous_clustering(0.1, drain_depth, alpha, beta, gamma, min_cluster_size, min_samples, cluster_selection_epsilon)\n",
    "previous_clustering(drain_st, 3, alpha, beta, gamma, min_cluster_size, min_samples, cluster_selection_epsilon)\n",
    "previous_clustering(drain_st, 5, alpha, beta, gamma, min_cluster_size, min_samples, cluster_selection_epsilon)\n",
    "previous_clustering(drain_st, drain_depth, 1, 0, 0, min_cluster_size, min_samples, cluster_selection_epsilon)\n",
    "previous_clustering(drain_st, drain_depth, 0, 1, 0, min_cluster_size, min_samples, cluster_selection_epsilon)\n",
    "previous_clustering(drain_st, drain_depth, 0.3, 0.4, 0.3, min_cluster_size, min_samples, cluster_selection_epsilon)\n",
    "previous_clustering(drain_st, drain_depth, 0.9, 0.1, 0, min_cluster_size, min_samples, cluster_selection_epsilon)\n",
    "previous_clustering(drain_st, drain_depth, 0.5, 0.5, 0, min_cluster_size, min_samples, cluster_selection_epsilon)\n",
    "previous_clustering(drain_st, drain_depth, 0.1, 0.9, 0, min_cluster_size, min_samples, cluster_selection_epsilon)\n",
    "previous_clustering(drain_st, drain_depth, alpha, beta, gamma, 10, min_samples, cluster_selection_epsilon)\n",
    "previous_clustering(drain_st, drain_depth, alpha, beta, gamma, min_cluster_size, 10, cluster_selection_epsilon)\n",
    "previous_clustering(drain_st, drain_depth, alpha, beta, gamma, min_cluster_size, min_samples, 0.5)\n",
    "\n",
    "new_clustering(drain_st, drain_depth, alpha, beta, gamma, min_cluster_size, min_samples, cluster_selection_epsilon)\n",
    "new_clustering(0.3, drain_depth, alpha, beta, gamma, min_cluster_size, min_samples, cluster_selection_epsilon)\n",
    "new_clustering(0.1, drain_depth, alpha, beta, gamma, min_cluster_size, min_samples, cluster_selection_epsilon)\n",
    "new_clustering(drain_st, 3, alpha, beta, gamma, min_cluster_size, min_samples, cluster_selection_epsilon)\n",
    "new_clustering(drain_st, 5, alpha, beta, gamma, min_cluster_size, min_samples, cluster_selection_epsilon)\n",
    "new_clustering(drain_st, drain_depth, 1, 0, 0, min_cluster_size, min_samples, cluster_selection_epsilon)\n",
    "new_clustering(drain_st, drain_depth, 0, 1, 0, min_cluster_size, min_samples, cluster_selection_epsilon)\n",
    "new_clustering(drain_st, drain_depth, 0.2, 0.1, 0.7, min_cluster_size, min_samples, cluster_selection_epsilon)\n",
    "new_clustering(drain_st, drain_depth, 0.9, 0.1, 0, min_cluster_size, min_samples, cluster_selection_epsilon)\n",
    "new_clustering(drain_st, drain_depth, 0.5, 0.5, 0, min_cluster_size, min_samples, cluster_selection_epsilon)\n",
    "new_clustering(drain_st, drain_depth, 0.1, 0.9, 0, min_cluster_size, min_samples, cluster_selection_epsilon)\n",
    "new_clustering(drain_st, drain_depth, alpha, beta, gamma, 10, min_samples, cluster_selection_epsilon)\n",
    "new_clustering(drain_st, drain_depth, alpha, beta, gamma, min_cluster_size, 10, cluster_selection_epsilon)\n",
    "new_clustering(drain_st, drain_depth, alpha, beta, gamma, min_cluster_size, min_samples, 0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
